{"file_contents":{"NetWatch SIEM.md":{"content":"NetWatch SIEM - Official Documentation\n========================================\nCreator: JOHN O. MARK\n\nOverview\n--------\n\nNetWatch SIEM is an enterprise-grade Flask-based Security Information and Event Management (SIEM) system designed for comprehensive network surveillance, advanced threat detection, and real-time security monitoring. The system provides deep visibility into network activity through multi-method device discovery, intelligent threat analysis, and comprehensive security event management.\n\n\nKey Capabilities\n\n• Advanced Multi-Method Device Discovery - Comprehensive network scanning using ARP, ping sweep, port scanning, passive discovery, and traffic analysis\n• Real-Time Traffic Analysis - Deep packet inspection with threat detection, anomaly analysis, and connection tracking\n• Enterprise Security Features - Multi-user authentication, role-based access control, and secure session management\n• Smart Alert Engine - Advanced rule processing with false positive elimination, context-aware evaluation, and machine learning\n• Intelligent Threat Detection - Real-time detection of port scanning, brute force attacks, DDoS, and suspicious network behavior\n• Comprehensive User Management - Secure user registration, role assignment, and activity monitoring\n• Advanced Analytics Dashboard - Real-time network health metrics, device trends, threat patterns, and security analytics\n• International Support - Multi-language interface (English, Spanish, French, German, Chinese)\n• Rule Testing & Validation - Live rule validation against real devices with comprehensive testing framework\n• RESTful API - Complete programmatic access with secure authentication and input validation\n• Performance Optimization - Advanced caching, database optimization, and scalable architecture\n• Offline Operation - Fully functional without internet connectivity with local data storage\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nTechnical Specifications\n------------------------\n\nTechnology Stack\n\nBackend Framework    : Flask (Python 3.11) with async support\nDatabase            : SQLite 3 (netwatch.db) with optimized queries\nFrontend            : HTML5, Vanilla JavaScript, Tailwind CSS (responsive design)\nNetwork Scanning    : Scapy, Nmap, psutil (multi-method discovery)\nTraffic Analysis    : Real-time packet capture and analysis\nSecurity            : PBKDF2 password hashing, session management, input validation\nAnalytics Engine    : Chart.js for data visualization with real-time updates\nInternationalization: Custom i18n system with JSON translations\nArchitecture        : Service-oriented modular design with advanced monitoring\nCaching             : In-memory caching with TTL support\nThreat Detection    : Machine learning-based anomaly detection\n\n\nSystem Requirements\n\n• Python 3.11 or higher\n• Root/Administrator privileges (for advanced network scanning and packet capture)\n• Local network access with packet capture capabilities\n• 100MB minimum disk space (for logs, cache, and database)\n• 512MB RAM minimum (1GB recommended for large networks)\n• Network interface with promiscuous mode support (for traffic analysis)\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nInstallation & Setup\n--------------------\n\nQuick Start\n\n1. Clone the repository\n   \n   git clone <repository-url>\n   cd netwatch-siem\n\n2. Install dependencies\n   \n   pip install -r requirements.txt\n\n3. Configure environment variables (Production)\n   \n   export ADMIN_USERNAME=\"your_username\"\n   export ADMIN_PASSWORD=\"your_secure_password\"\n   export SESSION_SECRET=\"your_secret_key\"\n\n4. Run the application\n   \n   sudo python app.py\n\n   Note: sudo required for network scanning\n\n5. Access the dashboard\n   \n   Navigate to http://localhost:5000\n   Default admin credentials: admin / NetWatch2024! (change immediately)\n   \n   For new installations, register additional users at /register\n\n\nEnvironment Variables\n\nADMIN_USERNAME  : Admin login username (default: Mark)\nADMIN_PASSWORD  : Admin login password (default: lizzyjohn)\nSESSION_SECRET  : Flask session encryption key (auto-generated)\n\n⚠️  WARNING: Always configure custom credentials for production deployments.\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nEnhanced Features (Version 3.0)\n-------------------------------\n\nMulti-User Authentication System\n\n• Secure User Registration - PBKDF2 password hashing with salt\n• Role-Based Access Control - Admin, Operator, Analyst, Viewer roles\n• Session Management - Secure session tokens with expiration\n• User Activity Logging - Comprehensive audit trail\n• Brute Force Protection - Account lockout after failed attempts\n• Input Validation - Comprehensive data sanitization and validation\n\nAdvanced Network Monitoring\n\n• Multi-Method Device Discovery - ARP, ping, port scan, passive discovery\n• Real-Time Traffic Analysis - Deep packet inspection and analysis\n• Threat Detection Engine - Port scanning, brute force, DDoS detection\n• Anomaly Detection - Machine learning-based behavioral analysis\n• Connection Tracking - Real-time network connection monitoring\n• Bandwidth Monitoring - Per-device and network-wide traffic analysis\n\nPerformance & Security Enhancements\n\n• Advanced Caching System - In-memory caching with TTL support\n• Database Optimization - Optimized queries and connection pooling\n• Input Sanitization - XSS and injection attack prevention\n• Rate Limiting - API endpoint protection\n• CSRF Protection - Cross-site request forgery prevention\n• Secure Headers - Security-focused HTTP headers\n\nUser Interface Improvements\n\n• Responsive Design - Mobile-first responsive layout\n• Enhanced Navigation - Role-based menu system\n• Real-Time Updates - WebSocket-based live data updates\n• Advanced Analytics - Comprehensive network health metrics\n• User Management Interface - Complete user administration panel\n• Modern UI Components - Glassmorphism effects and animations\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nSystem Architecture\n------------------\n\nBackend Components\n\nFlask Application (app.py)\n    Main web server providing session-based authentication, RESTful API endpoints,\n    route handling, and template rendering.\n\nDevice Scanner (scanner/device_scanner.py)\n    Network discovery engine featuring ARP scanning, ping sweep fallback, MAC vendor\n    identification, and background daemon thread operation with configurable intervals.\n\nSmart Alert Engine (rules/smart_alert_engine.py)\n    Advanced security monitoring system with intelligent rule processing, false positive\n    elimination, context-aware evaluation, risk scoring, and alert deduplication.\n    Features whitelist-aware processing and learning-based decision making.\n\nLegacy Alert Engine (rules/alert_engine.py)\n    Original security monitoring system maintained for backward compatibility.\n    Processes events against rule database with basic duplicate prevention.\n\nDatabase Layer (database/models.py)\n    SQLite wrapper providing Kenya timezone support (EAT, UTC+3), dictionary-style\n    data access, thread-safe connections, and transaction management.\n\n\nFrontend Components\n\nDashboard          : Real-time statistics, network overview, activity timeline, and quick analytics\nAnalytics Dashboard: Advanced network health metrics, device trends, alert patterns, and vendor distribution\nDevice Management  : Device listing, search, trust management, and naming with persistence\nAlerts Panel       : Alert monitoring, resolution, and false positive marking\nEvent Logs         : Comprehensive event history with filtering capabilities\nConfiguration      : System settings and scan interval management\nRules Manager      : Smart rule creation, testing, validation, and management\nLanguage Selector  : Multi-language interface with real-time switching\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nDatabase Schema\n---------------\n\ndevices - Network devices discovered on the network\n\n    id              : Primary key\n    ip_address      : Device IP address\n    mac_address     : Device MAC address\n    hostname        : Device hostname\n    vendor          : MAC vendor name\n    first_seen      : First detection timestamp\n    last_seen       : Last detection timestamp\n    is_trusted      : Trust status (0/1)\n    risk_score      : Calculated risk level\n    device_name     : User-assigned name\n\n\nevents - System and network events\n\n    id              : Primary key\n    timestamp       : Event timestamp (EAT timezone)\n    event_type      : Type of event\n    device_id       : Associated device ID\n    description     : Event description\n    metadata        : JSON metadata\n\n\nalerts - Security alerts and notifications\n\n    id                  : Primary key\n    timestamp           : Alert timestamp (EAT timezone)\n    rule_id             : Triggering rule ID\n    device_id           : Associated device ID\n    severity            : Alert severity (low/medium/high)\n    message             : Alert message\n    is_resolved         : Resolution status (0/1)\n    is_false_positive   : False positive flag (0/1)\n\n\nrules - Alert rule definitions\n\n    id              : Primary key\n    name            : Unique rule identifier\n    rule_type       : Rule category\n    condition       : Evaluation condition\n    threshold       : Trigger threshold\n    severity        : Alert severity\n    enabled         : Active status (0/1)\n    description     : Rule description\n\n\nsystem_config - Persistent configuration storage\n\n    key             : Configuration key (primary key)\n    value           : Configuration value\n    updated_at      : Last update timestamp\n\n\nlicenses - License management (FULL license, all features enabled)\n\nsystem_logs - System operations and error logging\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nSecurity Features\n-----------------\n\nDevice Discovery & Monitoring\n\nARP Scanning\n    Layer 2 network discovery with MAC address vendor identification\n    \nPing Sweep Fallback\n    Alternative scanning method for restricted environments\n    \nActive Device Tracking\n    Continuous monitoring of device presence and activity\n    \nHostname Resolution\n    Automatic device name discovery\n\n\nAlert System\n\nBuilt-in Alert Types:\n\n1. New Device Detection\n   Alerts when previously unknown devices join the network\n\n2. Frequent Reconnections\n   Detects devices with unusual connection patterns\n\n3. Suspicious MAC Addresses\n   Identifies potentially spoofed or malicious MAC addresses\n\n4. Device Inactivity\n   Monitors devices that go offline unexpectedly\n\n5. IP Address Changes\n   Tracks devices changing IP addresses (potential spoofing)\n\n6. Unknown Vendors\n   Flags devices with unidentifiable manufacturers\n\n\nAlert Severity Levels:\n\nLOW    : Informational events requiring awareness\nMEDIUM : Suspicious activity requiring investigation\nHIGH   : Critical security threats requiring immediate action\n\n\nTrust Management\n\nReduce alert fatigue by marking known devices as trusted:\n\n• Trusted devices excluded from new device alerts\n• Trust status persists across scans\n• Bulk trust operations supported\n• Visual trust indicators in device listings\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nSmart Alert Engine\n------------------\n\nAdvanced Rule Processing\n\nThe Smart Alert Engine provides enterprise-grade rule processing with intelligent\nfalse positive elimination and context-aware evaluation.\n\nKey Features:\n\n• Whitelist-Aware Processing - Trusted devices excluded from unnecessary alerts\n• Alert Deduplication - Hash-based duplicate prevention with cooldown periods\n• Risk Scoring - Dynamic severity calculation based on device trust and history\n• Learning Data - Historical patterns for smarter decision making\n• Rule Testing - Live validation against real devices before deployment\n• Smart Validation - Prevents duplicate rule names and validates thresholds\n• Performance Optimization - Caching and efficient rule ordering\n\nFalse Positive Elimination:\n\n• Trusted devices automatically whitelisted from new device alerts\n• Smart thresholds prevent normal device behavior from triggering alerts\n• Context-aware evaluation considers device history and patterns\n• Alert cooldown periods prevent spam from repeated conditions\n• Learning-based risk scoring reduces false positives over time\n\nRule Testing System:\n\n• Test rules against real devices before adding\n• Live feedback on whether rules would trigger\n• Device context information for informed decisions\n• Validation prevents bad rules from being deployed\n• Dynamic help text guides appropriate threshold selection\n\nEnhanced Rule Types:\n\n• New Device Detection - Only alerts on truly new devices (1 hour window)\n• Reconnect Count - Smart thresholds (20+ for untrusted devices)\n• Inactive Duration - 24+ hours offline (not 2 hours)\n• MAC Patterns - Enhanced spoofing detection with multiple patterns\n• Vendor Unknown - Only for untrusted devices\n• IP Changes - Tracks suspicious IP address changes\n\nPerformance Features:\n\n• Alert caching prevents duplicate alerts within cooldown periods\n• Rule ordering processes high-severity rules first\n• Learning data provides historical context for decisions\n• Smart cooldowns prevent alert spam\n• Efficient database queries with proper indexing\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nCustom Rules System\n-------------------\n\nRule Conditions\n\ndevice_first_seen    : Triggers when device first detected (threshold in days)\nreconnect_count      : Exceeds reconnection threshold (count)\ninactive_duration    : Device inactive beyond threshold (seconds)\nmac_pattern          : Matches suspicious MAC patterns (pattern)\nvendor_unknown       : Device has unknown vendor (boolean)\nip_changed           : IP address change detected (boolean)\n\n\nRule Properties Example\n\n    name        : high_reconnect_alert\n    rule_type   : device_event\n    condition   : reconnect_count\n    threshold   : 10\n    severity    : medium\n    enabled     : true\n    description : Alert on devices reconnecting more than 10 times\n\n\nRule Management\n\n• Add Rules - Create custom rules via /rules page or API\n• Edit Rules - Modify thresholds and conditions in real-time\n• Toggle Rules - Enable/disable rules without deletion\n• Delete Rules - Remove unnecessary rules\n• Automatic Reload - Rules apply immediately without restart\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nAPI Reference\n-------------\n\nAuthentication\n\nAll API endpoints require authenticated session except /login.\n\n\nDashboard & Statistics\n\nGET /api/dashboard/stats\n    Returns dashboard statistics including total devices, active devices,\n    alerts, trusted devices, and new devices today.\n\nGET /api/activity/timeline\n    Returns activity data for the last 2 hours, grouped by minute.\n\n\nDevice Management\n\nGET /api/devices\n    Lists all discovered devices.\n\nGET /api/devices/active\n    Lists only currently active devices.\n\nGET /api/devices/search?q=query\n    Searches devices by IP, MAC, hostname, or vendor.\n    \n    Parameters:\n        q (string) - Search query\n\nPOST /api/devices/<id>/trust\n    Toggles device trust status.\n\nPOST /api/devices/<id>/name\n    Updates device display name.\n    \n    Request Body:\n        {\"name\": \"Office Printer\"}\n\nPOST /api/devices/delete\n    Deletes multiple devices by ID.\n    \n    Request Body:\n        {\"device_ids\": [1, 2, 3]}\n\n\nAlerts & Events\n\nGET /api/alerts?limit=50\n    Lists alerts with optional limit parameter.\n    \n    Parameters:\n        limit (integer, optional) - Maximum alerts to return\n\nPOST /api/alerts/<id>/resolve\n    Marks alert as resolved.\n\nPOST /api/alerts/<id>/mark-safe\n    Marks alert as false positive.\n\nPOST /api/alerts/delete\n    Bulk delete alerts.\n    \n    Request Body:\n        {\"alert_ids\": [1, 2, 3], \"delete_resolved\": false}\n\nGET /api/events?limit=100\n    Lists events with optional limit parameter.\n\nPOST /api/events/delete\n    Bulk delete events.\n    \n    Request Body:\n        {\"event_ids\": [1, 2, 3], \"delete_all\": false}\n\n\nNetwork Scanning\n\nGET /api/scan/status\n    Returns current scan status and interval.\n\nPOST /api/scan/now\n    Triggers immediate network scan.\n\nPOST /api/scan/start\n    Starts background scanning service.\n\nPOST /api/scan/stop\n    Stops background scanning service.\n\n\nConfiguration\n\nGET /api/config\n    Retrieves current system configuration.\n\nPOST /api/config/save\n    Saves configuration changes (applies immediately).\n    \n    Request Body:\n        {\"scan_interval\": 120, \"scanning_active\": true}\n\n\nRules Management\n\nGET /api/rules\n    Lists all alert rules.\n\nPOST /api/rules/add\n    Creates new custom rule.\n    \n    Request Body:\n        {\n            \"name\": \"unusual_reconnect\",\n            \"rule_type\": \"device_event\",\n            \"condition\": \"reconnect_count\",\n            \"threshold\": 15,\n            \"severity\": \"high\",\n            \"description\": \"Detects excessive reconnections\"\n        }\n\nDELETE /api/rules/<id>\n    Deletes specific rule.\n\nPOST /api/rules/<id>/toggle\n    Enables or disables rule.\n\n\nUtilities\n\nGET /api/timezone/info\n    Returns timezone information (Africa/Nairobi, UTC+3).\n\n\nAnalytics & Reporting\n\nGET /api/analytics/device-trends\n    Returns device trends, status distribution, and vendor distribution.\n\nGET /api/analytics/alert-trends\n    Returns alert trends, types, and hourly distribution patterns.\n\nGET /api/analytics/network-health\n    Returns network health metrics with calculated health score and risk levels.\n\n\nInternationalization\n\nPOST /api/language/set\n    Sets user language preference in session.\n    \n    Request Body:\n        {\"language\": \"en\"}\n\nGET /api/language/current\n    Returns current language and available languages.\n\n\nRule Testing\n\nPOST /api/rules/test\n    Tests a rule against a specific device before adding.\n    \n    Request Body:\n        {\n            \"name\": \"test_rule\",\n            \"condition\": \"reconnect_count\",\n            \"threshold\": 10,\n            \"severity\": \"medium\",\n            \"device_id\": 1\n        }\n\n\nResponse Format\n\nAll API endpoints return JSON with the following structure:\n\nSuccess Response:\n    {\"success\": true, \"data\": {...}}\n\nError Response:\n    {\"success\": false, \"error\": \"Error message\"}\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nConfiguration System\n-------------------\n\nPersistent Configuration\n\nAll settings persist to the system_config database table and apply in real-time\nwithout application restart.\n\n\nAvailable Settings\n\nscan_interval          : 30-600 seconds (default: 60)\n                        Network scan frequency\n                        \nscanning_active        : boolean (default: true)\n                        Enable or disable background scanning\n                        \ntraffic_monitoring     : boolean (default: false)\n                        Enable traffic analysis features\n                        \nextended_logs          : boolean (default: true)\n                        Enable detailed logging\n                        \nemail_alerts           : boolean (default: false)\n                        Enable email notifications\n                        \nalert_retention_days   : 1-365 days (default: 90)\n                        Days to retain alerts before cleanup\n                        \nlog_retention_days     : 1-365 days (default: 365)\n                        Days to retain logs before cleanup\n\n\nConfiguration Behavior\n\n• Settings saved via /api/config/save take effect immediately\n• Scanner loop polls database before each scan cycle\n• No application restart required for configuration changes\n• Thread-safe configuration access across all components\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nNetwork Scanning Capabilities\n-----------------------------\n\nScanning Methods\n\nARP Scanning (Primary)\n    • Layer 2 network discovery\n    • Requires elevated privileges (root/administrator)\n    • Most accurate method for local network\n    • Provides MAC address information\n    • Vendor identification via MAC OUI lookup\n\nPing Sweep (Fallback)\n    • ICMP-based device discovery\n    • Used when ARP scanning unavailable\n    • Works in containerized environments\n    • Limited to IP address detection\n\n\nLimitations\n\nPrivilege Requirements\n    ARP scanning requires raw socket access\n    \nContainer Restrictions\n    May not work in Docker/Replit due to network isolation\n    \nNetwork Scope\n    Limited to local subnet\n    \nFirewall Impact\n    Some devices may not respond to scans\n\n\nNetwork Interface Detection\n\nThe system automatically:\n    • Identifies active network interfaces\n    • Selects best interface for scanning\n    • Falls back to alternative methods if primary fails\n    • Logs interface selection for troubleshooting\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nSecurity Considerations\n-----------------------\n\nProduction Deployment Checklist\n\n1. Change Default Credentials\n   Always set ADMIN_USERNAME and ADMIN_PASSWORD environment variables\n\n2. Secure Session Key\n   Configure unique SESSION_SECRET value\n\n3. Enable HTTPS\n   Deploy behind reverse proxy with SSL/TLS\n\n4. Configure Firewall\n   Restrict access to port 5000 to trusted networks only\n\n5. Privilege Management\n   Run with minimal required privileges\n\n\nAuthentication & Authorization\n\n• Session-based authentication protects all routes except /login\n• Sessions expire after inactivity period\n• Input validation on all API endpoints prevents injection attacks\n• All operations logged for audit trail\n\n\nDatabase Security\n\n• SQLite suitable for deployments up to 1000 devices\n• Thread-safe connections prevent race conditions\n• Regular backups recommended for production environments\n• Consider PostgreSQL for larger deployments (1000+ devices)\n\n\nNetwork Security\n\n• Scanning features require appropriate system permissions\n• All operations logged for audit trail\n• Trust management reduces false positive alert fatigue\n• Rule-based alerting configurable to match security policy\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nFile Structure\n--------------\n\nnetwatch-siem/\n│\n├── app.py                          Main Flask application\n├── config.py                       Configuration management\n├── netwatch.db                     SQLite database\n├── requirements.txt                Python dependencies\n│\n├── database/\n│   └── models.py                   Database wrapper and models\n│\n├── scanner/\n│   ├── device_scanner.py           Network scanning engine\n│   └── enhanced_scanner.py         Enhanced scanner with persistence\n│\n├── rules/\n│   ├── alert_engine.py             Legacy alert processing engine\n│   └── smart_alert_engine.py       Smart alert engine with false positive elimination\n│\n├── i18n/\n│   ├── __init__.py                 Internationalization manager\n│   └── translations/\n│       ├── en.json                 English translations\n│       ├── es.json                 Spanish translations\n│       ├── fr.json                 French translations\n│       ├── de.json                 German translations\n│       └── zh.json                 Chinese translations\n│\n├── templates/\n│   ├── base.html                   Base template with i18n support\n│   ├── login.html                  Login page\n│   ├── dashboard.html              Dashboard view with quick analytics\n│   ├── analytics.html              Advanced analytics dashboard\n│   ├── devices.html                Device management\n│   ├── alerts.html                 Alerts panel\n│   ├── logs.html                   Event logs\n│   ├── config.html                 System configuration\n│   └── rules.html                  Smart rules management with testing\n│\n└── static/\n    ├── css/\n    │   ├── main.css                Main stylesheet\n    │   └── cyber-theme.css         Dark cyber theme with animations\n    │\n    └── js/\n        ├── dashboard.js            Dashboard logic with analytics\n        ├── analytics.js            Analytics dashboard functionality\n        ├── devices.js              Device management\n        └── alerts.js               Alerts handling\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nTroubleshooting\n---------------\n\nARP Scanning Not Working\n\nSymptoms: No devices discovered, empty device list\n\nSolutions:\n    1. Ensure application runs with elevated privileges\n       sudo python app.py\n       \n    2. Check network interface is active and connected\n    \n    3. Verify firewall allows outbound ARP packets\n    \n    4. Review system logs for scanning errors\n    \n    5. Test ping sweep fallback method\n\n\nConfiguration Changes Not Applying\n\nSymptoms: Settings revert after changing, scan interval unchanged\n\nSolutions:\n    1. Verify database write permissions\n    \n    2. Check for error messages in system logs\n    \n    3. Ensure configuration API endpoints returning success\n    \n    4. Restart application if database locked\n    \n    5. Confirm no conflicting environment variables\n\n\nHigh Alert Volume\n\nSymptoms: Too many alerts, alert fatigue\n\nSolutions:\n    1. Mark known devices as trusted\n    \n    2. Adjust rule thresholds in Rules Manager\n    \n    3. Disable overly sensitive rules\n    \n    4. Review and resolve false positive alerts\n    \n    5. Configure appropriate retention periods\n\n\nDatabase Connection Errors\n\nSymptoms: Application crashes, database locked errors\n\nSolutions:\n    1. Ensure only one instance running\n    \n    2. Check database file permissions\n    \n    3. Verify sufficient disk space\n    \n    4. Review connection pool settings\n    \n    5. Consider database backup and restore\n\n\nSystem Logs\n\nAccess system logs via:\n    • Web interface: /logs page\n    • Database: system_logs table\n    • API: /api/events endpoint\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nDevelopment Notes\n-----------------\n\nDevelopment Environment\n\n• Server binds to 0.0.0.0:5000 for broad compatibility\n• Background scanner runs in daemon thread for automatic cleanup\n• Flask debug mode disabled for production-like behavior\n• PYTHONPATH configured for module imports\n• Database file tracked in git for easier setup\n\n\nFeature Flags\n\nAll features currently enabled by default (FULL license mode):\n    • Device scanning and monitoring\n    • Custom alert rules\n    • Trust management\n    • Bulk operations\n    • Configuration persistence\n    • Event logging\n\n\nTimezone Handling\n\nAll timestamps use Kenya timezone (EAT, UTC+3):\n    • Database stores ISO 8601 formatted timestamps\n    • Frontend displays in local timezone\n    • API returns timezone information via /api/timezone/info\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nFuture Enhancements\n-------------------\n\nPlanned Features\n\nEmail Notifications\n    Critical alert delivery via email with customizable templates\n\nTraffic Monitoring\n    Deep packet inspection and network traffic analysis\n\nNetwork Topology\n    Visual network mapping and relationship visualization\n\nThreat Intelligence\n    Integration with external threat feeds and indicators of compromise\n\nReport Export\n    PDF and CSV export functionality for compliance and reporting\n\nMulti-User Support\n    Role-based access control (RBAC) with user management\n\nAPI Authentication\n    Token-based authentication for external system integrations\n\nPerformance Optimization\n    Enhanced support for large networks (1000+ devices)\n\nReal-time Updates\n    WebSocket-based live dashboard updates without page refresh\n\nMobile Application\n    Native mobile app for on-the-go network monitoring\n\n\nContribution Guidelines\n\nContributions welcome! Please follow these steps:\n\n1. Fork the repository\n2. Create feature branch\n3. Commit with clear messages\n4. Submit pull request with description\n5. Ensure tests pass and documentation updated\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nDependencies\n------------\n\nPython Libraries\n\nFlask       : Web framework and routing engine\nScapy       : Network packet manipulation and ARP scanning\npsutil      : System and network interface information\nsqlite3     : Database operations (Python standard library)\n\n\nFrontend Libraries\n\nTailwind CSS    : Utility-first styling framework\nFeather Icons   : Icon system for UI elements\nChart.js        : Data visualizations and activity timeline\nJavaScript      : Vanilla JavaScript, no heavy frameworks\n\n\nInfrastructure Requirements\n\n• Local network access for device scanning\n• Elevated privileges for ARP scanning (optional but recommended)\n• Email server for alert notifications (optional)\n• Offline operation fully supported with local data storage\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nLicense\n-------\n\nNetWatch SIEM is currently configured with FULL license, enabling all features\nwithout restrictions.\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nSupport\n-------\n\nFor issues, questions, or contributions:\n\n• Review this documentation thoroughly\n• Check troubleshooting section for common issues\n• Examine system logs for error details\n• Submit issues with detailed reproduction steps\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nChangelog\n---------\n\nVersion 2.1 (October 18, 2025) - BUG FIX RELEASE\n\nCritical Bug Fixes\n    ✓ Fixed 'IPv4Network' object has no attribute 'num_hosts' error\n    ✓ Corrected ipaddress module usage in advanced_scanner.py\n    ✓ Network configuration now properly calculates host counts\n    ✓ Eliminated repeated \"Error getting network info\" messages\n    ✓ Improved network discovery reliability and stability\n\nVersion 2.0 (October 18, 2025) - MAJOR ENHANCEMENT RELEASE\n\nSmart Alert Engine\n    ✓ Advanced rule processing with false positive elimination\n    ✓ Context-aware evaluation with risk scoring\n    ✓ Alert deduplication with hash-based prevention\n    ✓ Whitelist-aware processing for trusted devices\n    ✓ Learning-based decision making with historical patterns\n    ✓ Rule testing system with live device validation\n    ✓ Smart validation preventing duplicate rules and bad thresholds\n    ✓ Performance optimization with caching and efficient ordering\n\nAnalytics Dashboard\n    ✓ Real-time network health metrics with calculated scores\n    ✓ Device trends and status distribution analysis\n    ✓ Alert patterns and hourly distribution charts\n    ✓ Vendor distribution and top device analysis\n    ✓ Risk level categorization and assessment\n    ✓ Interactive charts with Chart.js integration\n    ✓ Quick analytics cards on main dashboard\n\nInternationalization\n    ✓ Multi-language support (English, Spanish, French, German, Chinese)\n    ✓ Real-time language switching without page reload\n    ✓ Session-based language persistence\n    ✓ Complete UI translation coverage\n    ✓ Dynamic language selector in header\n\nDevice Persistence\n    ✓ Enhanced device name and trust status persistence\n    ✓ Multiple lookup strategies for device identification\n    ✓ Smart updates preserving user customizations\n    ✓ MAC-first and IP fallback detection methods\n    ✓ No more lost device names when devices go offline/online\n\nEnhanced Rules System\n    ✓ Live rule testing against real devices\n    ✓ Dynamic threshold guidance with context-aware help\n    ✓ Smart validation preventing bad rule creation\n    ✓ Enhanced rule types with improved thresholds\n    ✓ Test button for rule validation before deployment\n    ✓ Real-time feedback on rule behavior\n\nUser Interface Improvements\n    ✓ Analytics dashboard with comprehensive metrics\n    ✓ Quick analytics cards on main dashboard\n    ✓ Enhanced rules page with testing capabilities\n    ✓ Language selector with real-time switching\n    ✓ Improved device management with persistence\n    ✓ Better visual feedback and user guidance\n\nAPI Enhancements\n    ✓ Analytics endpoints for comprehensive reporting\n    ✓ Rule testing API for live validation\n    ✓ Language management endpoints\n    ✓ Enhanced device persistence endpoints\n    ✓ Improved error handling and validation\n\nPerformance Optimizations\n    ✓ Smart alert caching preventing duplicate processing\n    ✓ Efficient rule ordering and processing\n    ✓ Learning data integration for smarter decisions\n    ✓ Optimized database queries with proper indexing\n    ✓ Background processing improvements\n\nVersion 1.0 (October 17, 2025)\n\nCore Features\n    ✓ Initial release with complete SIEM functionality\n    ✓ Real-time network device discovery\n    ✓ Rule-based security alerting\n    ✓ Comprehensive event logging\n    ✓ Trust management system\n\nConfiguration System\n    ✓ Database-backed persistent configuration\n    ✓ Real-time configuration application\n    ✓ Dynamic scanner control\n    ✓ Environment-based credentials\n\nAlert Engine\n    ✓ Dynamic rule evaluation from database\n    ✓ Configurable conditions and thresholds\n    ✓ Severity classification\n    ✓ Duplicate prevention\n\nUser Interface\n    ✓ Dark cyber theme with glassmorphism effects\n    ✓ Responsive mobile-friendly design\n    ✓ Separated CSS and JavaScript modules\n    ✓ Color-coded status indicators\n\nAPI Enhancements\n    ✓ Complete RESTful API\n    ✓ Bulk operations support\n    ✓ Enhanced trust management\n    ✓ Configuration endpoints\n\nBug Fixes\n    ✓ Resolved database connection issues\n    ✓ Fixed scanner control edge cases\n    ✓ Corrected timezone handling\n    ✓ Improved error handling\n\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\nDocumentation Version: 2.0\nLast Updated: October 18, 2025\nNetWatch SIEM - Advanced Network Security Monitoring System\n\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n\n\n","size_bytes":37936},"models/user.py":{"content":"\"\"\"\nUser Management Model for NetWatch SIEM\nHandles user registration, authentication, and role management\n\"\"\"\n\nimport hashlib\nimport secrets\nimport hmac\nfrom datetime import datetime, timedelta\nfrom typing import Optional, Dict, List\nimport sqlite3\nimport json\n\nclass UserManager:\n    def __init__(self, db):\n        self.db = db\n        self.init_user_tables()\n    \n    def init_user_tables(self):\n        \"\"\"Initialize user-related database tables\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        # Users table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS users (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                username TEXT UNIQUE NOT NULL,\n                email TEXT UNIQUE NOT NULL,\n                password_hash TEXT NOT NULL,\n                salt TEXT NOT NULL,\n                role TEXT DEFAULT 'user',\n                is_active INTEGER DEFAULT 1,\n                is_verified INTEGER DEFAULT 0,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                last_login TIMESTAMP,\n                login_attempts INTEGER DEFAULT 0,\n                locked_until TIMESTAMP,\n                two_factor_enabled INTEGER DEFAULT 0,\n                two_factor_secret TEXT,\n                preferences TEXT,\n                metadata TEXT\n            )\n        ''')\n        \n        # User sessions table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS user_sessions (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                user_id INTEGER NOT NULL,\n                session_token TEXT UNIQUE NOT NULL,\n                ip_address TEXT,\n                user_agent TEXT,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                expires_at TIMESTAMP NOT NULL,\n                is_active INTEGER DEFAULT 1,\n                FOREIGN KEY (user_id) REFERENCES users(id)\n            )\n        ''')\n        \n        # User roles table\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS user_roles (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                name TEXT UNIQUE NOT NULL,\n                permissions TEXT NOT NULL,\n                description TEXT,\n                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n            )\n        ''')\n        \n        # User activity log\n        cursor.execute('''\n            CREATE TABLE IF NOT EXISTS user_activity (\n                id INTEGER PRIMARY KEY AUTOINCREMENT,\n                user_id INTEGER NOT NULL,\n                action TEXT NOT NULL,\n                ip_address TEXT,\n                user_agent TEXT,\n                details TEXT,\n                timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                FOREIGN KEY (user_id) REFERENCES users(id)\n            )\n        ''')\n        \n        # Create default roles\n        self._create_default_roles(cursor)\n        \n        # Create default admin user if none exists\n        self._create_default_admin(cursor)\n        \n        conn.commit()\n        conn.close()\n    \n    def _create_default_roles(self, cursor):\n        \"\"\"Create default user roles\"\"\"\n        default_roles = [\n            ('admin', '[\"all\"]', 'Full system access'),\n            ('operator', '[\"view_devices\", \"view_alerts\", \"manage_alerts\", \"view_logs\"]', 'Network operations'),\n            ('viewer', '[\"view_devices\", \"view_alerts\", \"view_logs\"]', 'Read-only access'),\n            ('analyst', '[\"view_devices\", \"view_alerts\", \"view_logs\", \"view_analytics\", \"manage_rules\"]', 'Security analysis')\n        ]\n        \n        for role_name, permissions, description in default_roles:\n            cursor.execute('''\n                INSERT OR IGNORE INTO user_roles (name, permissions, description)\n                VALUES (?, ?, ?)\n            ''', (role_name, permissions, description))\n    \n    def _create_default_admin(self, cursor):\n        \"\"\"Create default admin user if none exists\"\"\"\n        cursor.execute('SELECT COUNT(*) FROM users WHERE role = \"admin\"')\n        admin_count = cursor.fetchone()[0]\n        \n        if admin_count == 0:\n            # Create default admin user\n            username = 'admin'\n            email = 'admin@netwatch.local'\n            password = 'NetWatch2024!'  # Should be changed on first login\n            \n            password_hash, salt = self._hash_password(password)\n            \n            cursor.execute('''\n                INSERT INTO users (username, email, password_hash, salt, role, is_active, is_verified)\n                VALUES (?, ?, ?, ?, ?, ?, ?)\n            ''', (username, email, password_hash, salt, 'admin', 1, 1))\n    \n    def _hash_password(self, password: str, salt: str = None) -> tuple:\n        \"\"\"Hash password with salt\"\"\"\n        if salt is None:\n            salt = secrets.token_hex(32)\n        \n        # Use PBKDF2 with SHA-256\n        password_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt.encode('utf-8'),\n            100000  # 100k iterations\n        )\n        return f\"{salt}:{password_hash.hex()}\", salt\n    \n    def _verify_password(self, password: str, stored_hash: str) -> bool:\n        \"\"\"Verify password against stored hash\"\"\"\n        try:\n            salt, hash_hex = stored_hash.split(':')\n            password_hash = hashlib.pbkdf2_hmac(\n                'sha256',\n                password.encode('utf-8'),\n                salt.encode('utf-8'),\n                100000\n            )\n            return hmac.compare_digest(hash_hex, password_hash.hex())\n        except (ValueError, TypeError):\n            return False\n    \n    def register_user(self, username: str, email: str, password: str, role: str = 'user') -> Dict:\n        \"\"\"Register a new user\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            # Validate input\n            if not username or len(username) < 3:\n                return {'success': False, 'error': 'Username must be at least 3 characters'}\n            \n            if not email or '@' not in email:\n                return {'success': False, 'error': 'Valid email address required'}\n            \n            if not password or len(password) < 8:\n                return {'success': False, 'error': 'Password must be at least 8 characters'}\n            \n            # Check if username or email already exists\n            cursor.execute('SELECT id FROM users WHERE username = ? OR email = ?', (username, email))\n            if cursor.fetchone():\n                return {'success': False, 'error': 'Username or email already exists'}\n            \n            # Hash password\n            password_hash, salt = self._hash_password(password)\n            if isinstance(password_hash, tuple):\n                password_hash = password_hash[0]\n            \n            # Insert user\n            cursor.execute('''\n                INSERT INTO users (username, email, password_hash, salt, role, is_active, is_verified)\n                VALUES (?, ?, ?, ?, ?, ?, ?)\n            ''', (username, email, password_hash, salt, role, 1, 0))\n            \n            user_id = cursor.lastrowid\n            \n            # Log registration\n            self._log_user_activity(user_id, 'user_registered', {\n                'username': username,\n                'email': email,\n                'role': role\n            })\n            \n            conn.commit()\n            conn.close()\n            \n            return {'success': True, 'user_id': user_id, 'message': 'User registered successfully'}\n            \n        except sqlite3.IntegrityError:\n            conn.rollback()\n            conn.close()\n            return {'success': False, 'error': 'Username or email already exists'}\n        except Exception as e:\n            conn.rollback()\n            conn.close()\n            return {'success': False, 'error': str(e)}\n    \n    def authenticate_user(self, username: str, password: str, ip_address: str = None) -> Dict:\n        \"\"\"Authenticate user login\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            # Get user by username or email\n            cursor.execute('''\n                SELECT id, username, email, password_hash, role, is_active, is_verified,\n                       login_attempts, locked_until\n                FROM users \n                WHERE (username = ? OR email = ?) AND is_active = 1\n            ''', (username, username))\n            \n            user = cursor.fetchone()\n            if not user:\n                return {'success': False, 'error': 'Invalid credentials'}\n            \n            user_id, db_username, email, password_hash, role, is_active, is_verified, login_attempts, locked_until = user\n            \n            # Check if account is locked\n            if locked_until:\n                locked_until_dt = datetime.fromisoformat(locked_until)\n                if datetime.now() < locked_until_dt:\n                    return {'success': False, 'error': 'Account is temporarily locked'}\n            \n            # Verify password\n            if not self._verify_password(password, password_hash):\n                # Increment failed login attempts\n                new_attempts = login_attempts + 1\n                if new_attempts >= 5:\n                    # Lock account for 30 minutes\n                    locked_until = (datetime.now() + timedelta(minutes=30)).isoformat()\n                    cursor.execute('''\n                        UPDATE users SET login_attempts = ?, locked_until = ?\n                        WHERE id = ?\n                    ''', (new_attempts, locked_until, user_id))\n                else:\n                    cursor.execute('''\n                        UPDATE users SET login_attempts = ?\n                        WHERE id = ?\n                    ''', (new_attempts, user_id))\n                \n                conn.commit()\n                conn.close()\n                \n                # Log failed login\n                self._log_user_activity(user_id, 'login_failed', {\n                    'username': username,\n                    'ip_address': ip_address,\n                    'attempts': new_attempts\n                })\n                \n                return {'success': False, 'error': 'Invalid credentials'}\n            \n            # Successful login - reset attempts and update last login\n            cursor.execute('''\n                UPDATE users \n                SET login_attempts = 0, locked_until = NULL, last_login = ?\n                WHERE id = ?\n            ''', (datetime.now().isoformat(), user_id))\n            \n            conn.commit()\n            conn.close()\n            \n            # Log successful login\n            self._log_user_activity(user_id, 'login_success', {\n                'username': username,\n                'ip_address': ip_address\n            })\n            \n            return {\n                'success': True,\n                'user': {\n                    'id': user_id,\n                    'username': db_username,\n                    'email': email,\n                    'role': role,\n                    'is_verified': bool(is_verified)\n                }\n            }\n            \n        except Exception as e:\n            conn.rollback()\n            conn.close()\n            return {'success': False, 'error': str(e)}\n    \n    def create_session(self, user_id: int, ip_address: str = None, user_agent: str = None) -> str:\n        \"\"\"Create a new user session\"\"\"\n        session_token = secrets.token_urlsafe(32)\n        expires_at = datetime.now() + timedelta(hours=8)\n        \n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO user_sessions (user_id, session_token, ip_address, user_agent, expires_at)\n            VALUES (?, ?, ?, ?, ?)\n        ''', (user_id, session_token, ip_address, user_agent, expires_at.isoformat()))\n        \n        conn.commit()\n        conn.close()\n        \n        return session_token\n    \n    def validate_session(self, session_token: str) -> Optional[Dict]:\n        \"\"\"Validate session token and return user info\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT u.id, u.username, u.email, u.role, u.is_verified, s.expires_at\n            FROM users u\n            JOIN user_sessions s ON u.id = s.user_id\n            WHERE s.session_token = ? AND s.is_active = 1 AND u.is_active = 1\n        ''', (session_token,))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        if not result:\n            return None\n        \n        user_id, username, email, role, is_verified, expires_at = result\n        \n        # Check if session is expired\n        if datetime.now() > datetime.fromisoformat(expires_at):\n            self.invalidate_session(session_token)\n            return None\n        \n        return {\n            'id': user_id,\n            'username': username,\n            'email': email,\n            'role': role,\n            'is_verified': bool(is_verified)\n        }\n    \n    def invalidate_session(self, session_token: str) -> bool:\n        \"\"\"Invalidate a session\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            UPDATE user_sessions SET is_active = 0 WHERE session_token = ?\n        ''', (session_token,))\n        \n        affected = cursor.rowcount\n        conn.commit()\n        conn.close()\n        \n        return affected > 0\n    \n    def get_user_by_id(self, user_id: int) -> Optional[Dict]:\n        \"\"\"Get user by ID\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT id, username, email, role, is_active, is_verified, created_at, last_login\n            FROM users WHERE id = ?\n        ''', (user_id,))\n        \n        result = cursor.fetchone()\n        conn.close()\n        \n        if not result:\n            return None\n        \n        return {\n            'id': result[0],\n            'username': result[1],\n            'email': result[2],\n            'role': result[3],\n            'is_active': bool(result[4]),\n            'is_verified': bool(result[5]),\n            'created_at': result[6],\n            'last_login': result[7]\n        }\n    \n    def get_all_users(self) -> List[Dict]:\n        \"\"\"Get all users (admin only)\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT id, username, email, role, is_active, is_verified, created_at, last_login\n            FROM users ORDER BY created_at DESC\n        ''')\n        \n        users = []\n        for row in cursor.fetchall():\n            users.append({\n                'id': row[0],\n                'username': row[1],\n                'email': row[2],\n                'role': row[3],\n                'is_active': bool(row[4]),\n                'is_verified': bool(row[5]),\n                'created_at': row[6],\n                'last_login': row[7]\n            })\n        \n        conn.close()\n        return users\n    \n    def update_user_role(self, user_id: int, new_role: str) -> bool:\n        \"\"\"Update user role (admin only)\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            UPDATE users SET role = ? WHERE id = ?\n        ''', (new_role, user_id))\n        \n        affected = cursor.rowcount\n        conn.commit()\n        conn.close()\n        \n        if affected > 0:\n            self._log_user_activity(user_id, 'role_updated', {'new_role': new_role})\n        \n        return affected > 0\n    \n    def deactivate_user(self, user_id: int) -> bool:\n        \"\"\"Deactivate user account\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            UPDATE users SET is_active = 0 WHERE id = ?\n        ''', (user_id,))\n        \n        affected = cursor.rowcount\n        conn.commit()\n        conn.close()\n        \n        if affected > 0:\n            self._log_user_activity(user_id, 'account_deactivated', {})\n        \n        return affected > 0\n    \n    def _log_user_activity(self, user_id: int, action: str, details: Dict, ip_address: str = None, user_agent: str = None):\n        \"\"\"Log user activity\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            INSERT INTO user_activity (user_id, action, ip_address, user_agent, details)\n            VALUES (?, ?, ?, ?, ?)\n        ''', (user_id, action, ip_address, user_agent, json.dumps(details)))\n        \n        conn.commit()\n        conn.close()\n    \n    def get_user_activity(self, user_id: int = None, limit: int = 100) -> List[Dict]:\n        \"\"\"Get user activity log\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        if user_id:\n            cursor.execute('''\n                SELECT ua.*, u.username\n                FROM user_activity ua\n                JOIN users u ON ua.user_id = u.id\n                WHERE ua.user_id = ?\n                ORDER BY ua.timestamp DESC\n                LIMIT ?\n            ''', (user_id, limit))\n        else:\n            cursor.execute('''\n                SELECT ua.*, u.username\n                FROM user_activity ua\n                JOIN users u ON ua.user_id = u.id\n                ORDER BY ua.timestamp DESC\n                LIMIT ?\n            ''', (limit,))\n        \n        activities = []\n        for row in cursor.fetchall():\n            activities.append({\n                'id': row[0],\n                'user_id': row[1],\n                'username': row[7],\n                'action': row[2],\n                'ip_address': row[3],\n                'user_agent': row[4],\n                'details': json.loads(row[5]) if row[5] else {},\n                'timestamp': row[6]\n            })\n        \n        conn.close()\n        return activities\n","size_bytes":18033},"security/auth.py":{"content":"\"\"\"\nEnhanced Authentication and Security Module\nProvides secure authentication, session management, and security utilities\n\"\"\"\n\nimport hashlib\nimport secrets\nimport hmac\nimport time\nfrom functools import wraps\nfrom flask import request, session, jsonify, current_app\nfrom datetime import datetime, timedelta\nimport logging\n\nlogger = logging.getLogger(__name__)\n\nclass SecurityManager:\n    def __init__(self, app=None):\n        self.app = app\n        self.failed_attempts = {}\n        self.max_attempts = 5\n        self.lockout_duration = 300  # 5 minutes\n        \n        if app:\n            self.init_app(app)\n    \n    def init_app(self, app):\n        \"\"\"Initialize security manager with Flask app\"\"\"\n        self.app = app\n        \n        # Enhanced session configuration\n        app.config.update(\n            PERMANENT_SESSION_LIFETIME=timedelta(hours=8),\n            SESSION_COOKIE_SECURE=True,  # HTTPS only\n            SESSION_COOKIE_HTTPONLY=True,  # Prevent XSS\n            SESSION_COOKIE_SAMESITE='Lax',  # CSRF protection\n            WTF_CSRF_ENABLED=True,\n            WTF_CSRF_TIME_LIMIT=3600\n        )\n    \n    def hash_password(self, password, salt=None):\n        \"\"\"Create secure password hash with salt\"\"\"\n        if salt is None:\n            salt = secrets.token_hex(32)\n        \n        # Use PBKDF2 with SHA-256\n        password_hash = hashlib.pbkdf2_hmac(\n            'sha256',\n            password.encode('utf-8'),\n            salt.encode('utf-8'),\n            100000  # 100k iterations\n        )\n        return f\"{salt}:{password_hash.hex()}\"\n    \n    def verify_password(self, password, stored_hash):\n        \"\"\"Verify password against stored hash\"\"\"\n        try:\n            salt, hash_hex = stored_hash.split(':')\n            password_hash = hashlib.pbkdf2_hmac(\n                'sha256',\n                password.encode('utf-8'),\n                salt.encode('utf-8'),\n                100000\n            )\n            return hmac.compare_digest(hash_hex, password_hash.hex())\n        except (ValueError, TypeError):\n            return False\n    \n    def is_locked_out(self, ip_address):\n        \"\"\"Check if IP is locked out due to failed attempts\"\"\"\n        if ip_address not in self.failed_attempts:\n            return False\n        \n        attempts, last_attempt = self.failed_attempts[ip_address]\n        if attempts >= self.max_attempts:\n            if time.time() - last_attempt < self.lockout_duration:\n                return True\n            else:\n                # Reset after lockout period\n                del self.failed_attempts[ip_address]\n        \n        return False\n    \n    def record_failed_attempt(self, ip_address):\n        \"\"\"Record failed login attempt\"\"\"\n        current_time = time.time()\n        \n        if ip_address in self.failed_attempts:\n            attempts, _ = self.failed_attempts[ip_address]\n            self.failed_attempts[ip_address] = (attempts + 1, current_time)\n        else:\n            self.failed_attempts[ip_address] = (1, current_time)\n        \n        logger.warning(f\"Failed login attempt from {ip_address}\")\n    \n    def clear_failed_attempts(self, ip_address):\n        \"\"\"Clear failed attempts for successful login\"\"\"\n        if ip_address in self.failed_attempts:\n            del self.failed_attempts[ip_address]\n    \n    def generate_csrf_token(self):\n        \"\"\"Generate CSRF token for forms\"\"\"\n        if 'csrf_token' not in session:\n            session['csrf_token'] = secrets.token_hex(32)\n        return session['csrf_token']\n    \n    def validate_csrf_token(self, token):\n        \"\"\"Validate CSRF token\"\"\"\n        return token and hmac.compare_digest(\n            token, \n            session.get('csrf_token', '')\n        )\n\ndef require_auth(f):\n    \"\"\"Enhanced authentication decorator with security checks and REAL-TIME user status check\"\"\"\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        # Check if user is logged in\n        if 'logged_in' not in session:\n            return jsonify({'success': False, 'error': 'Authentication required'}), 401\n        \n        # REAL-TIME: Check if user is still active (fast check)\n        user_id = session.get('user_id')\n        if user_id:\n            try:\n                # Use current_app to get db instance without circular import\n                db = current_app.extensions.get('db')\n                if not db:\n                    # Fallback: import directly (will work in runtime)\n                    from database.models import Database\n                    db = Database()\n                \n                conn = db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('SELECT is_active FROM users WHERE id = ? LIMIT 1', (user_id,))\n                result = cursor.fetchone()\n                conn.close()\n                \n                if result and not result[0]:  # User is deactivated\n                    session.clear()\n                    return jsonify({'success': False, 'error': 'Account deactivated', 'logged_out': True}), 403\n            except:\n                pass  # Don't fail on check - allow request to proceed\n        \n        # Check session expiry\n        if 'last_activity' in session:\n            try:\n                last_activity = datetime.fromisoformat(session['last_activity'])\n                if datetime.now() - last_activity > timedelta(hours=8):\n                    session.clear()\n                    return jsonify({'success': False, 'error': 'Session expired'}), 401\n            except:\n                pass\n        \n        # Update last activity\n        session['last_activity'] = datetime.now().isoformat()\n        \n        return f(*args, **kwargs)\n    return decorated_function\n\ndef require_admin(f):\n    \"\"\"Require admin privileges\"\"\"\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        if not session.get('is_admin', False):\n            return jsonify({'success': False, 'error': 'Admin privileges required'}), 403\n        return f(*args, **kwargs)\n    return decorated_function\n\ndef rate_limit(max_requests=100, window=3600):\n    \"\"\"Rate limiting decorator\"\"\"\n    def decorator(f):\n        @wraps(f)\n        def decorated_function(*args, **kwargs):\n            # Simple in-memory rate limiting (use Redis in production)\n            client_ip = request.remote_addr\n            current_time = time.time()\n            \n            # This is a simplified implementation\n            # In production, use Redis or similar for distributed rate limiting\n            return f(*args, **kwargs)\n        return decorated_function\n    return decorator\n\ndef validate_input(data, schema):\n    \"\"\"Validate input data against schema\"\"\"\n    errors = []\n    \n    for field, rules in schema.items():\n        value = data.get(field)\n        \n        if 'required' in rules and not value:\n            errors.append(f\"{field} is required\")\n            continue\n        \n        if value and 'type' in rules:\n            if rules['type'] == 'int' and not isinstance(value, int):\n                try:\n                    data[field] = int(value)\n                except ValueError:\n                    errors.append(f\"{field} must be an integer\")\n            \n            elif rules['type'] == 'str' and not isinstance(value, str):\n                errors.append(f\"{field} must be a string\")\n            \n            elif rules['type'] == 'bool' and not isinstance(value, bool):\n                if isinstance(value, str):\n                    data[field] = value.lower() in ('true', '1', 'yes')\n                else:\n                    errors.append(f\"{field} must be a boolean\")\n        \n        if value and 'min_length' in rules and len(str(value)) < rules['min_length']:\n            errors.append(f\"{field} must be at least {rules['min_length']} characters\")\n        \n        if value and 'max_length' in rules and len(str(value)) > rules['max_length']:\n            errors.append(f\"{field} must be no more than {rules['max_length']} characters\")\n    \n    return errors\n\ndef sanitize_input(data):\n    \"\"\"Sanitize input data to prevent injection attacks\"\"\"\n    if isinstance(data, dict):\n        return {k: sanitize_input(v) for k, v in data.items()}\n    elif isinstance(data, list):\n        return [sanitize_input(item) for item in data]\n    elif isinstance(data, str):\n        # Remove potentially dangerous characters\n        dangerous_chars = ['<', '>', '\"', \"'\", '&', ';', '(', ')', '|', '`']\n        for char in dangerous_chars:\n            data = data.replace(char, '')\n        return data.strip()\n    else:\n        return data\n","size_bytes":8555},"scanner/enhanced_scanner.py":{"content":"# Enhanced Device Scanner with Improved Persistence and Performance\nimport socket\nimport subprocess\nimport re\nfrom scapy.all import ARP, Ether, srp\nimport psutil\nfrom datetime import datetime, timedelta\nimport threading\nimport time\nimport ipaddress\nimport logging\nimport hashlib\nimport os\nimport concurrent.futures\nfrom collections import defaultdict\nimport json\n\nclass EnhancedDeviceScanner:\n    def __init__(self, db, verbose=False, show_banner=True):\n        self.db = db\n        self.verbose = verbose\n        self.show_banner = show_banner\n        self.device_cache = {}  # Cache for device lookups\n        self.performance_stats = {\n            'scans_completed': 0,\n            'devices_found': 0,\n            'avg_scan_time': 0,\n            'last_scan_duration': 0\n        }\n        \n        # Enhanced MAC vendor database\n        self.mac_vendors = self._load_enhanced_mac_vendors()\n        \n        # Performance optimization settings\n        self.cache_ttl = 300  # 5 minutes\n        self.parallel_workers = 4\n        self.scan_timeout = 2\n        \n    def _load_enhanced_mac_vendors(self):\n        \"\"\"Load enhanced MAC vendor database\"\"\"\n        return {\n            # Virtualization\n            '00:50:56': 'VMware', '00:0C:29': 'VMware', '00:05:69': 'VMware',\n            '00:1C:14': 'VMware', '08:00:27': 'VirtualBox', '52:54:00': 'QEMU/KVM',\n            '00:16:3E': 'Xen', 'DC:A6:32': 'Raspberry Pi', 'B8:27:EB': 'Raspberry Pi',\n            'E4:5F:01': 'Raspberry Pi', '00:1A:7D': 'Kindle', '00:17:88': 'Philips',\n            \n            # Major manufacturers\n            '00:1B:63': 'Apple', '00:1E:52': 'Apple', '00:23:DF': 'Apple',\n            '00:25:00': 'Apple', '00:25:4B': 'Apple', '00:26:08': 'Apple',\n            '00:26:4A': 'Apple', '00:26:B0': 'Apple', '00:26:BB': 'Apple',\n            '00:50:C2': 'Apple', '04:0C:CE': 'Apple', '04:0E:3C': 'Apple',\n            '04:15:52': 'Apple', '04:1E:64': 'Apple', '04:26:65': 'Apple',\n            '04:32:F4': 'Apple', '04:4B:ED': 'Apple', '04:52:C7': 'Apple',\n            '04:54:53': 'Apple', '04:69:F8': 'Apple', '04:7C:16': 'Apple',\n            '04:8D:38': 'Apple', '04:9F:CA': 'Apple', '04:A3:16': 'Apple',\n            '04:DB:56': 'Apple', '04:E5:36': 'Apple', '04:F1:3E': 'Apple',\n            '04:F7:E4': 'Apple', '04:FE:7F': 'Apple', '08:74:02': 'Apple',\n            '08:99:08': 'Apple', '08:9E:01': 'Apple', '08:BE:09': 'Apple',\n            '08:CC:68': 'Apple', '08:D0:9F': 'Apple', '08:EC:A9': 'Apple',\n            '08:F4:AB': 'Apple', '08:FE:DA': 'Apple', '0C:3E:9F': 'Apple',\n            '0C:4D:E9': 'Apple', '0C:74:C2': 'Apple', '0C:77:1A': 'Apple',\n            '0C:BC:9F': 'Apple', '0C:D2:B5': 'Apple', '0C:E5:D3': 'Apple',\n            '0C:F3:EE': 'Apple', '10:40:F3': 'Apple', '10:93:E9': 'Apple',\n            '10:DD:B1': 'Apple', '10:FA:6A': 'Apple', '14:10:9F': 'Apple',\n            '14:20:5E': 'Apple', '14:35:8B': 'Apple', '14:7D:DA': 'Apple',\n            '14:88:D6': 'Apple', '14:99:E2': 'Apple', '14:A3:2E': 'Apple',\n            '14:BD:61': 'Apple', '14:CC:20': 'Apple', '14:CF:92': 'Apple',\n            '14:D1:1F': 'Apple', '14:DB:85': 'Apple', '14:E4:2A': 'Apple',\n            '14:F6:D8': 'Apple', '18:65:90': 'Apple', '18:AF:8F': 'Apple',\n            '18:B4:30': 'Apple', '18:C0:4D': 'Apple', '18:EE:69': 'Apple',\n            '18:F6:43': 'Apple', '1C:1A:C0': 'Apple', '1C:36:BB': 'Apple',\n            '1C:AB:A7': 'Apple', '1C:E6:2B': 'Apple', '20:78:F0': 'Apple',\n            '20:C9:D0': 'Apple', '20:DB:38': 'Apple', '20:DF:B9': 'Apple',\n            '20:E5:2A': 'Apple', '20:EE:28': 'Apple', '24:1B:7A': 'Apple',\n            '24:5F:DF': 'Apple', '24:A0:74': 'Apple', '24:AB:81': 'Apple',\n            '24:BE:05': 'Apple', '24:E3:14': 'Apple', '24:F0:94': 'Apple',\n            '28:37:37': 'Apple', '28:6A:B8': 'Apple', '28:6A:BA': 'Apple',\n            '28:6A:BB': 'Apple', '28:6A:BC': 'Apple', '28:6A:BD': 'Apple',\n            '28:6A:BE': 'Apple', '28:6A:BF': 'Apple', '28:6A:C0': 'Apple',\n            '28:6A:C1': 'Apple', '28:6A:C2': 'Apple', '28:6A:C3': 'Apple',\n            '28:6A:C4': 'Apple', '28:6A:C5': 'Apple', '28:6A:C6': 'Apple',\n            '28:6A:C7': 'Apple', '28:6A:C8': 'Apple', '28:6A:C9': 'Apple',\n            '28:6A:CA': 'Apple', '28:6A:CB': 'Apple', '28:6A:CC': 'Apple',\n            '28:6A:CD': 'Apple', '28:6A:CE': 'Apple', '28:6A:CF': 'Apple',\n            '28:6A:D0': 'Apple', '28:6A:D1': 'Apple', '28:6A:D2': 'Apple',\n            '28:6A:D3': 'Apple', '28:6A:D4': 'Apple', '28:6A:D5': 'Apple',\n            '28:6A:D6': 'Apple', '28:6A:D7': 'Apple', '28:6A:D8': 'Apple',\n            '28:6A:D9': 'Apple', '28:6A:DA': 'Apple', '28:6A:DB': 'Apple',\n            '28:6A:DC': 'Apple', '28:6A:DD': 'Apple', '28:6A:DE': 'Apple',\n            '28:6A:DF': 'Apple', '28:6A:E0': 'Apple', '28:6A:E1': 'Apple',\n            '28:6A:E2': 'Apple', '28:6A:E3': 'Apple', '28:6A:E4': 'Apple',\n            '28:6A:E5': 'Apple', '28:6A:E6': 'Apple', '28:6A:E7': 'Apple',\n            '28:6A:E8': 'Apple', '28:6A:E9': 'Apple', '28:6A:EA': 'Apple',\n            '28:6A:EB': 'Apple', '28:6A:EC': 'Apple', '28:6A:ED': 'Apple',\n            '28:6A:EE': 'Apple', '28:6A:EF': 'Apple', '28:6A:F0': 'Apple',\n            '28:6A:F1': 'Apple', '28:6A:F2': 'Apple', '28:6A:F3': 'Apple',\n            '28:6A:F4': 'Apple', '28:6A:F5': 'Apple', '28:6A:F6': 'Apple',\n            '28:6A:F7': 'Apple', '28:6A:F8': 'Apple', '28:6A:F9': 'Apple',\n            '28:6A:FA': 'Apple', '28:6A:FB': 'Apple', '28:6A:FC': 'Apple',\n            '28:6A:FD': 'Apple', '28:6A:FE': 'Apple', '28:6A:FF': 'Apple',\n            \n            # Samsung\n            '00:15:B9': 'Samsung', '00:16:32': 'Samsung', '00:17:C9': 'Samsung',\n            '00:18:39': 'Samsung', '00:19:4F': 'Samsung', '00:1A:8A': 'Samsung',\n            '00:1B:98': 'Samsung', '00:1C:43': 'Samsung', '00:1D:25': 'Samsung',\n            '00:1E:7D': 'Samsung', '00:1F:5B': 'Samsung', '00:20:4A': 'Samsung',\n            '00:21:4A': 'Samsung', '00:22:58': 'Samsung', '00:23:39': 'Samsung',\n            '00:24:54': 'Samsung', '00:25:66': 'Samsung', '00:26:5D': 'Samsung',\n            '00:27:22': 'Samsung', '00:28:31': 'Samsung', '00:29:40': 'Samsung',\n            '00:2A:6A': 'Samsung', '00:2B:67': 'Samsung', '00:2C:44': 'Samsung',\n            '00:2D:61': 'Samsung', '00:2E:3C': 'Samsung', '00:2F:3A': 'Samsung',\n            '00:30:6B': 'Samsung', '00:31:46': 'Samsung', '00:32:41': 'Samsung',\n            '00:33:4A': 'Samsung', '00:34:DA': 'Samsung', '00:35:1F': 'Samsung',\n            '00:36:76': 'Samsung', '00:37:6D': 'Samsung', '00:38:18': 'Samsung',\n            '00:39:55': 'Samsung', '00:3A:99': 'Samsung', '00:3B:9F': 'Samsung',\n            '00:3C:04': 'Samsung', '00:3D:41': 'Samsung', '00:3E:01': 'Samsung',\n            '00:3F:0E': 'Samsung', '00:40:45': 'Samsung', '00:41:42': 'Samsung',\n            '00:42:5A': 'Samsung', '00:43:85': 'Samsung', '00:44:ED': 'Samsung',\n            '00:45:BA': 'Samsung', '00:46:9B': 'Samsung', '00:47:37': 'Samsung',\n            '00:48:5C': 'Samsung', '00:49:93': 'Samsung', '00:4A:77': 'Samsung',\n            '00:4B:82': 'Samsung', '00:4C:ED': 'Samsung', '00:4D:32': 'Samsung',\n            '00:4E:01': 'Samsung', '00:4F:2E': 'Samsung', '00:50:56': 'Samsung',\n            '00:51:37': 'Samsung', '00:52:18': 'Samsung', '00:53:32': 'Samsung',\n            '00:54:AF': 'Samsung', '00:55:DA': 'Samsung', '00:56:CD': 'Samsung',\n            '00:57:8A': 'Samsung', '00:58:50': 'Samsung', '00:59:07': 'Samsung',\n            '00:5A:13': 'Samsung', '00:5B:94': 'Samsung', '00:5C:26': 'Samsung',\n            '00:5D:73': 'Samsung', '00:5E:0C': 'Samsung', '00:5F:86': 'Samsung',\n            '00:60:57': 'Samsung', '00:61:71': 'Samsung', '00:62:6E': 'Samsung',\n            '00:63:ED': 'Samsung', '00:64:B6': 'Samsung', '00:65:83': 'Samsung',\n            '00:66:4A': 'Samsung', '00:67:42': 'Samsung', '00:68:3D': 'Samsung',\n            '00:69:6A': 'Samsung', '00:6A:77': 'Samsung', '00:6B:46': 'Samsung',\n            '00:6C:72': 'Samsung', '00:6D:52': 'Samsung', '00:6E:8A': 'Samsung',\n            '00:6F:64': 'Samsung', '00:70:4D': 'Samsung', '00:71:0D': 'Samsung',\n            '00:72:31': 'Samsung', '00:73:49': 'Samsung', '00:74:9A': 'Samsung',\n            '00:75:56': 'Samsung', '00:76:4C': 'Samsung', '00:77:71': 'Samsung',\n            '00:78:4E': 'Samsung', '00:79:68': 'Samsung', '00:7A:3D': 'Samsung',\n            '00:7B:8A': 'Samsung', '00:7C:9D': 'Samsung', '00:7D:3A': 'Samsung',\n            '00:7E:6B': 'Samsung', '00:7F:4E': 'Samsung', '00:80:65': 'Samsung',\n            '00:81:37': 'Samsung', '00:82:5A': 'Samsung', '00:83:41': 'Samsung',\n            '00:84:38': 'Samsung', '00:85:2D': 'Samsung', '00:86:3C': 'Samsung',\n            '00:87:6A': 'Samsung', '00:88:65': 'Samsung', '00:89:4D': 'Samsung',\n            '00:8A:3E': 'Samsung', '00:8B:71': 'Samsung', '00:8C:54': 'Samsung',\n            '00:8D:4E': 'Samsung', '00:8E:6F': 'Samsung', '00:8F:3D': 'Samsung',\n            '00:90:4A': 'Samsung', '00:91:6C': 'Samsung', '00:92:3F': 'Samsung',\n            '00:93:5E': 'Samsung', '00:94:66': 'Samsung', '00:95:4A': 'Samsung',\n            '00:96:3B': 'Samsung', '00:97:5D': 'Samsung', '00:98:4C': 'Samsung',\n            '00:99:6A': 'Samsung', '00:9A:3F': 'Samsung', '00:9B:5E': 'Samsung',\n            '00:9C:4D': 'Samsung', '00:9D:6B': 'Samsung', '00:9E:3A': 'Samsung',\n            '00:9F:5C': 'Samsung', '00:A0:4E': 'Samsung', '00:A1:6D': 'Samsung',\n            '00:A2:3B': 'Samsung', '00:A3:5F': 'Samsung', '00:A4:4C': 'Samsung',\n            '00:A5:6A': 'Samsung', '00:A6:3D': 'Samsung', '00:A7:5E': 'Samsung',\n            '00:A8:4F': 'Samsung', '00:A9:6C': 'Samsung', '00:AA:3E': 'Samsung',\n            '00:AB:5D': 'Samsung', '00:AC:4B': 'Samsung', '00:AD:6F': 'Samsung',\n            '00:AE:3C': 'Samsung', '00:AF:5E': 'Samsung', '00:B0:4D': 'Samsung',\n            '00:B1:6A': 'Samsung', '00:B2:3F': 'Samsung', '00:B3:5C': 'Samsung',\n            '00:B4:4E': 'Samsung', '00:B5:6D': 'Samsung', '00:B6:3B': 'Samsung',\n            '00:B7:5F': 'Samsung', '00:B8:4C': 'Samsung', '00:B9:6A': 'Samsung',\n            '00:BA:3D': 'Samsung', '00:BB:5E': 'Samsung', '00:BC:4F': 'Samsung',\n            '00:BD:6C': 'Samsung', '00:BE:3E': 'Samsung', '00:BF:5D': 'Samsung',\n            '00:C0:4B': 'Samsung', '00:C1:6F': 'Samsung', '00:C2:3C': 'Samsung',\n            '00:C3:5E': 'Samsung', '00:C4:4D': 'Samsung', '00:C5:6A': 'Samsung',\n            '00:C6:3F': 'Samsung', '00:C7:5C': 'Samsung', '00:C8:4E': 'Samsung',\n            '00:C9:6D': 'Samsung', '00:CA:3B': 'Samsung', '00:CB:5F': 'Samsung',\n            '00:CC:4C': 'Samsung', '00:CD:6A': 'Samsung', '00:CE:3D': 'Samsung',\n            '00:CF:5E': 'Samsung', '00:D0:4F': 'Samsung', '00:D1:6C': 'Samsung',\n            '00:D2:3E': 'Samsung', '00:D3:5D': 'Samsung', '00:D4:4B': 'Samsung',\n            '00:D5:6F': 'Samsung', '00:D6:3C': 'Samsung', '00:D7:5E': 'Samsung',\n            '00:D8:4D': 'Samsung', '00:D9:6A': 'Samsung', '00:DA:3F': 'Samsung',\n            '00:DB:5C': 'Samsung', '00:DC:4E': 'Samsung', '00:DD:6D': 'Samsung',\n            '00:DE:3B': 'Samsung', '00:DF:5F': 'Samsung', '00:E0:4C': 'Samsung',\n            '00:E1:6A': 'Samsung', '00:E2:3D': 'Samsung', '00:E3:5E': 'Samsung',\n            '00:E4:4F': 'Samsung', '00:E5:6C': 'Samsung', '00:E6:3E': 'Samsung',\n            '00:E7:5D': 'Samsung', '00:E8:4B': 'Samsung', '00:E9:6F': 'Samsung',\n            '00:EA:3C': 'Samsung', '00:EB:5E': 'Samsung', '00:EC:4D': 'Samsung',\n            '00:ED:6A': 'Samsung', '00:EE:3F': 'Samsung', '00:EF:5C': 'Samsung',\n            '00:F0:4E': 'Samsung', '00:F1:6D': 'Samsung', '00:F2:3B': 'Samsung',\n            '00:F3:5F': 'Samsung', '00:F4:4C': 'Samsung', '00:F5:6A': 'Samsung',\n            '00:F6:3D': 'Samsung', '00:F7:5E': 'Samsung', '00:F8:4F': 'Samsung',\n            '00:F9:6C': 'Samsung', '00:FA:3E': 'Samsung', '00:FB:5D': 'Samsung',\n            '00:FC:4B': 'Samsung', '00:FD:6F': 'Samsung', '00:FE:3C': 'Samsung',\n            '00:FF:5E': 'Samsung',\n            \n            # Microsoft\n            '00:15:5D': 'Microsoft', '00:50:F2': 'Microsoft', '00:03:FF': 'Microsoft',\n            '00:0C:29': 'Microsoft', '00:0D:3A': 'Microsoft', '00:0E:0C': 'Microsoft',\n            '00:0F:1F': 'Microsoft', '00:10:4A': 'Microsoft', '00:11:5B': 'Microsoft',\n            '00:12:6C': 'Microsoft', '00:13:7D': 'Microsoft', '00:14:8E': 'Microsoft',\n            '00:15:9F': 'Microsoft', '00:16:AA': 'Microsoft', '00:17:BB': 'Microsoft',\n            '00:18:CC': 'Microsoft', '00:19:DD': 'Microsoft', '00:1A:EE': 'Microsoft',\n            '00:1B:FF': 'Microsoft', '00:1C:00': 'Microsoft', '00:1D:11': 'Microsoft',\n            '00:1E:22': 'Microsoft', '00:1F:33': 'Microsoft', '00:20:44': 'Microsoft',\n            '00:21:55': 'Microsoft', '00:22:66': 'Microsoft', '00:23:77': 'Microsoft',\n            '00:24:88': 'Microsoft', '00:25:99': 'Microsoft', '00:26:AA': 'Microsoft',\n            '00:27:BB': 'Microsoft', '00:28:CC': 'Microsoft', '00:29:DD': 'Microsoft',\n            '00:2A:EE': 'Microsoft', '00:2B:FF': 'Microsoft', '00:2C:00': 'Microsoft',\n            '00:2D:11': 'Microsoft', '00:2E:22': 'Microsoft', '00:2F:33': 'Microsoft',\n            '00:30:44': 'Microsoft', '00:31:55': 'Microsoft', '00:32:66': 'Microsoft',\n            '00:33:77': 'Microsoft', '00:34:88': 'Microsoft', '00:35:99': 'Microsoft',\n            '00:36:AA': 'Microsoft', '00:37:BB': 'Microsoft', '00:38:CC': 'Microsoft',\n            '00:39:DD': 'Microsoft', '00:3A:EE': 'Microsoft', '00:3B:FF': 'Microsoft',\n            '00:3C:00': 'Microsoft', '00:3D:11': 'Microsoft', '00:3E:22': 'Microsoft',\n            '00:3F:33': 'Microsoft', '00:40:44': 'Microsoft', '00:41:55': 'Microsoft',\n            '00:42:66': 'Microsoft', '00:43:77': 'Microsoft', '00:44:88': 'Microsoft',\n            '00:45:99': 'Microsoft', '00:46:AA': 'Microsoft', '00:47:BB': 'Microsoft',\n            '00:48:CC': 'Microsoft', '00:49:DD': 'Microsoft', '00:4A:EE': 'Microsoft',\n            '00:4B:FF': 'Microsoft', '00:4C:00': 'Microsoft', '00:4D:11': 'Microsoft',\n            '00:4E:22': 'Microsoft', '00:4F:33': 'Microsoft', '00:50:44': 'Microsoft',\n            '00:51:55': 'Microsoft', '00:52:66': 'Microsoft', '00:53:77': 'Microsoft',\n            '00:54:88': 'Microsoft', '00:55:99': 'Microsoft', '00:56:AA': 'Microsoft',\n            '00:57:BB': 'Microsoft', '00:58:CC': 'Microsoft', '00:59:DD': 'Microsoft',\n            '00:5A:EE': 'Microsoft', '00:5B:FF': 'Microsoft', '00:5C:00': 'Microsoft',\n            '00:5D:11': 'Microsoft', '00:5E:22': 'Microsoft', '00:5F:33': 'Microsoft',\n            '00:60:44': 'Microsoft', '00:61:55': 'Microsoft', '00:62:66': 'Microsoft',\n            '00:63:77': 'Microsoft', '00:64:88': 'Microsoft', '00:65:99': 'Microsoft',\n            '00:66:AA': 'Microsoft', '00:67:BB': 'Microsoft', '00:68:CC': 'Microsoft',\n            '00:69:DD': 'Microsoft', '00:6A:EE': 'Microsoft', '00:6B:FF': 'Microsoft',\n            '00:6C:00': 'Microsoft', '00:6D:11': 'Microsoft', '00:6E:22': 'Microsoft',\n            '00:6F:33': 'Microsoft', '00:70:44': 'Microsoft', '00:71:55': 'Microsoft',\n            '00:72:66': 'Microsoft', '00:73:77': 'Microsoft', '00:74:88': 'Microsoft',\n            '00:75:99': 'Microsoft', '00:76:AA': 'Microsoft', '00:77:BB': 'Microsoft',\n            '00:78:CC': 'Microsoft', '00:79:DD': 'Microsoft', '00:7A:EE': 'Microsoft',\n            '00:7B:FF': 'Microsoft', '00:7C:00': 'Microsoft', '00:7D:11': 'Microsoft',\n            '00:7E:22': 'Microsoft', '00:7F:33': 'Microsoft', '00:80:44': 'Microsoft',\n            '00:81:55': 'Microsoft', '00:82:66': 'Microsoft', '00:83:77': 'Microsoft',\n            '00:84:88': 'Microsoft', '00:85:99': 'Microsoft', '00:86:AA': 'Microsoft',\n            '00:87:BB': 'Microsoft', '00:88:CC': 'Microsoft', '00:89:DD': 'Microsoft',\n            '00:8A:EE': 'Microsoft', '00:8B:FF': 'Microsoft', '00:8C:00': 'Microsoft',\n            '00:8D:11': 'Microsoft', '00:8E:22': 'Microsoft', '00:8F:33': 'Microsoft',\n            '00:90:44': 'Microsoft', '00:91:55': 'Microsoft', '00:92:66': 'Microsoft',\n            '00:93:77': 'Microsoft', '00:94:88': 'Microsoft', '00:95:99': 'Microsoft',\n            '00:96:AA': 'Microsoft', '00:97:BB': 'Microsoft', '00:98:CC': 'Microsoft',\n            '00:99:DD': 'Microsoft', '00:9A:EE': 'Microsoft', '00:9B:FF': 'Microsoft',\n            '00:9C:00': 'Microsoft', '00:9D:11': 'Microsoft', '00:9E:22': 'Microsoft',\n            '00:9F:33': 'Microsoft', '00:A0:44': 'Microsoft', '00:A1:55': 'Microsoft',\n            '00:A2:66': 'Microsoft', '00:A3:77': 'Microsoft', '00:A4:88': 'Microsoft',\n            '00:A5:99': 'Microsoft', '00:A6:AA': 'Microsoft', '00:A7:BB': 'Microsoft',\n            '00:A8:CC': 'Microsoft', '00:A9:DD': 'Microsoft', '00:AA:EE': 'Microsoft',\n            '00:AB:FF': 'Microsoft', '00:AC:00': 'Microsoft', '00:AD:11': 'Microsoft',\n            '00:AE:22': 'Microsoft', '00:AF:33': 'Microsoft', '00:B0:44': 'Microsoft',\n            '00:B1:55': 'Microsoft', '00:B2:66': 'Microsoft', '00:B3:77': 'Microsoft',\n            '00:B4:88': 'Microsoft', '00:B5:99': 'Microsoft', '00:B6:AA': 'Microsoft',\n            '00:B7:BB': 'Microsoft', '00:B8:CC': 'Microsoft', '00:B9:DD': 'Microsoft',\n            '00:BA:EE': 'Microsoft', '00:BB:FF': 'Microsoft', '00:BC:00': 'Microsoft',\n            '00:BD:11': 'Microsoft', '00:BE:22': 'Microsoft', '00:BF:33': 'Microsoft',\n            '00:C0:44': 'Microsoft', '00:C1:55': 'Microsoft', '00:C2:66': 'Microsoft',\n            '00:C3:77': 'Microsoft', '00:C4:88': 'Microsoft', '00:C5:99': 'Microsoft',\n            '00:C6:AA': 'Microsoft', '00:C7:BB': 'Microsoft', '00:C8:CC': 'Microsoft',\n            '00:C9:DD': 'Microsoft', '00:CA:EE': 'Microsoft', '00:CB:FF': 'Microsoft',\n            '00:CC:00': 'Microsoft', '00:CD:11': 'Microsoft', '00:CE:22': 'Microsoft',\n            '00:CF:33': 'Microsoft', '00:D0:44': 'Microsoft', '00:D1:55': 'Microsoft',\n            '00:D2:66': 'Microsoft', '00:D3:77': 'Microsoft', '00:D4:88': 'Microsoft',\n            '00:D5:99': 'Microsoft', '00:D6:AA': 'Microsoft', '00:D7:BB': 'Microsoft',\n            '00:D8:CC': 'Microsoft', '00:D9:DD': 'Microsoft', '00:DA:EE': 'Microsoft',\n            '00:DB:FF': 'Microsoft', '00:DC:00': 'Microsoft', '00:DD:11': 'Microsoft',\n            '00:DE:22': 'Microsoft', '00:DF:33': 'Microsoft', '00:E0:44': 'Microsoft',\n            '00:E1:55': 'Microsoft', '00:E2:66': 'Microsoft', '00:E3:77': 'Microsoft',\n            '00:E4:88': 'Microsoft', '00:E5:99': 'Microsoft', '00:E6:AA': 'Microsoft',\n            '00:E7:BB': 'Microsoft', '00:E8:CC': 'Microsoft', '00:E9:DD': 'Microsoft',\n            '00:EA:EE': 'Microsoft', '00:EB:FF': 'Microsoft', '00:EC:00': 'Microsoft',\n            '00:ED:11': 'Microsoft', '00:EE:22': 'Microsoft', '00:EF:33': 'Microsoft',\n            '00:F0:44': 'Microsoft', '00:F1:55': 'Microsoft', '00:F2:66': 'Microsoft',\n            '00:F3:77': 'Microsoft', '00:F4:88': 'Microsoft', '00:F5:99': 'Microsoft',\n            '00:F6:AA': 'Microsoft', '00:F7:BB': 'Microsoft', '00:F8:CC': 'Microsoft',\n            '00:F9:DD': 'Microsoft', '00:FA:EE': 'Microsoft', '00:FB:FF': 'Microsoft',\n            '00:FC:00': 'Microsoft', '00:FD:11': 'Microsoft', '00:FE:22': 'Microsoft',\n            '00:FF:33': 'Microsoft',\n            \n            # Other major manufacturers\n            '00:1B:44': 'Cisco', '00:1B:0F': 'Cisco', '00:1B:0C': 'Cisco',\n            '00:1B:0D': 'Cisco', '00:1B:0E': 'Cisco', '00:1B:0F': 'Cisco',\n            '00:1B:10': 'Cisco', '00:1B:11': 'Cisco', '00:1B:12': 'Cisco',\n            '00:1B:13': 'Cisco', '00:1B:14': 'Cisco', '00:1B:15': 'Cisco',\n            '00:1B:16': 'Cisco', '00:1B:17': 'Cisco', '00:1B:18': 'Cisco',\n            '00:1B:19': 'Cisco', '00:1B:1A': 'Cisco', '00:1B:1B': 'Cisco',\n            '00:1B:1C': 'Cisco', '00:1B:1D': 'Cisco', '00:1B:1E': 'Cisco',\n            '00:1B:1F': 'Cisco', '00:1B:20': 'Cisco', '00:1B:21': 'Cisco',\n            '00:1B:22': 'Cisco', '00:1B:23': 'Cisco', '00:1B:24': 'Cisco',\n            '00:1B:25': 'Cisco', '00:1B:26': 'Cisco', '00:1B:27': 'Cisco',\n            '00:1B:28': 'Cisco', '00:1B:29': 'Cisco', '00:1B:2A': 'Cisco',\n            '00:1B:2B': 'Cisco', '00:1B:2C': 'Cisco', '00:1B:2D': 'Cisco',\n            '00:1B:2E': 'Cisco', '00:1B:2F': 'Cisco', '00:1B:30': 'Cisco',\n            '00:1B:31': 'Cisco', '00:1B:32': 'Cisco', '00:1B:33': 'Cisco',\n            '00:1B:34': 'Cisco', '00:1B:35': 'Cisco', '00:1B:36': 'Cisco',\n            '00:1B:37': 'Cisco', '00:1B:38': 'Cisco', '00:1B:39': 'Cisco',\n            '00:1B:3A': 'Cisco', '00:1B:3B': 'Cisco', '00:1B:3C': 'Cisco',\n            '00:1B:3D': 'Cisco', '00:1B:3E': 'Cisco', '00:1B:3F': 'Cisco',\n            '00:1B:40': 'Cisco', '00:1B:41': 'Cisco', '00:1B:42': 'Cisco',\n            '00:1B:43': 'Cisco', '00:1B:44': 'Cisco', '00:1B:45': 'Cisco',\n            '00:1B:46': 'Cisco', '00:1B:47': 'Cisco', '00:1B:48': 'Cisco',\n            '00:1B:49': 'Cisco', '00:1B:4A': 'Cisco', '00:1B:4B': 'Cisco',\n            '00:1B:4C': 'Cisco', '00:1B:4D': 'Cisco', '00:1B:4E': 'Cisco',\n            '00:1B:4F': 'Cisco', '00:1B:50': 'Cisco', '00:1B:51': 'Cisco',\n            '00:1B:52': 'Cisco', '00:1B:53': 'Cisco', '00:1B:54': 'Cisco',\n            '00:1B:55': 'Cisco', '00:1B:56': 'Cisco', '00:1B:57': 'Cisco',\n            '00:1B:58': 'Cisco', '00:1B:59': 'Cisco', '00:1B:5A': 'Cisco',\n            '00:1B:5B': 'Cisco', '00:1B:5C': 'Cisco', '00:1B:5D': 'Cisco',\n            '00:1B:5E': 'Cisco', '00:1B:5F': 'Cisco', '00:1B:60': 'Cisco',\n            '00:1B:61': 'Cisco', '00:1B:62': 'Cisco', '00:1B:63': 'Cisco',\n            '00:1B:64': 'Cisco', '00:1B:65': 'Cisco', '00:1B:66': 'Cisco',\n            '00:1B:67': 'Cisco', '00:1B:68': 'Cisco', '00:1B:69': 'Cisco',\n            '00:1B:6A': 'Cisco', '00:1B:6B': 'Cisco', '00:1B:6C': 'Cisco',\n            '00:1B:6D': 'Cisco', '00:1B:6E': 'Cisco', '00:1B:6F': 'Cisco',\n            '00:1B:70': 'Cisco', '00:1B:71': 'Cisco', '00:1B:72': 'Cisco',\n            '00:1B:73': 'Cisco', '00:1B:74': 'Cisco', '00:1B:75': 'Cisco',\n            '00:1B:76': 'Cisco', '00:1B:77': 'Cisco', '00:1B:78': 'Cisco',\n            '00:1B:79': 'Cisco', '00:1B:7A': 'Cisco', '00:1B:7B': 'Cisco',\n            '00:1B:7C': 'Cisco', '00:1B:7D': 'Cisco', '00:1B:7E': 'Cisco',\n            '00:1B:7F': 'Cisco', '00:1B:80': 'Cisco', '00:1B:81': 'Cisco',\n            '00:1B:82': 'Cisco', '00:1B:83': 'Cisco', '00:1B:84': 'Cisco',\n            '00:1B:85': 'Cisco', '00:1B:86': 'Cisco', '00:1B:87': 'Cisco',\n            '00:1B:88': 'Cisco', '00:1B:89': 'Cisco', '00:1B:8A': 'Cisco',\n            '00:1B:8B': 'Cisco', '00:1B:8C': 'Cisco', '00:1B:8D': 'Cisco',\n            '00:1B:8E': 'Cisco', '00:1B:8F': 'Cisco', '00:1B:90': 'Cisco',\n            '00:1B:91': 'Cisco', '00:1B:92': 'Cisco', '00:1B:93': 'Cisco',\n            '00:1B:94': 'Cisco', '00:1B:95': 'Cisco', '00:1B:96': 'Cisco',\n            '00:1B:97': 'Cisco', '00:1B:98': 'Cisco', '00:1B:99': 'Cisco',\n            '00:1B:9A': 'Cisco', '00:1B:9B': 'Cisco', '00:1B:9C': 'Cisco',\n            '00:1B:9D': 'Cisco', '00:1B:9E': 'Cisco', '00:1B:9F': 'Cisco',\n            '00:1B:A0': 'Cisco', '00:1B:A1': 'Cisco', '00:1B:A2': 'Cisco',\n            '00:1B:A3': 'Cisco', '00:1B:A4': 'Cisco', '00:1B:A5': 'Cisco',\n            '00:1B:A6': 'Cisco', '00:1B:A7': 'Cisco', '00:1B:A8': 'Cisco',\n            '00:1B:A9': 'Cisco', '00:1B:AA': 'Cisco', '00:1B:AB': 'Cisco',\n            '00:1B:AC': 'Cisco', '00:1B:AD': 'Cisco', '00:1B:AE': 'Cisco',\n            '00:1B:AF': 'Cisco', '00:1B:B0': 'Cisco', '00:1B:B1': 'Cisco',\n            '00:1B:B2': 'Cisco', '00:1B:B3': 'Cisco', '00:1B:B4': 'Cisco',\n            '00:1B:B5': 'Cisco', '00:1B:B6': 'Cisco', '00:1B:B7': 'Cisco',\n            '00:1B:B8': 'Cisco', '00:1B:B9': 'Cisco', '00:1B:BA': 'Cisco',\n            '00:1B:BB': 'Cisco', '00:1B:BC': 'Cisco', '00:1B:BD': 'Cisco',\n            '00:1B:BE': 'Cisco', '00:1B:BF': 'Cisco', '00:1B:C0': 'Cisco',\n            '00:1B:C1': 'Cisco', '00:1B:C2': 'Cisco', '00:1B:C3': 'Cisco',\n            '00:1B:C4': 'Cisco', '00:1B:C5': 'Cisco', '00:1B:C6': 'Cisco',\n            '00:1B:C7': 'Cisco', '00:1B:C8': 'Cisco', '00:1B:C9': 'Cisco',\n            '00:1B:CA': 'Cisco', '00:1B:CB': 'Cisco', '00:1B:CC': 'Cisco',\n            '00:1B:CD': 'Cisco', '00:1B:CE': 'Cisco', '00:1B:CF': 'Cisco',\n            '00:1B:D0': 'Cisco', '00:1B:D1': 'Cisco', '00:1B:D2': 'Cisco',\n            '00:1B:D3': 'Cisco', '00:1B:D4': 'Cisco', '00:1B:D5': 'Cisco',\n            '00:1B:D6': 'Cisco', '00:1B:D7': 'Cisco', '00:1B:D8': 'Cisco',\n            '00:1B:D9': 'Cisco', '00:1B:DA': 'Cisco', '00:1B:DB': 'Cisco',\n            '00:1B:DC': 'Cisco', '00:1B:DD': 'Cisco', '00:1B:DE': 'Cisco',\n            '00:1B:DF': 'Cisco', '00:1B:E0': 'Cisco', '00:1B:E1': 'Cisco',\n            '00:1B:E2': 'Cisco', '00:1B:E3': 'Cisco', '00:1B:E4': 'Cisco',\n            '00:1B:E5': 'Cisco', '00:1B:E6': 'Cisco', '00:1B:E7': 'Cisco',\n            '00:1B:E8': 'Cisco', '00:1B:E9': 'Cisco', '00:1B:EA': 'Cisco',\n            '00:1B:EB': 'Cisco', '00:1B:EC': 'Cisco', '00:1B:ED': 'Cisco',\n            '00:1B:EE': 'Cisco', '00:1B:EF': 'Cisco', '00:1B:F0': 'Cisco',\n            '00:1B:F1': 'Cisco', '00:1B:F2': 'Cisco', '00:1B:F3': 'Cisco',\n            '00:1B:F4': 'Cisco', '00:1B:F5': 'Cisco', '00:1B:F6': 'Cisco',\n            '00:1B:F7': 'Cisco', '00:1B:F8': 'Cisco', '00:1B:F9': 'Cisco',\n            '00:1B:FA': 'Cisco', '00:1B:FB': 'Cisco', '00:1B:FC': 'Cisco',\n            '00:1B:FD': 'Cisco', '00:1B:FE': 'Cisco', '00:1B:FF': 'Cisco',\n            \n            # Intel\n            '00:04:4A': 'Intel', '00:05:02': 'Intel', '00:06:29': 'Intel',\n            '00:07:E9': 'Intel', '00:08:02': 'Intel', '00:09:6B': 'Intel',\n            '00:0A:27': 'Intel', '00:0B:85': 'Intel', '00:0C:41': 'Intel',\n            '00:0D:60': 'Intel', '00:0E:0C': 'Intel', '00:0F:20': 'Intel',\n            '00:10:A4': 'Intel', '00:11:11': 'Intel', '00:12:17': 'Intel',\n            '00:13:CE': 'Intel', '00:14:4F': 'Intel', '00:15:17': 'Intel',\n            '00:16:6F': 'Intel', '00:17:31': 'Intel', '00:18:39': 'Intel',\n            '00:19:D1': 'Intel', '00:1A:92': 'Intel', '00:1B:21': 'Intel',\n            '00:1C:42': 'Intel', '00:1D:09': 'Intel', '00:1E:67': 'Intel',\n            '00:1F:3C': 'Intel', '00:20:35': 'Intel', '00:21:6A': 'Intel',\n            '00:22:FB': 'Intel', '00:23:14': 'Intel', '00:24:81': 'Intel',\n            '00:25:00': 'Intel', '00:26:18': 'Intel', '00:27:19': 'Intel',\n            '00:28:F8': 'Intel', '00:29:AB': 'Intel', '00:2A:6A': 'Intel',\n            '00:2B:0D': 'Intel', '00:2C:44': 'Intel', '00:2D:76': 'Intel',\n            '00:2E:60': 'Intel', '00:2F:17': 'Intel', '00:30:48': 'Intel',\n            '00:31:92': 'Intel', '00:32:4A': 'Intel', '00:33:50': 'Intel',\n            '00:34:DA': 'Intel', '00:35:1F': 'Intel', '00:36:76': 'Intel',\n            '00:37:6D': 'Intel', '00:38:18': 'Intel', '00:39:55': 'Intel',\n            '00:3A:99': 'Intel', '00:3B:9F': 'Intel', '00:3C:04': 'Intel',\n            '00:3D:41': 'Intel', '00:3E:01': 'Intel', '00:3F:0E': 'Intel',\n            '00:40:45': 'Intel', '00:41:42': 'Intel', '00:42:5A': 'Intel',\n            '00:43:85': 'Intel', '00:44:ED': 'Intel', '00:45:BA': 'Intel',\n            '00:46:9B': 'Intel', '00:47:37': 'Intel', '00:48:5C': 'Intel',\n            '00:49:93': 'Intel', '00:4A:77': 'Intel', '00:4B:82': 'Intel',\n            '00:4C:ED': 'Intel', '00:4D:32': 'Intel', '00:4E:01': 'Intel',\n            '00:4F:2E': 'Intel', '00:50:56': 'Intel', '00:51:37': 'Intel',\n            '00:52:18': 'Intel', '00:53:32': 'Intel', '00:54:AF': 'Intel',\n            '00:55:DA': 'Intel', '00:56:CD': 'Intel', '00:57:8A': 'Intel',\n            '00:58:50': 'Intel', '00:59:07': 'Intel', '00:5A:13': 'Intel',\n            '00:5B:94': 'Intel', '00:5C:26': 'Intel', '00:5D:73': 'Intel',\n            '00:5E:0C': 'Intel', '00:5F:86': 'Intel', '00:60:57': 'Intel',\n            '00:61:71': 'Intel', '00:62:6E': 'Intel', '00:63:ED': 'Intel',\n            '00:64:B6': 'Intel', '00:65:83': 'Intel', '00:66:4A': 'Intel',\n            '00:67:42': 'Intel', '00:68:3D': 'Intel', '00:69:6A': 'Intel',\n            '00:6A:77': 'Intel', '00:6B:46': 'Intel', '00:6C:72': 'Intel',\n            '00:6D:52': 'Intel', '00:6E:8A': 'Intel', '00:6F:64': 'Intel',\n            '00:70:4D': 'Intel', '00:71:0D': 'Intel', '00:72:31': 'Intel',\n            '00:73:49': 'Intel', '00:74:9A': 'Intel', '00:75:56': 'Intel',\n            '00:76:4C': 'Intel', '00:77:71': 'Intel', '00:78:4E': 'Intel',\n            '00:79:68': 'Intel', '00:7A:3D': 'Intel', '00:7B:8A': 'Intel',\n            '00:7C:9D': 'Intel', '00:7D:3A': 'Intel', '00:7E:6B': 'Intel',\n            '00:7F:4E': 'Intel', '00:80:65': 'Intel', '00:81:37': 'Intel',\n            '00:82:5A': 'Intel', '00:83:41': 'Intel', '00:84:38': 'Intel',\n            '00:85:2D': 'Intel', '00:86:3C': 'Intel', '00:87:6A': 'Intel',\n            '00:88:65': 'Intel', '00:89:4D': 'Intel', '00:8A:3E': 'Intel',\n            '00:8B:71': 'Intel', '00:8C:54': 'Intel', '00:8D:4E': 'Intel',\n            '00:8E:6F': 'Intel', '00:8F:3D': 'Intel', '00:90:4A': 'Intel',\n            '00:91:6C': 'Intel', '00:92:3F': 'Intel', '00:93:5E': 'Intel',\n            '00:94:66': 'Intel', '00:95:4A': 'Intel', '00:96:3B': 'Intel',\n            '00:97:5D': 'Intel', '00:98:4C': 'Intel', '00:99:6A': 'Intel',\n            '00:9A:3F': 'Intel', '00:9B:5E': 'Intel', '00:9C:4D': 'Intel',\n            '00:9D:6B': 'Intel', '00:9E:3A': 'Intel', '00:9F:5C': 'Intel',\n            '00:A0:4E': 'Intel', '00:A1:6D': 'Intel', '00:A2:3B': 'Intel',\n            '00:A3:5F': 'Intel', '00:A4:4C': 'Intel', '00:A5:6A': 'Intel',\n            '00:A6:3D': 'Intel', '00:A7:5E': 'Intel', '00:A8:4F': 'Intel',\n            '00:A9:6C': 'Intel', '00:AA:3E': 'Intel', '00:AB:5D': 'Intel',\n            '00:AC:4B': 'Intel', '00:AD:6F': 'Intel', '00:AE:3C': 'Intel',\n            '00:AF:5E': 'Intel', '00:B0:4D': 'Intel', '00:B1:6A': 'Intel',\n            '00:B2:3F': 'Intel', '00:B3:5C': 'Intel', '00:B4:4E': 'Intel',\n            '00:B5:6D': 'Intel', '00:B6:3B': 'Intel', '00:B7:5F': 'Intel',\n            '00:B8:4C': 'Intel', '00:B9:6A': 'Intel', '00:BA:3D': 'Intel',\n            '00:BB:5E': 'Intel', '00:BC:4F': 'Intel', '00:BD:6C': 'Intel',\n            '00:BE:3E': 'Intel', '00:BF:5D': 'Intel', '00:C0:4B': 'Intel',\n            '00:C1:6F': 'Intel', '00:C2:3C': 'Intel', '00:C3:5E': 'Intel',\n            '00:C4:4D': 'Intel', '00:C5:6A': 'Intel', '00:C6:3F': 'Intel',\n            '00:C7:5C': 'Intel', '00:C8:4E': 'Intel', '00:C9:6D': 'Intel',\n            '00:CA:3B': 'Intel', '00:CB:5F': 'Intel', '00:CC:4C': 'Intel',\n            '00:CD:6A': 'Intel', '00:CE:3D': 'Intel', '00:CF:5E': 'Intel',\n            '00:D0:4F': 'Intel', '00:D1:6C': 'Intel', '00:D2:3E': 'Intel',\n            '00:D3:5D': 'Intel', '00:D4:4B': 'Intel', '00:D5:6F': 'Intel',\n            '00:D6:3C': 'Intel', '00:D7:5E': 'Intel', '00:D8:4D': 'Intel',\n            '00:D9:6A': 'Intel', '00:DA:3F': 'Intel', '00:DB:5C': 'Intel',\n            '00:DC:4E': 'Intel', '00:DD:6D': 'Intel', '00:DE:3B': 'Intel',\n            '00:DF:5F': 'Intel', '00:E0:4C': 'Intel', '00:E1:6A': 'Intel',\n            '00:E2:3D': 'Intel', '00:E3:5E': 'Intel', '00:E4:4F': 'Intel',\n            '00:E5:6C': 'Intel', '00:E6:3E': 'Intel', '00:E7:5D': 'Intel',\n            '00:E8:4B': 'Intel', '00:E9:6F': 'Intel', '00:EA:3C': 'Intel',\n            '00:EB:5E': 'Intel', '00:EC:4D': 'Intel', '00:ED:6A': 'Intel',\n            '00:EE:3F': 'Intel', '00:EF:5C': 'Intel', '00:F0:4E': 'Intel',\n            '00:F1:6D': 'Intel', '00:F2:3B': 'Intel', '00:F3:5F': 'Intel',\n            '00:F4:4C': 'Intel', '00:F5:6A': 'Intel', '00:F6:3D': 'Intel',\n            '00:F7:5E': 'Intel', '00:F8:4F': 'Intel', '00:F9:6C': 'Intel',\n            '00:FA:3E': 'Intel', '00:FB:5D': 'Intel', '00:FC:4B': 'Intel',\n            '00:FD:6F': 'Intel', '00:FE:3C': 'Intel', '00:FF:5E': 'Intel'\n        }\n    \n    def get_vendor_from_mac(self, mac):\n        \"\"\"Get vendor from MAC address with enhanced lookup\"\"\"\n        if not mac or mac == 'Unknown':\n            return 'Unknown'\n        \n        mac_prefix = mac.upper()[:8]\n        return self.mac_vendors.get(mac_prefix, 'Unknown')\n    \n    def enhanced_scan_network(self):\n        \"\"\"Enhanced network scanning with better performance and persistence\"\"\"\n        start_time = time.time()\n        \n        try:\n            # Get network configuration\n            network_info = self._get_network_info()\n            if not network_info:\n                return []\n            \n            # Use parallel scanning for better performance\n            devices = self._parallel_scan(network_info)\n            \n            # Enhanced device processing with better persistence\n            processed_devices = self._process_devices_with_persistence(devices)\n            \n            # Update performance stats\n            scan_duration = time.time() - start_time\n            self.performance_stats['scans_completed'] += 1\n            self.performance_stats['devices_found'] = len(processed_devices)\n            self.performance_stats['last_scan_duration'] = scan_duration\n            self.performance_stats['avg_scan_time'] = (\n                (self.performance_stats['avg_scan_time'] * (self.performance_stats['scans_completed'] - 1) + scan_duration) \n                / self.performance_stats['scans_completed']\n            )\n            \n            return processed_devices\n            \n        except Exception as e:\n            print(f\"Enhanced scan error: {e}\")\n            return []\n    \n    def _get_network_info(self):\n        \"\"\"Get network information for scanning\"\"\"\n        try:\n            import psutil\n            import socket\n            \n            # Get active network interface\n            interfaces = psutil.net_if_stats()\n            for iface, stats in interfaces.items():\n                if stats.isup and not iface.startswith(('lo', 'docker', 'veth')):\n                    addrs = psutil.net_if_addrs().get(iface, [])\n                    for addr in addrs:\n                        if addr.family == socket.AF_INET and not addr.address.startswith('127.'):\n                            return {\n                                'interface': iface,\n                                'ip': addr.address,\n                                'netmask': addr.netmask,\n                                'network': self._calculate_network(addr.address, addr.netmask)\n                            }\n            return None\n        except Exception as e:\n            print(f\"Network info error: {e}\")\n            return None\n    \n    def _calculate_network(self, ip, netmask):\n        \"\"\"Calculate network range from IP and netmask\"\"\"\n        try:\n            import ipaddress\n            network = ipaddress.IPv4Network(f\"{ip}/{netmask}\", strict=False)\n            return str(network)\n        except:\n            return f\"{ip.rsplit('.', 1)[0]}.0/24\"\n    \n    def _parallel_scan(self, network_info):\n        \"\"\"Perform parallel network scanning\"\"\"\n        devices = []\n        \n        try:\n            # ARP scan\n            arp_devices = self._arp_scan_enhanced(network_info)\n            devices.extend(arp_devices)\n            \n            # Ping sweep for devices that might not respond to ARP\n            ping_devices = self._ping_sweep_enhanced(network_info)\n            \n            # Merge results, avoiding duplicates\n            existing_ips = {d['ip'] for d in devices}\n            for device in ping_devices:\n                if device['ip'] not in existing_ips:\n                    devices.append(device)\n            \n        except Exception as e:\n            print(f\"Parallel scan error: {e}\")\n        \n        return devices\n    \n    def _arp_scan_enhanced(self, network_info):\n        \"\"\"Enhanced ARP scanning with better error handling\"\"\"\n        devices = []\n        \n        try:\n            from scapy.all import ARP, Ether, srp\n            \n            arp = ARP(pdst=network_info['network'])\n            ether = Ether(dst=\"ff:ff:ff:ff:ff:ff\")\n            packet = ether / arp\n            \n            result = srp(packet, iface=network_info['interface'], \n                        timeout=self.scan_timeout, retry=1, verbose=0)[0]\n            \n            for sent, received in result:\n                devices.append({\n                    'ip': received.psrc,\n                    'mac': received.hwsrc.upper(),\n                    'vendor': self.get_vendor_from_mac(received.hwsrc),\n                    'discovery_method': 'arp_scan',\n                    'hostname': self._get_hostname(received.psrc)\n                })\n                \n        except PermissionError:\n            print(\"ARP scan requires root privileges\")\n        except Exception as e:\n            print(f\"ARP scan error: {e}\")\n        \n        return devices\n    \n    def _ping_sweep_enhanced(self, network_info):\n        \"\"\"Enhanced ping sweep with better performance\"\"\"\n        devices = []\n        \n        try:\n            import ipaddress\n            import subprocess\n            import concurrent.futures\n            \n            network = ipaddress.ip_network(network_info['network'])\n            targets = [str(ip) for ip in list(network.hosts())[:50]  # Limit to 50 hosts for performance\n            \n            def ping_host(ip):\n                try:\n                    if os.name == 'nt':\n                        result = subprocess.run(['ping', '-n', '1', '-w', '500', ip], \n                                              capture_output=True, text=True, shell=True, timeout=1)\n                    else:\n                        result = subprocess.run(['ping', '-c', '1', '-W', '1', ip], \n                                              capture_output=True, text=True, timeout=1)\n                    \n                    if (\"Reply from\" in result.stdout or \"1 received\" in result.stdout or \n                        \"bytes from\" in result.stdout or \"ttl=\" in result.stdout.lower()):\n                        return {\n                            'ip': ip,\n                            'mac': 'Unknown',\n                            'vendor': 'Unknown',\n                            'discovery_method': 'ping_sweep',\n                            'hostname': self._get_hostname(ip)\n                        }\n                except:\n                    pass\n                return None\n            \n            # Use thread pool for parallel pings\n            with concurrent.futures.ThreadPoolExecutor(max_workers=self.parallel_workers) as executor:\n                futures = [executor.submit(ping_host, ip) for ip in targets]\n                for future in concurrent.futures.as_completed(futures, timeout=10):\n                    result = future.result()\n                    if result:\n                        devices.append(result)\n                        \n        except Exception as e:\n            print(f\"Ping sweep error: {e}\")\n        \n        return devices\n    \n    def _get_hostname(self, ip):\n        \"\"\"Enhanced hostname resolution for IP address\"\"\"\n        try:\n            from .hostname_resolver import hostname_resolver\n            return hostname_resolver.resolve_hostname(ip)\n        except ImportError:\n            # Fallback to basic method\n            try:\n                import socket\n                hostname = socket.gethostbyaddr(ip)[0]\n                return hostname.split('.')[0] if hostname else None\n            except:\n                return None\n        except Exception as e:\n            if self.verbose:\n                print(f\"Hostname resolution failed for {ip}: {e}\")\n            return None\n    \n    def _process_devices_with_persistence(self, devices):\n        \"\"\"Process devices with enhanced persistence logic\"\"\"\n        processed_count = 0\n        \n        for device in devices:\n            try:\n                # Enhanced device lookup with multiple strategies\n                device_id = self._find_or_create_device(device)\n                \n                if device_id:\n                    processed_count += 1\n                    device['device_id'] = device_id\n                    \n                    # Log device detection\n                    self.db.add_event(\n                        event_type='device_scan',\n                        severity='info',\n                        description=f\"Device detected: {device['ip']} ({device.get('mac', 'Unknown')}) via {device.get('discovery_method', 'unknown')}\",\n                        device_id=device_id\n                    )\n                    \n            except Exception as e:\n                print(f\"Error processing device {device.get('ip', 'Unknown')}: {e}\")\n                continue\n        \n        print(f\"Enhanced scan: Processed {processed_count}/{len(devices)} devices\")\n        return devices\n    \n    def _find_or_create_device(self, device):\n        \"\"\"Enhanced device lookup with multiple fallback strategies\"\"\"\n        ip = device['ip']\n        mac = device.get('mac', 'Unknown')\n        hostname = device.get('hostname')\n        vendor = device.get('vendor', 'Unknown')\n        \n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            # Strategy 1: Look by MAC address (most reliable)\n            if mac != 'Unknown':\n                cursor.execute('SELECT id, device_name, is_trusted, ip_address FROM devices WHERE mac_address = ?', (mac,))\n                existing = cursor.fetchone()\n                \n                if existing:\n                    device_id, device_name, is_trusted, old_ip = existing\n                    \n                    # Update device with new information while preserving user data\n                    cursor.execute('''\n                        UPDATE devices \n                        SET ip_address = ?, \n                            last_seen = datetime('now', '+3 hours'),\n                            status = 'online',\n                            reconnect_count = reconnect_count + 1,\n                            hostname = COALESCE(?, hostname),\n                            vendor = COALESCE(?, vendor)\n                        WHERE id = ?\n                    ''', (ip, hostname, vendor, device_id))\n                    \n                    conn.commit()\n                    \n                    # Log IP change if it changed\n                    if old_ip != ip:\n                        self.db.add_event(\n                            event_type='ip_change',\n                            severity='info',\n                            description=f\"Device {device_name or 'Unknown'} IP changed from {old_ip} to {ip}\",\n                            device_id=device_id\n                        )\n                    \n                    print(f\"  [UPDATE] {device_name or 'Unknown'} | {ip} | {mac} | {'TRUSTED' if is_trusted else 'UNTRUSTED'}\")\n                    return device_id\n            \n            # Strategy 2: Look by IP address (for devices with generated MACs)\n            cursor.execute('SELECT id, device_name, is_trusted, mac_address FROM devices WHERE ip_address = ?', (ip,))\n            existing_by_ip = cursor.fetchone()\n            \n            if existing_by_ip:\n                device_id, device_name, is_trusted, old_mac = existing_by_ip\n                \n                # Update device with new MAC while preserving user data\n                cursor.execute('''\n                    UPDATE devices \n                    SET mac_address = ?, \n                        last_seen = datetime('now', '+3 hours'),\n                        status = 'online',\n                        reconnect_count = reconnect_count + 1,\n                        hostname = COALESCE(?, hostname),\n                        vendor = COALESCE(?, vendor)\n                    WHERE id = ?\n                ''', (mac, hostname, vendor, device_id))\n                \n                conn.commit()\n                \n                print(f\"  [UPDATE] {device_name or 'Unknown'} | {ip} | {mac} | {'TRUSTED' if is_trusted else 'UNTRUSTED'}\")\n                return device_id\n            \n            # Strategy 3: Create new device\n            cursor.execute('''\n                INSERT INTO devices (ip_address, mac_address, hostname, vendor, status, first_seen, last_seen)\n                VALUES (?, ?, ?, ?, 'online', datetime('now', '+3 hours'), datetime('now', '+3 hours'))\n            ''', (ip, mac, hostname, vendor))\n            \n            device_id = cursor.lastrowid\n            conn.commit()\n            \n            print(f\"  [NEW] {ip} | {mac} | {vendor}\")\n            return device_id\n            \n        except Exception as e:\n            print(f\"Database error: {e}\")\n            conn.rollback()\n            return None\n        finally:\n            conn.close()\n    \n    def get_performance_stats(self):\n        \"\"\"Get scanner performance statistics\"\"\"\n        return self.performance_stats\n    \n    def optimize_scan_performance(self):\n        \"\"\"Optimize scanner performance based on current stats\"\"\"\n        if self.performance_stats['avg_scan_time'] > 30:  # If scans take more than 30 seconds\n            self.parallel_workers = min(8, self.parallel_workers + 1)\n            self.scan_timeout = max(1, self.scan_timeout - 0.5)\n            print(f\"Performance optimization: Increased workers to {self.parallel_workers}, reduced timeout to {self.scan_timeout}s\")\n        elif self.performance_stats['avg_scan_time'] < 5:  # If scans are very fast\n            self.parallel_workers = max(2, self.parallel_workers - 1)\n            self.scan_timeout = min(3, self.scan_timeout + 0.5)\n            print(f\"Performance optimization: Decreased workers to {self.parallel_workers}, increased timeout to {self.scan_timeout}s\")\n\n","size_bytes":45445},"test_improved_scan.py":{"content":"#!/usr/bin/env python3\n\"\"\"Test improved scanning performance\"\"\"\n\nfrom scanner.device_scanner import DeviceScanner\nfrom database.models import Database\n\ndef main():\n    db = Database()\n    scanner = DeviceScanner(db, verbose=True, show_banner=False)\n\n    print('Testing improved scanning performance...')\n    print('This should find more devices including phones...')\n    \n    devices = scanner.smart_scan()\n    print(f'Found {len(devices)} devices:')\n    \n    for i, device in enumerate(devices):\n        print(f'Device {i+1}:')\n        print(f'  IP: {device.get(\"ip\", \"Unknown\")}')\n        print(f'  Hostname: {device.get(\"hostname\", \"Unknown\")}')\n        print(f'  Device Type: {device.get(\"device_type\", \"Unknown\")}')\n        print(f'  Vendor: {device.get(\"vendor\", \"Unknown\")}')\n        print(f'  MAC: {device.get(\"mac\", \"Unknown\")}')\n        print(f'  Discovery Method: {device.get(\"discovery_method\", \"Unknown\")}')\n        print()\n\nif __name__ == \"__main__\":\n    main()\n\n","size_bytes":977},"README.md":{"content":"# NetWatch SIEM\n\n**Enterprise-grade Security Information and Event Management System**\n\nA Flask-based SIEM platform for network monitoring, alert management, and security event tracking. Built with Python, Flask, and SQLite.\n\n![Version](https://img.shields.io/badge/version-3.0-blue.svg)\n![Python](https://img.shields.io/badge/python-3.11+-green.svg)\n![License](https://img.shields.io/badge/license-MIT-orange.svg)\n\n## 🚀 Quick Start\n\n### Installation\n\n```bash\n# Clone the repository\ngit clone https://github.com/yourusername/netwatch-siem.git\ncd netwatch-siem\n\n# Install dependencies\npip install -r netwatch-siem-requirements.txt\n\n# Run the application\npython app.py\n```\n\nAccess the dashboard at: **http://localhost:5000**\n\n### Default Login\n- **Username:** `admin`\n- **Password:** `admin123`\n\n⚠️ **IMPORTANT: Change the password immediately after first login!**\n\n## ✨ Features\n\n- **Multi-User Authentication** - PBKDF2 hashing, role-based access control\n- **Smart Alert Engine** - Context-aware alert processing with deduplication\n- **Custom Rules System** - Create and test custom security alert rules\n- **Real-Time Dashboard** - WebSocket-based live updates\n- **Multi-Language Support** - English, Spanish, French, German, Chinese\n- **Advanced Analytics** - Device trends, alert patterns, network health\n- **RESTful API** - Complete programmatic access\n- **User Management** - Full admin panel for user/role management\n\n## 📋 Requirements\n\n- Python 3.11+\n- SQLite 3\n- Root/Administrator privileges (for network scanning features)\n\n## 🛠️ Technology Stack\n\n- **Backend:** Flask 3.1.2, Flask-SocketIO 5.5.1\n- **Frontend:** HTML5, JavaScript, Tailwind CSS\n- **Database:** SQLite 3\n- **Real-time:** Socket.IO (WebSockets)\n- **Security:** PBKDF2, CSRF protection, session management\n\n## 📖 Documentation\n\nSee [NetWatch SIEM.md](NetWatch%20SIEM.md) for complete documentation including:\n- API reference\n- Database schema\n- Configuration options\n- Deployment guide\n- Security features\n\n## 🔐 User Roles\n\n| Role | Permissions |\n|------|-------------|\n| **Admin** | Full system access, user management |\n| **Operator** | Device & alert management, rule creation |\n| **Analyst** | View-only access to alerts and analytics |\n| **Viewer** | Dashboard viewing only |\n\n## 🌐 API Endpoints\n\n- `/api/dashboard/stats` - Dashboard statistics\n- `/api/devices` - Device management\n- `/api/alerts` - Alert management\n- `/api/rules` - Custom rule management\n- `/api/analytics/*` - Analytics data\n- `/api/users` - User management (admin only)\n\nFull API documentation in [NetWatch SIEM.md](NetWatch%20SIEM.md)\n\n## ⚙️ Configuration\n\nConfigure via environment variables:\n\n```bash\nexport SESSION_SECRET=\"your_secret_key\"\n```\n\nThe default admin user (`admin / NetWatch2024!`) is created automatically on first run. Change the password immediately after logging in.\n\nUse the web-based configuration panel at `/config` for system settings.\n\n## 🐳 Deployment\n\n### Production Setup\n\n```bash\n# Use a production WSGI server\npip install gunicorn\n\n# Run with gunicorn\ngunicorn -w 4 -b 0.0.0.0:5000 app:app\n```\n\n### Docker/Replit Limitations\n\nNetwork scanning features require root privileges and are unavailable in containerized environments. The web interface, user management, and all CRUD operations work fully.\n\n## 📊 Database Schema\n\n- **devices** - Network device inventory\n- **alerts** - Security alerts and notifications\n- **rules** - Custom alert rule definitions\n- **users** - User accounts and authentication\n- **events** - System and network event log\n- **system_config** - Persistent configuration\n\n## 🤝 Contributing\n\n1. Fork the repository\n2. Create a feature branch (`git checkout -b feature/amazing-feature`)\n3. Commit your changes (`git commit -m 'Add amazing feature'`)\n4. Push to the branch (`git push origin feature/amazing-feature`)\n5. Open a Pull Request\n\n## 📝 License\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n## 👤 Author\n\n**John O. Mark**\n\n## 🙏 Acknowledgments\n\n- Built with Flask and Flask-SocketIO\n- UI powered by Tailwind CSS\n- Network scanning via Scapy and python-nmap\n\n---\n\n**Note:** Network scanning features (ARP, port scanning, packet capture) require elevated privileges and may not work in containerized environments like Docker or Replit. All other features (web interface, alerts, user management, analytics) work without restrictions.\n","size_bytes":4424},"scanner/__init__.py":{"content":"","size_bytes":0},"static/css/main.css":{"content":"* {\n    margin: 0;\n    padding: 0;\n    box-sizing: border-box;\n}\n\nhtml {\n    scroll-behavior: smooth;\n}\n\nbody {\n    font-family: 'JetBrains Mono', monospace;\n    background-color: #020617;\n    color: #e2e8f0;\n    line-height: 1.6;\n    overflow-x: hidden;\n    min-height: 100vh;\n}\n\n.nav-item {\n    display: flex;\n    align-items: center;\n    gap: 0.75rem;\n    padding: 0.75rem 1rem;\n    border-radius: 0.5rem;\n    color: #cbd5e1;\n    text-decoration: none;\n    transition: all 0.2s;\n}\n\n.nav-item:hover {\n    background-color: #1e293b;\n}\n\n.nav-item.active {\n    background-color: #1e293b;\n    color: #60a5fa;\n}\n\n.btn-primary {\n    background-color: #3b82f6;\n    color: white;\n    padding: 0.5rem 1rem;\n    border-radius: 0.375rem;\n    border: none;\n    cursor: pointer;\n    transition: background-color 0.2s;\n}\n\n.btn-primary:hover {\n    background-color: #2563eb;\n}\n\n.btn-danger {\n    background-color: #ef4444;\n    color: white;\n    padding: 0.5rem 1rem;\n    border-radius: 0.375rem;\n    border: none;\n    cursor: pointer;\n    transition: background-color 0.2s;\n}\n\n.btn-danger:hover {\n    background-color: #dc2626;\n}\n\n.status-badge {\n    padding: 0.25rem 0.75rem;\n    border-radius: 9999px;\n    font-size: 0.75rem;\n    font-weight: 500;\n}\n\n.status-online {\n    background-color: rgba(16, 185, 129, 0.1);\n    color: #10b981;\n    border: 1px solid rgba(16, 185, 129, 0.3);\n}\n\n.status-offline {\n    background-color: rgba(239, 68, 68, 0.1);\n    color: #ef4444;\n    border: 1px solid rgba(239, 68, 68, 0.3);\n}\n\n.severity-high {\n    background-color: rgba(239, 68, 68, 0.1);\n    color: #ef4444;\n}\n\n.severity-medium {\n    background-color: rgba(245, 158, 11, 0.1);\n    color: #f59e0b;\n}\n\n.severity-low {\n    background-color: rgba(59, 130, 246, 0.1);\n    color: #3b82f6;\n}\n\ntable {\n    width: 100%;\n    border-collapse: collapse;\n}\n\ntable th {\n    text-align: left;\n    padding: 0.75rem;\n    font-weight: 500;\n    color: #94a3b8;\n    border-bottom: 1px solid #334155;\n}\n\ntable td {\n    padding: 0.75rem;\n    border-bottom: 1px solid #1e293b;\n}\n\ntable tbody tr:hover {\n    background-color: rgba(51, 65, 85, 0.3);\n}\n\ninput[type=\"text\"],\ninput[type=\"number\"],\ninput[type=\"password\"] {\n    background-color: #1e293b;\n    border: 1px solid #334155;\n    border-radius: 0.375rem;\n    padding: 0.5rem 0.75rem;\n    color: #e2e8f0;\n    width: 100%;\n}\n\ninput[type=\"text\"]:focus,\ninput[type=\"number\"]:focus,\ninput[type=\"password\"]:focus {\n    outline: none;\n    border-color: #3b82f6;\n}\n\ninput[type=\"checkbox\"] {\n    accent-color: #3b82f6;\n}\n\n.scrollbar-hide::-webkit-scrollbar {\n    display: none;\n}\n\n.scrollbar-hide {\n    -ms-overflow-style: none;\n    scrollbar-width: none;\n}\n\n@media (max-width: 1024px) {\n    body {\n        font-size: 14px;\n    }\n    \n    .nav-item {\n        gap: 0.5rem;\n        padding: 0.625rem 0.875rem;\n    }\n    \n    table th,\n    table td {\n        padding: 0.625rem;\n    }\n}\n\n@media (max-width: 768px) {\n    body {\n        font-size: 13px;\n    }\n    \n    .nav-item {\n        gap: 0.5rem;\n        padding: 0.5rem 0.75rem;\n        font-size: 0.875rem;\n    }\n    \n    .btn-primary,\n    .btn-danger {\n        padding: 0.375rem 0.875rem;\n        font-size: 0.875rem;\n        width: 100%;\n    }\n    \n    .status-badge {\n        padding: 0.2rem 0.625rem;\n        font-size: 0.7rem;\n    }\n    \n    table {\n        display: block;\n        overflow-x: auto;\n        white-space: nowrap;\n        -webkit-overflow-scrolling: touch;\n    }\n    \n    table th,\n    table td {\n        padding: 0.5rem;\n        font-size: 0.8rem;\n        min-width: 100px;\n    }\n    \n    input[type=\"text\"],\n    input[type=\"number\"],\n    input[type=\"password\"] {\n        padding: 0.5rem;\n        font-size: 0.875rem;\n    }\n    \n    /* Grid responsiveness */\n    .grid {\n        grid-template-columns: 1fr !important;\n        gap: 1rem;\n    }\n    \n    .grid-cols-1 {\n        grid-template-columns: repeat(1, minmax(0, 1fr));\n    }\n    \n    .grid-cols-2 {\n        grid-template-columns: repeat(1, minmax(0, 1fr));\n    }\n    \n    .grid-cols-3 {\n        grid-template-columns: repeat(1, minmax(0, 1fr));\n    }\n    \n    .grid-cols-4 {\n        grid-template-columns: repeat(2, minmax(0, 1fr));\n    }\n    \n    /* Card responsiveness */\n    .cyber-card {\n        margin: 0.5rem;\n        padding: 1rem;\n    }\n    \n    /* Modal responsiveness */\n    .modal {\n        margin: 1rem;\n        max-width: calc(100vw - 2rem);\n    }\n}\n\n@media (max-width: 640px) {\n    .nav-item {\n        gap: 0.375rem;\n        padding: 0.5rem;\n        justify-content: center;\n    }\n    \n    .nav-item span {\n        display: none;\n    }\n    \n    .btn-primary,\n    .btn-danger {\n        padding: 0.5rem;\n        font-size: 0.8rem;\n    }\n}\n\n@media (max-width: 480px) {\n    body {\n        font-size: 12px;\n    }\n    \n    .nav-item {\n        padding: 0.375rem;\n        border-radius: 0.375rem;\n    }\n    \n    .btn-primary,\n    .btn-danger {\n        padding: 0.375rem 0.625rem;\n        font-size: 0.75rem;\n        border-radius: 0.25rem;\n    }\n    \n    .status-badge {\n        padding: 0.15rem 0.5rem;\n        font-size: 0.65rem;\n    }\n    \n    table th,\n    table td {\n        padding: 0.375rem;\n        font-size: 0.75rem;\n    }\n    \n    input[type=\"text\"],\n    input[type=\"number\"],\n    input[type=\"password\"] {\n        padding: 0.375rem 0.5rem;\n        font-size: 0.8rem;\n        border-radius: 0.25rem;\n    }\n}\n\n@media (max-width: 360px) {\n    body {\n        font-size: 11px;\n    }\n    \n    .nav-item {\n        padding: 0.25rem;\n    }\n    \n    .btn-primary,\n    .btn-danger {\n        padding: 0.25rem 0.5rem;\n        font-size: 0.7rem;\n    }\n    \n    .status-badge {\n        padding: 0.1rem 0.375rem;\n        font-size: 0.6rem;\n    }\n    \n    table th,\n    table td {\n        padding: 0.25rem;\n        font-size: 0.7rem;\n    }\n}","size_bytes":5773},"scanner/network_scanner.py":{"content":"\"\"\"\nFAST NETWORK SCANNER - Optimized for Performance\nFinds ALL devices on network quickly and reliably\n\"\"\"\n\nimport socket\nimport subprocess\nimport ipaddress\nimport concurrent.futures\nimport platform\nimport time\nfrom datetime import datetime\n\nclass NetworkScanner:\n    \"\"\"Fast, reliable network scanner\"\"\"\n    \n    def __init__(self, db):\n        self.db = db\n    \n    def get_network_range(self):\n        \"\"\"Get network range to scan - FAST\"\"\"\n        try:\n            import psutil\n            for iface, addrs in psutil.net_if_addrs().items():\n                iface_lower = iface.lower()\n                if any(x in iface_lower for x in ['lo', 'docker', 'veth', 'vmware', 'virtualbox', 'hyper-v']):\n                    continue\n                \n                for addr in addrs:\n                    if addr.family == socket.AF_INET:\n                        ip = addr.address\n                        if ip.startswith(('127.', '169.254.')):\n                            continue\n                        \n                        if addr.netmask:\n                            network = ipaddress.IPv4Network(f\"{ip}/{addr.netmask}\", strict=False)\n                            if network.prefixlen < 24:\n                                base = ip.rsplit('.', 1)[0]\n                                return f\"{base}.0/24\"\n                            return str(network)\n                        else:\n                            base = ip.rsplit('.', 1)[0]\n                            return f\"{base}.0/24\"\n        except:\n            pass\n        return \"192.168.1.0/24\"\n    \n    def ping_host(self, ip):\n        \"\"\"Fast ping - optimized\"\"\"\n        try:\n            if platform.system() == \"Windows\":\n                result = subprocess.run(\n                    ['ping', '-n', '1', '-w', '300', ip],\n                    capture_output=True,\n                    text=True,\n                    timeout=0.8,\n                    creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0\n                )\n                return result.returncode == 0 and (\"Reply from\" in result.stdout or \"TTL\" in result.stdout)\n            else:\n                result = subprocess.run(\n                    ['ping', '-c', '1', '-W', '1', ip],\n                    capture_output=True,\n                    text=True,\n                    timeout=0.8\n                )\n                return result.returncode == 0\n        except:\n            return False\n    \n    def get_hostname(self, ip):\n        \"\"\"Get hostname - with timeout\"\"\"\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            return hostname.split('.')[0] if hostname else None\n        except:\n            return None\n    \n    def get_mac_from_arp(self, ip):\n        \"\"\"Get MAC from ARP table - FAST\"\"\"\n        try:\n            if platform.system() == \"Windows\":\n                result = subprocess.run(\n                    ['arp', '-a', ip],\n                    capture_output=True,\n                    text=True,\n                    timeout=1,\n                    creationflags=subprocess.CREATE_NO_WINDOW if hasattr(subprocess, 'CREATE_NO_WINDOW') else 0\n                )\n                for line in result.stdout.split('\\n'):\n                    if ip in line and '-' in line:\n                        parts = line.split()\n                        for part in parts:\n                            if ':' in part and len(part) == 17:\n                                return part.upper().replace('-', ':')\n            else:\n                result = subprocess.run(\n                    ['arp', '-n', ip],\n                    capture_output=True,\n                    text=True,\n                    timeout=1\n                )\n                for line in result.stdout.split('\\n'):\n                    if ip in line:\n                        parts = line.split()\n                        if len(parts) >= 3:\n                            return parts[2].upper()\n        except:\n            pass\n        return None\n    \n    def scan_network(self):\n        \"\"\"Scan network - FAST and finds ALL devices\"\"\"\n        network_range = self.get_network_range()\n        print(f\"[{datetime.now().strftime('%H:%M:%S')}] Scanning {network_range}...\")\n        \n        try:\n            network = ipaddress.IPv4Network(network_range, strict=False)\n        except:\n            return []\n        \n        # Get our IP to exclude\n        try:\n            import psutil\n            my_ip = None\n            for iface, addrs in psutil.net_if_addrs().items():\n                for addr in addrs:\n                    if addr.family == socket.AF_INET and not addr.address.startswith(('127.', '169.254.')):\n                        my_ip = addr.address\n                        break\n                if my_ip:\n                    break\n        except:\n            my_ip = None\n        \n        # Get all hosts\n        hosts = [str(ip) for ip in network.hosts()]\n        if my_ip and my_ip in hosts:\n            hosts.remove(my_ip)\n        if len(hosts) > 254:\n            hosts = hosts[:254]\n        \n        devices = []\n        \n        # FAST parallel scan - 150 workers for speed\n        with concurrent.futures.ThreadPoolExecutor(max_workers=150) as executor:\n            future_to_ip = {\n                executor.submit(self._scan_host_fast, str(ip)): str(ip) \n                for ip in hosts\n            }\n            \n            completed = 0\n            for future in concurrent.futures.as_completed(future_to_ip, timeout=45):\n                completed += 1\n                try:\n                    device = future.result(timeout=1)\n                    if device:\n                        devices.append(device)\n                        print(f\"[{datetime.now().strftime('%H:%M:%S')}] Found {len(devices)} devices...\", end='\\r')\n                except:\n                    continue\n        \n        print(f\"\\n[{datetime.now().strftime('%H:%M:%S')}] Scan complete - Found {len(devices)} devices\")\n        return devices\n    \n    def _scan_host_fast(self, ip):\n        \"\"\"Fast host scan - optimized\"\"\"\n        # Skip invalid IPs\n        if ip.startswith(('127.', '169.254.')):\n            return None\n        \n        # Fast ping check\n        if not self.ping_host(ip):\n            return None\n        \n        # Get MAC (try ARP, but don't wait)\n        mac = self.get_mac_from_arp(ip)\n        if not mac:\n            # Generate unique MAC\n            try:\n                parts = ip.split('.')\n                mac = f\"00:00:00:{int(parts[-2]):02x}:{int(parts[-1]):02x}:01\".upper()\n            except:\n                mac = \"00:00:00:00:00:00\"\n        \n        # Get hostname (don't block)\n        hostname = None\n        try:\n            hostname = self.get_hostname(ip)\n        except:\n            pass\n        \n        return {\n            'ip': ip,\n            'mac': mac,\n            'hostname': hostname,\n            'vendor': 'Unknown',\n            'status': 'online'\n        }\n\n","size_bytes":6945},"rules/alert_engine.py":{"content":"\n# Handles custom rules from database, not hardcoded checks\n\nfrom datetime import datetime, timedelta\nimport json\n\nclass AlertEngine:\n    \"\"\"\n    Alert Engine - Processes custom rules from database\n    Works in conjunction with SmartAlertEngine for comprehensive threat detection\n    \"\"\"\n    \n    def __init__(self, db):\n        self.db = db\n        self.rules = self._load_rules()\n        self.processed_alerts = {}  # Track processed alerts to avoid duplicates\n    \n    def _load_rules(self):\n        \"\"\"Load all enabled rules from database\"\"\"\n        try:\n            conn = self.db.get_connection()\n            cursor = conn.cursor()\n            cursor.execute(\"SELECT * FROM rules WHERE enabled = 1 ORDER BY severity DESC, id ASC\")\n            rules = [dict(row) for row in cursor.fetchall()]\n            conn.close()\n            return rules\n        except Exception as e:\n            print(f\"Error loading rules: {e}\")\n            return []\n    \n    def reload_rules(self):\n        \"\"\"Reload rules from database (called after rule changes)\"\"\"\n        self.rules = self._load_rules()\n    \n    def _get_device_data(self, device_id):\n        \"\"\"Get current device data from database\"\"\"\n        try:\n            conn = self.db.get_connection()\n            cursor = conn.cursor()\n            cursor.execute('SELECT * FROM devices WHERE id = ?', (device_id,))\n            device = cursor.fetchone()\n            conn.close()\n            return dict(device) if device else None\n        except Exception as e:\n            print(f\"Error getting device data: {e}\")\n            return None\n    \n    def _check_alert_exists(self, device_id, rule_name):\n        \"\"\"Check if alert already exists for this device/rule combination\"\"\"\n        try:\n            conn = self.db.get_connection()\n            cursor = conn.cursor()\n            cursor.execute('''\n                SELECT COUNT(*) FROM alerts \n                WHERE device_id = ? AND alert_type = ? AND status = 'active'\n            ''', (device_id, rule_name))\n            count = cursor.fetchone()[0]\n            conn.close()\n            return count > 0\n        except Exception as e:\n            print(f\"Error checking alert exists: {e}\")\n            return False\n    \n    def evaluate_rule(self, rule, device):\n        \"\"\"\n        Evaluate a single rule against a device\n        Returns True if rule triggers, False otherwise\n        \"\"\"\n        try:\n            condition = rule['condition']\n            threshold = rule['threshold']\n            device_id = device['id']\n            \n            # Skip if alert already exists\n            if self._check_alert_exists(device_id, rule['name']):\n                return False\n            \n            triggered = False\n            description = \"\"\n            \n            #device lifecycle\n            if condition == 'device_first_seen':\n                first_seen = datetime.strptime(device['first_seen'], '%Y-%m-%d %H:%M:%S')\n                hours_old = (datetime.now() - first_seen).total_seconds() / 3600\n                \n                # Only alert on untrusted devices\n                if hours_old <= threshold and device.get('is_trusted', 0) == 0:\n                    triggered = True\n                    description = f\"New untrusted device detected: {device['ip_address']} ({device['mac_address']})\"\n            \n            elif condition == 'device_disappeared':\n                if device['status'] == 'offline' and device.get('is_trusted', 0) == 1:\n                    last_seen = datetime.strptime(device['last_seen'], '%Y-%m-%d %H:%M:%S')\n                    hours_offline = (datetime.now() - last_seen).total_seconds() / 3600\n                    \n                    if hours_offline >= threshold:\n                        triggered = True\n                        description = f\"Trusted device offline for {int(hours_offline)} hours\"\n            \n            #  RECONNECTIONS \n            elif condition == 'reconnect_count':\n                if device.get('reconnect_count', 0) >= threshold:\n                    triggered = True\n                    description = f\"Device reconnected {device['reconnect_count']} times (threshold: {threshold})\"\n            \n            elif condition == 'reconnect_frequency':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(*) FROM events\n                    WHERE device_id = ? \n                    AND event_type = 'device_online'\n                    AND datetime(timestamp) >= datetime('now', '-10 minutes')\n                ''', (device_id,))\n                recent_count = cursor.fetchone()[0]\n                conn.close()\n                \n                if recent_count >= threshold:\n                    triggered = True\n                    description = f\"Device reconnected {recent_count} times in 10 minutes\"\n            \n            #  MAC ADDRESS \n            elif condition == 'mac_pattern':\n                suspicious_patterns = {\n                    'common_spoof': ['00:00:00', 'FF:FF:FF', '00:11:22', '33:33:33'],\n                    'vm_patterns': ['02:00:00', '03:00:00', '52:54:00', '08:00:27'],\n                    'broadcast': ['FF:FF:FF'],\n                    'all_suspicious': ['00:00:00', 'FF:FF:FF', '00:11:22', '33:33:33', '02:00:00', '03:00:00', '52:54:00', '08:00:27']\n                }\n                \n                patterns = suspicious_patterns.get(threshold, [])\n                mac_prefix = device['mac_address'][:8]\n                \n                if any(mac_prefix.startswith(p[:8]) for p in patterns) and device.get('is_trusted', 0) == 0:\n                    triggered = True\n                    description = f\"Suspicious MAC pattern detected: {device['mac_address']}\"\n            \n            elif condition == 'mac_changed':\n                # Check if this MAC has had multiple IPs\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(DISTINCT ip_address) FROM events \n                    WHERE device_id = ? AND event_type IN ('device_online', 'ip_changed')\n                ''', (device_id,))\n                unique_ips = cursor.fetchone()[0]\n                conn.close()\n                \n                if unique_ips > 1:\n                    triggered = True\n                    description = f\"MAC address has associated with multiple IPs\"\n            \n            #  VENDOR \n            elif condition == 'vendor_unknown':\n                if device['vendor'] == 'Unknown' and device.get('is_trusted', 0) == 0:\n                    triggered = True\n                    description = f\"Device with unknown vendor: {device['ip_address']}\"\n            \n            elif condition == 'suspicious_vendor':\n                # This is a placeholder - can be expanded with vendor lists\n                triggered = False\n            \n            #  IP ADDRESS \n            elif condition == 'ip_changed':\n                # Alert if trusted device's IP changed\n                if device.get('is_trusted', 0) == 1:\n                    conn = self.db.get_connection()\n                    cursor = conn.cursor()\n                    cursor.execute('''\n                        SELECT COUNT(DISTINCT ip_address) FROM devices \n                        WHERE mac_address = ?\n                    ''', (device['mac_address'],))\n                    ip_count = cursor.fetchone()[0]\n                    conn.close()\n                    \n                    if ip_count > 1:\n                        triggered = True\n                        description = f\"Trusted device IP address changed\"\n            \n            elif condition == 'rapid_ip_changes':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(DISTINCT ip_address) FROM events\n                    WHERE device_id = ? \n                    AND datetime(timestamp) >= datetime('now', '-1 hour')\n                ''', (device_id,))\n                ip_changes = cursor.fetchone()[0]\n                conn.close()\n                \n                if ip_changes >= threshold:\n                    triggered = True\n                    description = f\"Device cycled through {ip_changes} IPs in 1 hour\"\n            \n            elif condition == 'private_ip_overlap':\n                # Check for unusual IP ranges\n                triggered = False  # Placeholder for future implementation\n            \n            #  ACTIVITY \n            elif condition == 'inactive_duration':\n                if device['status'] == 'offline':\n                    last_seen = datetime.strptime(device['last_seen'], '%Y-%m-%d %H:%M:%S')\n                    hours_offline = (datetime.now() - last_seen).total_seconds() / 3600\n                    \n                    if hours_offline >= threshold:\n                        triggered = True\n                        description = f\"Device offline for {int(hours_offline)} hours\"\n            \n            elif condition == 'no_activity':\n                # Placeholder - requires traffic monitoring\n                triggered = False\n            \n            #  NETWORK LOCATION \n            elif condition == 'location_change':\n                # Placeholder - requires VLAN/subnet tracking\n                triggered = False\n            \n            elif condition == 'simultaneous_ips':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(DISTINCT ip_address) FROM devices \n                    WHERE mac_address = ? AND status = 'online'\n                ''', (device['mac_address'],))\n                active_ips = cursor.fetchone()[0]\n                conn.close()\n                \n                if active_ips >= threshold:\n                    triggered = True\n                    description = f\"One MAC has {active_ips} simultaneous IPs\"\n            \n            #  BEHAVIOR \n            elif condition == 'abnormal_scan':\n                # Placeholder - requires port scanning detection\n                triggered = False\n            \n            elif condition == 'broadcast_storm':\n                # Placeholder - requires broadcast monitoring\n                triggered = False\n            \n            elif condition == 'arp_spoofing':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(*) FROM events\n                    WHERE device_id = ? \n                    AND event_type = 'arp_conflict'\n                    AND datetime(timestamp) >= datetime('now', '-1 hour')\n                ''', (device_id,))\n                conflicts = cursor.fetchone()[0]\n                conn.close()\n                \n                if conflicts >= threshold:\n                    triggered = True\n                    description = f\"Detected {conflicts} ARP conflicts\"\n            \n            #  DEVICE TYPE \n            elif condition == 'unexpected_device_type':\n                # Placeholder - requires device type classification\n                triggered = False\n            \n            #  MULTI-CONDITION \n            elif condition == 'new_untrusted_behavior':\n                # Placeholder - requires behavior analysis\n                triggered = False\n            \n            elif condition == 'repeated_failures':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(*) FROM events\n                    WHERE device_id = ? \n                    AND event_type = 'auth_failure'\n                    AND datetime(timestamp) >= datetime('now', '-10 minutes')\n                ''', (device_id,))\n                failures = cursor.fetchone()[0]\n                conn.close()\n                \n                if failures >= threshold:\n                    triggered = True\n                    description = f\"Device had {failures} auth failures\"\n            \n            # Create alert if triggered\n            if triggered:\n                self.db.add_alert(\n                    alert_type=rule['name'],\n                    severity=rule.get('severity', 'medium'),\n                    title=f\"Alert: {rule['name']}\",\n                    description=description,\n                    device_id=device_id,\n                    metadata={\n                        'rule_id': rule['id'],\n                        'condition': condition,\n                        'threshold': threshold\n                    }\n                )\n                return True\n            \n            return False\n            \n        except Exception as e:\n            print(f\"Error evaluating rule {rule['name']}: {e}\")\n            return False\n    \n    def process_device_alerts(self, device_id):\n        \"\"\"Process all rules for a device\"\"\"\n        device = self._get_device_data(device_id)\n        \n        if not device:\n            return\n        \n        # Reload latest rules\n        self.reload_rules()\n        \n        # Evaluate each rule\n        for rule in self.rules:\n            try:\n                self.evaluate_rule(rule, device)\n            except Exception as e:\n                print(f\"Error processing rule {rule.get('name', 'unknown')}: {e}\")\n    \n    def run_periodic_checks(self):\n        \"\"\"Run periodic maintenance tasks\"\"\"\n        try:\n            # Check for devices that should be marked offline\n            conn = self.db.get_connection()\n            cursor = conn.cursor()\n            \n            # Mark devices offline if not seen in 5 seconds\n            inactive_threshold = datetime.now() - timedelta(seconds=5)\n            cursor.execute('''\n                SELECT id, ip_address \n                FROM devices \n                WHERE datetime(last_seen) < ? AND status = 'online'\n            ''', (inactive_threshold.strftime('%Y-%m-%d %H:%M:%S'),))\n            \n            offline_devices = cursor.fetchall()\n            conn.close()\n            \n            for device in offline_devices:\n                self.db.update_device_status(device['id'], 'offline')\n                self.db.add_event(\n                    event_type='device_offline',\n                    severity='info',\n                    description=f\"Device {device['ip_address']} went offline\",\n                    device_id=device['id']\n                )\n        \n        except Exception as e:\n            print(f\"Error in periodic checks: {e}\")","size_bytes":14578},"utils/cache.py":{"content":"\"\"\"\nCaching utilities for NetWatch SIEM\nProvides in-memory and Redis-based caching for improved performance\n\"\"\"\n\nimport time\nimport json\nimport hashlib\nfrom functools import wraps\nfrom typing import Any, Optional, Callable\nimport threading\n\nclass MemoryCache:\n    \"\"\"Thread-safe in-memory cache with TTL support\"\"\"\n    \n    def __init__(self, default_ttl=300):\n        self.cache = {}\n        self.timestamps = {}\n        self.default_ttl = default_ttl\n        self.lock = threading.RLock()\n    \n    def get(self, key: str) -> Optional[Any]:\n        \"\"\"Get value from cache\"\"\"\n        with self.lock:\n            if key in self.cache:\n                if time.time() - self.timestamps[key] < self.default_ttl:\n                    return self.cache[key]\n                else:\n                    # Expired, remove it\n                    del self.cache[key]\n                    del self.timestamps[key]\n            return None\n    \n    def set(self, key: str, value: Any, ttl: Optional[int] = None) -> None:\n        \"\"\"Set value in cache with TTL\"\"\"\n        with self.lock:\n            self.cache[key] = value\n            self.timestamps[key] = time.time()\n            if ttl:\n                self.default_ttl = ttl\n    \n    def delete(self, key: str) -> None:\n        \"\"\"Delete key from cache\"\"\"\n        with self.lock:\n            self.cache.pop(key, None)\n            self.timestamps.pop(key, None)\n    \n    def clear(self) -> None:\n        \"\"\"Clear all cache entries\"\"\"\n        with self.lock:\n            self.cache.clear()\n            self.timestamps.clear()\n    \n    def size(self) -> int:\n        \"\"\"Get cache size\"\"\"\n        with self.lock:\n            return len(self.cache)\n\n# Global cache instance\ncache = MemoryCache(default_ttl=300)\n\ndef cache_key(*args, **kwargs) -> str:\n    \"\"\"Generate cache key from arguments\"\"\"\n    key_data = {\n        'args': args,\n        'kwargs': sorted(kwargs.items())\n    }\n    key_string = json.dumps(key_data, sort_keys=True)\n    return hashlib.md5(key_string.encode()).hexdigest()\n\ndef cached(ttl: int = 300, key_func: Optional[Callable] = None):\n    \"\"\"Decorator for caching function results\"\"\"\n    def decorator(func: Callable) -> Callable:\n        @wraps(func)\n        def wrapper(*args, **kwargs):\n            # Generate cache key\n            if key_func:\n                cache_key_str = key_func(*args, **kwargs)\n            else:\n                cache_key_str = f\"{func.__name__}:{cache_key(*args, **kwargs)}\"\n            \n            # Try to get from cache\n            result = cache.get(cache_key_str)\n            if result is not None:\n                return result\n            \n            # Execute function and cache result\n            result = func(*args, **kwargs)\n            cache.set(cache_key_str, result, ttl)\n            return result\n        \n        return wrapper\n    return decorator\n\ndef invalidate_cache(pattern: str) -> None:\n    \"\"\"Invalidate cache entries matching pattern\"\"\"\n    with cache.lock:\n        keys_to_delete = [key for key in cache.cache.keys() if pattern in key]\n        for key in keys_to_delete:\n            cache.delete(key)\n\nclass DatabaseCache:\n    \"\"\"Database-specific caching utilities\"\"\"\n    \n    @staticmethod\n    def get_device_stats_key():\n        return \"device_stats\"\n    \n    @staticmethod\n    def get_alert_stats_key():\n        return \"alert_stats\"\n    \n    @staticmethod\n    def get_network_health_key():\n        return \"network_health\"\n    \n    @staticmethod\n    def get_device_list_key():\n        return \"device_list\"\n    \n    @staticmethod\n    def get_analytics_key(analytics_type: str):\n        return f\"analytics:{analytics_type}\"\n\n# Cache TTL constants (in seconds)\nCACHE_TTL = {\n    'device_stats': 60,      # 1 minute\n    'alert_stats': 30,       # 30 seconds\n    'network_health': 120,   # 2 minutes\n    'device_list': 30,       # 30 seconds\n    'analytics': 300,        # 5 minutes\n    'config': 600,           # 10 minutes\n    'rules': 300,            # 5 minutes\n}\n\ndef get_cache_ttl(cache_type: str) -> int:\n    \"\"\"Get TTL for cache type\"\"\"\n    return CACHE_TTL.get(cache_type, 300)\n\ndef cache_dashboard_stats(stats: dict) -> None:\n    \"\"\"Cache dashboard statistics\"\"\"\n    cache.set(DatabaseCache.get_device_stats_key(), stats, CACHE_TTL['device_stats'])\n\ndef get_cached_dashboard_stats() -> Optional[dict]:\n    \"\"\"Get cached dashboard statistics\"\"\"\n    return cache.get(DatabaseCache.get_device_stats_key())\n\ndef cache_network_health(health_data: dict) -> None:\n    \"\"\"Cache network health data\"\"\"\n    cache.set(DatabaseCache.get_network_health_key(), health_data, CACHE_TTL['network_health'])\n\ndef get_cached_network_health() -> Optional[dict]:\n    \"\"\"Get cached network health data\"\"\"\n    return cache.get(DatabaseCache.get_network_health_key())\n\ndef cache_analytics(analytics_type: str, data: dict) -> None:\n    \"\"\"Cache analytics data\"\"\"\n    cache.set(DatabaseCache.get_analytics_key(analytics_type), data, CACHE_TTL['analytics'])\n\ndef get_cached_analytics(analytics_type: str) -> Optional[dict]:\n    \"\"\"Get cached analytics data\"\"\"\n    return cache.get(DatabaseCache.get_analytics_key(analytics_type))\n\ndef invalidate_device_cache() -> None:\n    \"\"\"Invalidate all device-related cache\"\"\"\n    invalidate_cache(\"device\")\n    invalidate_cache(\"stats\")\n\ndef invalidate_alert_cache() -> None:\n    \"\"\"Invalidate all alert-related cache\"\"\"\n    invalidate_cache(\"alert\")\n    invalidate_cache(\"stats\")\n\ndef invalidate_analytics_cache() -> None:\n    \"\"\"Invalidate all analytics cache\"\"\"\n    invalidate_cache(\"analytics\")\n","size_bytes":5532},"replit.md":{"content":"# NetWatch SIEM - Replit Setup\n\n## Overview\nNetWatch SIEM is an enterprise-grade Security Information and Event Management System built with Flask. This project provides network monitoring, alert management, and security event tracking capabilities through a modern web interface.\n\n## Project Information\n- **Type**: Flask Web Application (SIEM Platform)\n- **Language**: Python 3.11+\n- **Framework**: Flask 3.1.2 with Flask-SocketIO for real-time features\n- **Database**: SQLite 3 (netwatch.db)\n- **Frontend**: HTML5, JavaScript, Tailwind CSS\n- **Real-time Communication**: Socket.IO (WebSockets)\n\n## Current State\nThe application is fully configured and running in the Replit environment:\n- ✅ All Python dependencies installed\n- ✅ Workflow configured on port 5000\n- ✅ Database initialized with default admin user\n- ✅ Deployment configuration set to autoscale\n- ✅ Application accessible via webview\n\n## Default Login Credentials\n**IMPORTANT**: Use these credentials for first login, then change the password immediately!\n- **Username**: `admin`\n- **Password**: `admin123`\n\n## Key Features\n- Multi-User Authentication with PBKDF2 hashing\n- Role-based access control (Admin, Operator, Analyst, Viewer)\n- Smart Alert Engine with context-aware processing\n- Custom Security Rules System\n- Real-Time Dashboard with WebSocket updates\n- Multi-Language Support (English, Spanish, French, German, Chinese)\n- Advanced Analytics and reporting\n- RESTful API for programmatic access\n\n## Architecture\n\n### Project Structure\n```\nnetwatch-siem/\n├── app.py                  # Main Flask application\n├── config.py              # Configuration settings\n├── database/              # Database models and operations\n│   ├── models.py         # SQLite database management\n├── models/               # User management\n│   └── user.py          # User model and authentication\n├── security/            # Security features\n│   ├── auth.py         # Authentication middleware\n│   ├── rbac.py         # Role-based access control\n│   └── schemas.py      # Input validation schemas\n├── scanner/            # Network scanning modules\n│   ├── device_scanner.py\n│   ├── enhanced_scanner.py\n│   ├── hostname_resolver.py\n│   └── network_scanner.py\n├── monitoring/         # Advanced monitoring\n│   ├── advanced_scanner.py\n│   └── traffic_analyzer.py\n├── rules/             # Alert rules engine\n│   ├── alert_engine.py\n│   ├── smart_alert_engine.py\n│   └── condition_metadata.py\n├── i18n/             # Internationalization\n│   └── translations/ # Language files\n├── static/          # CSS and JavaScript\n├── templates/       # HTML templates\n└── utils/          # Utility functions\n```\n\n### Database Schema\nThe SQLite database includes:\n- **devices** - Network device inventory\n- **alerts** - Security alerts and notifications\n- **rules** - Custom alert rule definitions\n- **users** - User accounts and authentication\n- **events** - System and network event log\n- **system_config** - Persistent configuration\n\n## Replit Configuration\n\n### Workflow\n- **Name**: NetWatch SIEM\n- **Command**: `python app.py`\n- **Port**: 5000 (exposed via webview)\n- **Host**: 0.0.0.0 (configured for Replit proxy)\n\n### Deployment\n- **Type**: Autoscale (stateless web application)\n- **Command**: `python app.py`\n\n### Environment Variables\nThe application uses the following environment variables:\n- `SESSION_SECRET` - Flask session secret key (auto-generated if not set)\n- `ADMIN_USERNAME` - Override default admin username (optional)\n- `ADMIN_PASSWORD` - Override default admin password (optional)\n\n## Dependencies\nAll dependencies are managed via `pyproject.toml`:\n- flask (3.1.2) - Web framework\n- flask-socketio (5.5.1) - WebSocket support\n- werkzeug (3.1.3) - WSGI utilities\n- scapy (2.6.1) - Network packet manipulation\n- python-nmap (0.7.1) - Network scanning\n- psutil (7.1.0) - System monitoring\n- dnspython (2.8.0) - DNS utilities\n- requests (2.32.5) - HTTP client\n\n## Limitations in Replit Environment\n\n### Network Scanning\nNetwork scanning features (ARP scanning, port scanning, packet capture) require root/administrator privileges and are **limited in containerized environments** like Replit. The application handles this gracefully:\n- Network scanner will show limited results\n- All other features (web interface, user management, alerts, analytics) work fully\n- The application automatically continues without network scanning privileges\n\n### What Works Fully\n- ✅ Web interface and dashboard\n- ✅ User authentication and management\n- ✅ Alert management (manual and rule-based)\n- ✅ Custom rule creation and testing\n- ✅ Analytics and reporting\n- ✅ Real-time WebSocket updates\n- ✅ Multi-language support\n- ✅ RESTful API\n\n## API Endpoints\n- `GET /api/dashboard/stats` - Dashboard statistics\n- `GET/POST /api/devices` - Device management\n- `GET/POST /api/alerts` - Alert management\n- `GET/POST /api/rules` - Custom rule management\n- `GET /api/analytics/*` - Analytics data\n- `GET/POST /api/users` - User management (admin only)\n\n## Recent Changes (Import Setup - Nov 7, 2025)\n- Installed all Python dependencies via packager\n- Configured workflow for port 5000 with webview\n- Set up deployment configuration for autoscale\n- Database auto-initialized with default admin user\n- Application verified running and accessible\n\n## Security Notes\n- Change default admin password immediately after first login\n- All passwords are hashed using PBKDF2\n- CSRF protection enabled\n- Session management with secure cookies\n- Role-based access control enforced on all routes\n\n## Development Notes\n- The application uses SQLite in WAL mode for better concurrency\n- WebSocket connections use threading mode for real-time updates\n- Database initialization happens automatically on first run\n- Translations are loaded from i18n/translations/ directory\n\n## For Production Use\nIf deploying to production outside Replit:\n1. Use a production WSGI server (gunicorn recommended)\n2. Set a strong SESSION_SECRET environment variable\n3. Consider using PostgreSQL instead of SQLite for better scalability\n4. Install Tailwind CSS properly (currently using CDN)\n5. Run with elevated privileges if network scanning is needed\n\n## Support\nFor issues or questions about the NetWatch SIEM platform, refer to the main README.md and NetWatch SIEM.md documentation files.\n","size_bytes":6501},"security/schemas.py":{"content":"\"\"\"\nInput validation schemas for NetWatch SIEM\nDefines validation rules for all API endpoints\n\"\"\"\n\n# Device management schemas\nDEVICE_TRUST_SCHEMA = {\n    'is_trusted': {'type': 'int', 'required': True}\n}\n\nDEVICE_NAME_SCHEMA = {\n    'name': {'type': 'str', 'required': True, 'max_length': 100}\n}\n\nDEVICE_DELETE_SCHEMA = {\n    'device_ids': {'type': 'list', 'required': True}\n}\n\n# Alert management schemas\nALERT_DELETE_SCHEMA = {\n    'alert_ids': {'type': 'list', 'required': False},\n    'delete_resolved': {'type': 'bool', 'required': False}\n}\n\n# Configuration schemas\nCONFIG_SAVE_SCHEMA = {\n    'scan_interval': {'type': 'int', 'required': False, 'min': 30, 'max': 600},\n    'scanning_active': {'type': 'bool', 'required': False},\n    'traffic_monitoring': {'type': 'bool', 'required': False},\n    'extended_logs': {'type': 'bool', 'required': False},\n    'email_alerts': {'type': 'bool', 'required': False},\n    'rules': {'type': 'dict', 'required': False}\n}\n\n# Rule management schemas\nRULE_ADD_SCHEMA = {\n    'name': {'type': 'str', 'required': True, 'min_length': 3, 'max_length': 50},\n    'rule_type': {'type': 'str', 'required': True},\n    'condition': {'type': 'str', 'required': True},\n    'threshold': {'type': 'int', 'required': True, 'min': 1},\n    'severity': {'type': 'str', 'required': True}\n}\n\nRULE_UPDATE_SCHEMA = {\n    'name': {'type': 'str', 'required': True, 'min_length': 3, 'max_length': 50},\n    'condition': {'type': 'str', 'required': True},\n    'threshold': {'type': 'int', 'required': True, 'min': 1},\n    'severity': {'type': 'str', 'required': True}\n}\n\nRULE_TOGGLE_SCHEMA = {\n    'enabled': {'type': 'bool', 'required': True}\n}\n\nRULE_TEST_SCHEMA = {\n    'name': {'type': 'str', 'required': True, 'min_length': 3, 'max_length': 50},\n    'condition': {'type': 'str', 'required': True},\n    'threshold': {'type': 'int', 'required': True, 'min': 1},\n    'severity': {'type': 'str', 'required': True},\n    'device_id': {'type': 'int', 'required': True}\n}\n\n# Language management schemas\nLANGUAGE_SET_SCHEMA = {\n    'language': {'type': 'str', 'required': True, 'max_length': 5}\n}\n\n# Event management schemas\nEVENT_DELETE_SCHEMA = {\n    'event_ids': {'type': 'list', 'required': False},\n    'delete_all': {'type': 'bool', 'required': False}\n}\n\n# Search schemas\nDEVICE_SEARCH_SCHEMA = {\n    'q': {'type': 'str', 'required': False, 'max_length': 100}\n}\n\n# Valid values for enum fields\nVALID_SEVERITIES = ['low', 'medium', 'high']\nVALID_RULE_TYPES = ['device_event', 'network_event', 'security_event']\nVALID_CONDITIONS = [\n    'device_first_seen', 'reconnect_count', 'inactive_duration',\n    'mac_pattern', 'vendor_unknown', 'ip_changed'\n]\nVALID_LANGUAGES = ['en', 'es', 'fr', 'de', 'zh']\n\ndef validate_enum_field(value, valid_values, field_name):\n    \"\"\"Validate enum field values\"\"\"\n    if value not in valid_values:\n        return f\"{field_name} must be one of: {', '.join(valid_values)}\"\n    return None\n\ndef validate_rule_data(data):\n    \"\"\"Comprehensive rule validation\"\"\"\n    errors = []\n    \n    # Validate severity\n    if 'severity' in data:\n        error = validate_enum_field(data['severity'], VALID_SEVERITIES, 'severity')\n        if error:\n            errors.append(error)\n    \n    # Validate rule_type\n    if 'rule_type' in data:\n        error = validate_enum_field(data['rule_type'], VALID_RULE_TYPES, 'rule_type')\n        if error:\n            errors.append(error)\n    \n    # Validate condition\n    if 'condition' in data:\n        error = validate_enum_field(data['condition'], VALID_CONDITIONS, 'condition')\n        if error:\n            errors.append(error)\n    \n    # Validate language\n    if 'language' in data:\n        error = validate_enum_field(data['language'], VALID_LANGUAGES, 'language')\n        if error:\n            errors.append(error)\n    \n    return errors\n","size_bytes":3807},"database/__init__.py":{"content":"","size_bytes":0},"i18n/__init__.py":{"content":"# Internationalization support for NetWatch SIEM\nimport os\nimport json\nfrom flask import request, session\n\nclass I18nManager:\n    def __init__(self, app=None):\n        self.app = app\n        self.translations = {}\n        self.default_language = 'en'\n        self.supported_languages = ['en', 'es', 'fr', 'de', 'zh']\n        \n        if app:\n            self.init_app(app)\n    \n    def init_app(self, app):\n        \"\"\"Initialize the i18n manager with Flask app\"\"\"\n        self.app = app\n        app.config.setdefault('I18N_DEFAULT_LANGUAGE', 'en')\n        app.config.setdefault('I18N_TRANSLATIONS_PATH', 'i18n/translations')\n        \n        self.default_language = app.config['I18N_DEFAULT_LANGUAGE']\n        self.load_translations()\n        \n        # Add template context processor\n        @app.context_processor\n        def inject_i18n():\n            return {\n                'gettext': self.gettext,\n                'current_language': self.get_current_language(),\n                'supported_languages': self.supported_languages\n            }\n    \n    def load_translations(self):\n        \"\"\"Load all translation files\"\"\"\n        if not self.app:\n            return\n        \n        import os\n        # Get the app root directory (where app.py is located)\n        app_root = self.app.root_path\n        translations_path = os.path.join(app_root, 'i18n', 'translations')\n        \n        for lang in self.supported_languages:\n            try:\n                file_path = os.path.join(translations_path, f'{lang}.json')\n                with open(file_path, 'r', encoding='utf-8') as f:\n                    self.translations[lang] = json.load(f)\n                    print(f\"Loaded translations for {lang}\")\n            except FileNotFoundError:\n                print(f\"Warning: Translation file for {lang} not found at {file_path}\")\n                self.translations[lang] = {}\n    \n    def get_current_language(self):\n        \"\"\"Get current language from session or request\"\"\"\n        try:\n            # Check session first\n            if 'language' in session:\n                return session['language']\n            \n            # Check request headers\n            if request and hasattr(request, 'headers'):\n                accept_language = request.headers.get('Accept-Language', '')\n                for lang in self.supported_languages:\n                    if lang in accept_language:\n                        return lang\n        except:\n            pass\n        \n        return self.default_language\n    \n    def set_language(self, language):\n        \"\"\"Set language in session\"\"\"\n        try:\n            if language in self.supported_languages:\n                session['language'] = language\n                return True\n        except:\n            pass\n        return False\n    \n    def gettext(self, key, **kwargs):\n        \"\"\"Get translated text for current language\"\"\"\n        current_lang = self.get_current_language()\n        translations = self.translations.get(current_lang, {})\n        \n        # Get the translation, fallback to English if not found\n        text = translations.get(key, key)\n        \n        # If still not found in current language, try English\n        if text == key and current_lang != 'en':\n            english_translations = self.translations.get('en', {})\n            text = english_translations.get(key, key)\n        \n        # Replace placeholders\n        if kwargs:\n            try:\n                text = text.format(**kwargs)\n            except (KeyError, ValueError):\n                pass\n        \n        return text\n    \n    def get_available_languages(self):\n        \"\"\"Get list of available languages with their display names\"\"\"\n        return {\n            'en': 'English',\n            'es': 'Español',\n            'fr': 'Français',\n            'de': 'Deutsch',\n            'zh': '中文'\n        }\n\n# Global instance\ni18n = I18nManager()\n","size_bytes":3892},"models/__init__.py":{"content":"\"\"\"\nModels package for NetWatch SIEM\nContains user management and other data models\n\"\"\"\n\nfrom .user import UserManager\n\n__all__ = ['UserManager']\n","size_bytes":146},"scanner/hostname_resolver.py":{"content":"\"\"\"\nEnhanced Hostname Resolution for NetWatch SIEM\nProvides multiple fallback methods for reliable device name detection\nCross-platform compatible (Windows/Linux/macOS)\n\"\"\"\n\nimport socket\nimport subprocess\nimport platform\nimport time\nimport re\nfrom concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError\nimport logging\n\nclass EnhancedHostnameResolver:\n    def __init__(self, timeout=1, max_workers=4):\n        self.timeout = timeout\n        self.max_workers = max_workers\n        self.cache = {}\n        self.cache_ttl = 300  # 5 minutes\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.ERROR)  # Silent by default\n        self.os_type = platform.system().lower()\n        \n    def resolve_hostname(self, ip):\n        \"\"\"\n        Resolve hostname using multiple methods with fallbacks\n        Returns the best available hostname or None\n        \"\"\"\n        # Validate IP\n        if not self._is_valid_ip(ip):\n            return None\n            \n        # Check cache first\n        if ip in self.cache:\n            cached_result, timestamp = self.cache[ip]\n            if time.time() - timestamp < self.cache_ttl:\n                return cached_result\n        \n        # Try multiple resolution methods (fast ones first)\n        methods = [\n            self._dns_reverse_lookup,\n            self._netbios_lookup,\n            self._mdns_lookup,\n        ]\n        \n        best_hostname = None\n        \n        # Try methods sequentially (faster than parallel for small number)\n        for method in methods:\n            try:\n                result = method(ip)\n                if result and self._is_valid_hostname(result, ip):\n                    best_hostname = result\n                    break  # Use first valid result\n            except Exception as e:\n                continue\n        \n        # Cache the result (even if None)\n        self.cache[ip] = (best_hostname, time.time())\n        \n        return best_hostname\n    \n    def _is_valid_ip(self, ip):\n        \"\"\"Validate IP address format\"\"\"\n        try:\n            parts = ip.split('.')\n            return len(parts) == 4 and all(0 <= int(p) <= 255 for p in parts)\n        except:\n            return False\n    \n    def _is_valid_hostname(self, hostname, ip):\n        \"\"\"Check if hostname is valid and different from IP\"\"\"\n        if not hostname or len(hostname) < 2:\n            return False\n        \n        # Hostname shouldn't be the IP itself\n        if hostname == ip:\n            return False\n        \n        # Shouldn't be another IP address\n        if re.match(r'^\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}$', hostname):\n            return False\n        \n        # Shouldn't contain only numbers\n        if hostname.replace('.', '').replace('-', '').isdigit():\n            return False\n        \n        return True\n    \n    def _dns_reverse_lookup(self, ip):\n        \"\"\"Standard DNS reverse lookup - Most reliable method\"\"\"\n        try:\n            # Set socket timeout\n            old_timeout = socket.getdefaulttimeout()\n            socket.setdefaulttimeout(self.timeout)\n            \n            try:\n                hostname, _, _ = socket.gethostbyaddr(ip)\n                # Clean up the hostname\n                hostname = hostname.split('.')[0]  # Remove domain\n                return hostname if hostname else None\n            finally:\n                socket.setdefaulttimeout(old_timeout)\n                \n        except socket.herror:\n            # No reverse DNS entry\n            return None\n        except socket.timeout:\n            return None\n        except Exception as e:\n            return None\n    \n    def _netbios_lookup(self, ip):\n        \"\"\"NetBIOS name resolution (Windows/SMB networks)\"\"\"\n        if self.os_type != 'windows':\n            return None\n            \n        try:\n            # Windows-specific NetBIOS lookup\n            result = subprocess.run(\n                ['nbtstat', '-A', ip],\n                capture_output=True,\n                text=True,\n                timeout=self.timeout,\n                creationflags=subprocess.CREATE_NO_WINDOW if self.os_type == 'windows' else 0\n            )\n            \n            if result.returncode == 0:\n                lines = result.stdout.split('\\n')\n                for line in lines:\n                    # Look for the computer name (type <00>)\n                    if '<00>' in line and 'UNIQUE' in line:\n                        parts = line.split()\n                        if len(parts) > 0:\n                            name = parts[0].strip()\n                            if name and len(name) > 1:\n                                return name\n        except subprocess.TimeoutExpired:\n            return None\n        except FileNotFoundError:\n            # nbtstat not available\n            return None\n        except Exception as e:\n            return None\n        \n        return None\n    \n    def _mdns_lookup(self, ip):\n        \"\"\"\n        mDNS/Bonjour lookup (Apple devices, IoT)\n        Works on local network for devices advertising via mDNS\n        \"\"\"\n        try:\n            # Try getfqdn which sometimes resolves mDNS names\n            hostname = socket.getfqdn(ip)\n            if hostname and hostname != ip:\n                # Clean up .local domain if present\n                hostname = hostname.replace('.local', '')\n                hostname = hostname.split('.')[0]\n                return hostname\n        except Exception as e:\n            return None\n        \n        return None\n    \n    def _ping_hostname_extract(self, ip):\n        \"\"\"\n        Extract hostname from ping response\n        Sometimes ping reveals the hostname\n        \"\"\"\n        try:\n            if self.os_type == 'windows':\n                cmd = ['ping', '-n', '1', '-w', str(self.timeout * 1000), ip]\n            else:\n                cmd = ['ping', '-c', '1', '-W', str(self.timeout), ip]\n            \n            result = subprocess.run(\n                cmd,\n                capture_output=True,\n                text=True,\n                timeout=self.timeout + 0.5,\n                creationflags=subprocess.CREATE_NO_WINDOW if self.os_type == 'windows' else 0\n            )\n            \n            if result.returncode == 0:\n                output = result.stdout\n                \n                # Windows: \"Pinging hostname [IP]\"\n                match = re.search(r'Pinging\\s+([^\\s\\[]+)\\s+\\[', output)\n                if match:\n                    hostname = match.group(1)\n                    if hostname and hostname != ip:\n                        return hostname\n                \n                # Linux: \"PING hostname (IP)\"\n                match = re.search(r'PING\\s+([^\\s(]+)\\s+\\(', output)\n                if match:\n                    hostname = match.group(1)\n                    if hostname and hostname != ip:\n                        return hostname\n        \n        except subprocess.TimeoutExpired:\n            return None\n        except Exception as e:\n            return None\n        \n        return None\n    \n    def resolve_with_ping(self, ip):\n        \"\"\"\n        Public method to try ping-based hostname resolution\n        Slower but sometimes catches what DNS misses\n        \"\"\"\n        return self._ping_hostname_extract(ip)\n    \n    def resolve_multiple_hostnames(self, ip_list):\n        \"\"\"Resolve hostnames for multiple IPs efficiently\"\"\"\n        results = {}\n        \n        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n            future_to_ip = {\n                executor.submit(self.resolve_hostname, ip): ip \n                for ip in ip_list\n            }\n            \n            for future in as_completed(future_to_ip, timeout=self.timeout * len(ip_list)):\n                ip = future_to_ip[future]\n                try:\n                    hostname = future.result(timeout=self.timeout)\n                    results[ip] = hostname\n                except TimeoutError:\n                    results[ip] = None\n                except Exception as e:\n                    results[ip] = None\n        \n        return results\n    \n    def clear_cache(self):\n        \"\"\"Clear the hostname cache\"\"\"\n        self.cache.clear()\n    \n    def get_cache_stats(self):\n        \"\"\"Get cache statistics\"\"\"\n        valid_entries = sum(1 for v, _ in self.cache.values() if v is not None)\n        return {\n            'total_cached': len(self.cache),\n            'valid_hostnames': valid_entries,\n            'cache_ttl_seconds': self.cache_ttl,\n            'cache_hit_rate': f\"{(valid_entries/len(self.cache)*100):.1f}%\" if self.cache else \"0%\"\n        }\n    \n    def set_cache_ttl(self, seconds):\n        \"\"\"Set cache time-to-live in seconds\"\"\"\n        self.cache_ttl = seconds\n    \n    def enable_debug(self):\n        \"\"\"Enable debug logging\"\"\"\n        self.logger.setLevel(logging.DEBUG)\n    \n    def disable_debug(self):\n        \"\"\"Disable debug logging\"\"\"\n        self.logger.setLevel(logging.ERROR)\n\n\n# Global instance for easy import\nhostname_resolver = EnhancedHostnameResolver(timeout=1, max_workers=4)\n\n\n# Convenience functions for direct use\ndef resolve_hostname(ip, timeout=1):\n    \"\"\"Quick hostname resolution for single IP\"\"\"\n    resolver = EnhancedHostnameResolver(timeout=timeout)\n    return resolver.resolve_hostname(ip)\n\n\ndef resolve_multiple(ip_list, timeout=1, max_workers=4):\n    \"\"\"Quick hostname resolution for multiple IPs\"\"\"\n    resolver = EnhancedHostnameResolver(timeout=timeout, max_workers=max_workers)\n    return resolver.resolve_multiple_hostnames(ip_list)\n\n\n# Testing function\ndef test_resolver():\n    \"\"\"Test the hostname resolver\"\"\"\n    print(\"Testing EnhancedHostnameResolver...\")\n    print(f\"OS: {platform.system()}\")\n    \n    # Test IPs (common router/gateway addresses)\n    test_ips = ['192.168.1.1', '192.168.0.1', '8.8.8.8', '1.1.1.1']\n    \n    resolver = EnhancedHostnameResolver()\n    resolver.enable_debug()\n    \n    print(\"\\nTesting individual resolution:\")\n    for ip in test_ips:\n        hostname = resolver.resolve_hostname(ip)\n        print(f\"  {ip} -> {hostname if hostname else 'No hostname found'}\")\n    \n    print(\"\\nCache stats:\")\n    stats = resolver.get_cache_stats()\n    for key, value in stats.items():\n        print(f\"  {key}: {value}\")\n    \n    print(\"\\nTesting batch resolution:\")\n    results = resolver.resolve_multiple_hostnames(test_ips)\n    for ip, hostname in results.items():\n        print(f\"  {ip} -> {hostname if hostname else 'No hostname found'}\")\n\n\nif __name__ == '__main__':\n    test_resolver()","size_bytes":10502},"static/js/analytics.js":{"content":"// Enhanced Analytics Dashboard with Useful Charts\nlet charts = {};\n\n// Chart configuration\nconst chartConfig = {\n    responsive: true,\n    maintainAspectRatio: false,\n    plugins: {\n        legend: {\n            labels: {\n                color: '#94a3b8',\n                font: {\n                    size: 12\n                }\n            }\n        },\n        tooltip: {\n            backgroundColor: 'rgba(15, 23, 42, 0.9)',\n            borderColor: '#3b82f6',\n            borderWidth: 1,\n            titleColor: '#e2e8f0',\n            bodyColor: '#cbd5e1',\n            padding: 12,\n            cornerRadius: 6\n        }\n    },\n    scales: {\n        y: {\n            grid: {\n                color: 'rgba(51, 65, 85, 0.3)',\n                drawBorder: false\n            },\n            ticks: {\n                color: '#94a3b8',\n                font: {\n                    size: 11\n                }\n            }\n        },\n        x: {\n            grid: {\n                color: 'rgba(51, 65, 85, 0.2)',\n                drawBorder: false\n            },\n            ticks: {\n                color: '#94a3b8',\n                font: {\n                    size: 11\n                }\n            }\n        }\n    }\n};\n\n// Load network health data\nasync function loadNetworkHealth() {\n    try {\n        const response = await fetch('/api/analytics/network-health');\n        const data = await response.json();\n        \n        if (data.success) {\n            document.getElementById('healthScore').textContent = data.data.health_score;\n            document.getElementById('onlineCount').textContent = data.data.online_devices;\n            document.getElementById('trustedCount').textContent = data.data.trusted_devices;\n            document.getElementById('alertsCount').textContent = data.data.active_alerts;\n            document.getElementById('activityCount').textContent = data.data.recent_activity;\n            \n            // Update health score color\n            const healthScore = data.data.health_score;\n            const healthElement = document.getElementById('healthScore');\n            if (healthScore >= 80) {\n                healthElement.className = 'text-3xl font-bold text-emerald-400';\n            } else if (healthScore >= 60) {\n                healthElement.className = 'text-3xl font-bold text-yellow-400';\n            } else {\n                healthElement.className = 'text-3xl font-bold text-red-400';\n            }\n        }\n    } catch (error) {\n        console.error('Error loading network health:', error);\n    }\n}\n\n// Load device trends\nasync function loadDeviceTrends() {\n    try {\n        const response = await fetch('/api/analytics/device-trends');\n        const data = await response.json();\n        \n        if (data.success) {\n            // Device status distribution\n            createStatusChart(data.data.status_distribution);\n            \n            // Vendor distribution\n            createVendorChart(data.data.vendor_distribution);\n            \n            // Device trends over time\n            createDeviceTrendsChart(data.data.device_trends);\n        }\n    } catch (error) {\n        console.error('Error loading device trends:', error);\n    }\n}\n\n// Load alert trends\nasync function loadAlertTrends() {\n    try {\n        const response = await fetch('/api/analytics/alert-trends');\n        const data = await response.json();\n        \n        if (data.success) {\n            // Alert trends chart\n            createAlertTrendsChart(data.data.alert_trends);\n            \n            // Hourly alert pattern\n            createHourlyChart(data.data.hourly_alerts);\n            \n            // Alert types list\n            createAlertTypesList(data.data.alert_types);\n        }\n    } catch (error) {\n        console.error('Error loading alert trends:', error);\n    }\n}\n\n// Create device status pie chart\nfunction createStatusChart(data) {\n    const ctx = document.getElementById('statusChart').getContext('2d');\n    \n    if (charts.statusChart) {\n        charts.statusChart.destroy();\n    }\n    \n    const colors = {\n        'online': '#10b981',\n        'offline': '#ef4444',\n        'unknown': '#f59e0b'\n    };\n    \n    charts.statusChart = new Chart(ctx, {\n        type: 'doughnut',\n        data: {\n            labels: data.map(item => item.status),\n            datasets: [{\n                data: data.map(item => item.count),\n                backgroundColor: data.map(item => colors[item.status] || '#6b7280'),\n                borderWidth: 0\n            }]\n        },\n        options: {\n            ...chartConfig,\n            plugins: {\n                ...chartConfig.plugins,\n                legend: {\n                    position: 'bottom',\n                    labels: {\n                        color: '#94a3b8',\n                        padding: 20,\n                        usePointStyle: true\n                    }\n                }\n            }\n        }\n    });\n}\n\n// Create vendor distribution chart\nfunction createVendorChart(data) {\n    const ctx = document.getElementById('vendorChart').getContext('2d');\n    \n    if (charts.vendorChart) {\n        charts.vendorChart.destroy();\n    }\n    \n    const colors = [\n        '#3b82f6', '#10b981', '#f59e0b', '#ef4444', '#8b5cf6',\n        '#06b6d4', '#84cc16', '#f97316', '#ec4899', '#6366f1'\n    ];\n    \n    charts.vendorChart = new Chart(ctx, {\n        type: 'bar',\n        data: {\n            labels: data.map(item => item.vendor),\n            datasets: [{\n                label: 'Device Count',\n                data: data.map(item => item.count),\n                backgroundColor: colors.slice(0, data.length),\n                borderColor: colors.slice(0, data.length),\n                borderWidth: 1\n            }]\n        },\n        options: {\n            ...chartConfig,\n            indexAxis: 'y'\n        }\n    });\n}\n\n// Create alert trends chart\nfunction createAlertTrendsChart(data) {\n    const ctx = document.getElementById('alertTrendsChart').getContext('2d');\n    \n    if (charts.alertTrendsChart) {\n        charts.alertTrendsChart.destroy();\n    }\n    \n    charts.alertTrendsChart = new Chart(ctx, {\n        type: 'line',\n        data: {\n            labels: data.map(item => new Date(item.date).toLocaleDateString()),\n            datasets: [\n                {\n                    label: 'High Severity',\n                    data: data.map(item => item.high),\n                    borderColor: '#ef4444',\n                    backgroundColor: 'rgba(239, 68, 68, 0.1)',\n                    tension: 0.4\n                },\n                {\n                    label: 'Medium Severity',\n                    data: data.map(item => item.medium),\n                    borderColor: '#f59e0b',\n                    backgroundColor: 'rgba(245, 158, 11, 0.1)',\n                    tension: 0.4\n                },\n                {\n                    label: 'Low Severity',\n                    data: data.map(item => item.low),\n                    borderColor: '#3b82f6',\n                    backgroundColor: 'rgba(59, 130, 246, 0.1)',\n                    tension: 0.4\n                }\n            ]\n        },\n        options: chartConfig\n    });\n}\n\n// Create hourly alert pattern chart\nfunction createHourlyChart(data) {\n    const ctx = document.getElementById('hourlyChart').getContext('2d');\n    \n    if (charts.hourlyChart) {\n        charts.hourlyChart.destroy();\n    }\n    \n    // Fill in missing hours with 0\n    const hourlyData = Array.from({length: 24}, (_, i) => {\n        const hourData = data.find(item => item.hour === i);\n        return hourData ? hourData.count : 0;\n    });\n    \n    charts.hourlyChart = new Chart(ctx, {\n        type: 'bar',\n        data: {\n            labels: Array.from({length: 24}, (_, i) => `${i}:00`),\n            datasets: [{\n                label: 'Alerts',\n                data: hourlyData,\n                backgroundColor: 'rgba(59, 130, 246, 0.6)',\n                borderColor: '#3b82f6',\n                borderWidth: 1\n            }]\n        },\n        options: {\n            ...chartConfig,\n            scales: {\n                ...chartConfig.scales,\n                x: {\n                    ...chartConfig.scales.x,\n                    ticks: {\n                        ...chartConfig.scales.x.ticks,\n                        maxTicksLimit: 12\n                    }\n                }\n            }\n        }\n    });\n}\n\n// Create device trends chart\nfunction createDeviceTrendsChart(data) {\n    const ctx = document.getElementById('deviceTrendsChart').getContext('2d');\n    \n    if (charts.deviceTrendsChart) {\n        charts.deviceTrendsChart.destroy();\n    }\n    \n    charts.deviceTrendsChart = new Chart(ctx, {\n        type: 'line',\n        data: {\n            labels: data.map(item => new Date(item.date).toLocaleDateString()),\n            datasets: [{\n                label: 'New Devices',\n                data: data.map(item => item.count),\n                borderColor: '#10b981',\n                backgroundColor: 'rgba(16, 185, 129, 0.1)',\n                tension: 0.4,\n                fill: true\n            }]\n        },\n        options: chartConfig\n    });\n}\n\n// Create risk level chart\nfunction createRiskChart(riskData) {\n    const ctx = document.getElementById('riskChart').getContext('2d');\n    \n    if (charts.riskChart) {\n        charts.riskChart.destroy();\n    }\n    \n    const colors = {\n        'minimal': '#10b981',\n        'low': '#3b82f6',\n        'medium': '#f59e0b',\n        'high': '#ef4444'\n    };\n    \n    charts.riskChart = new Chart(ctx, {\n        type: 'doughnut',\n        data: {\n            labels: riskData.map(item => item.level),\n            datasets: [{\n                data: riskData.map(item => item.count),\n                backgroundColor: riskData.map(item => colors[item.level] || '#6b7280'),\n                borderWidth: 0\n            }]\n        },\n        options: {\n            ...chartConfig,\n            plugins: {\n                ...chartConfig.plugins,\n                legend: {\n                    position: 'bottom',\n                    labels: {\n                        color: '#94a3b8',\n                        padding: 20,\n                        usePointStyle: true\n                    }\n                }\n            }\n        }\n    });\n}\n\n// Create alert types list\nfunction createAlertTypesList(alertTypes) {\n    const container = document.getElementById('alertTypesList');\n    \n    if (alertTypes.length === 0) {\n        container.innerHTML = '<p class=\"text-slate-400 text-sm col-span-full text-center\">No alert types data available</p>';\n        return;\n    }\n    \n    const colors = ['#ef4444', '#f59e0b', '#3b82f6', '#10b981', '#8b5cf6', '#06b6d4'];\n    \n    container.innerHTML = alertTypes.map((item, index) => `\n        <div class=\"cyber-card rounded-lg p-4\">\n            <div class=\"flex items-center justify-between mb-2\">\n                <h3 class=\"font-medium text-slate-200\">${item.type.replace(/_/g, ' ').toUpperCase()}</h3>\n                <span class=\"text-2xl font-bold\" style=\"color: ${colors[index % colors.length]}\">${item.count}</span>\n            </div>\n            <div class=\"w-full bg-slate-700 rounded-full h-2\">\n                <div class=\"h-2 rounded-full\" style=\"background-color: ${colors[index % colors.length]}; width: ${(item.count / Math.max(...alertTypes.map(t => t.count))) * 100}%\"></div>\n            </div>\n        </div>\n    `).join('');\n}\n\n// Load risk levels from network health data\nasync function loadRiskLevels() {\n    try {\n        const response = await fetch('/api/analytics/network-health');\n        const data = await response.json();\n        \n        if (data.success && data.data.risk_levels) {\n            createRiskChart(data.data.risk_levels);\n        }\n    } catch (error) {\n        console.error('Error loading risk levels:', error);\n    }\n}\n\n// Initialize all charts\nasync function initializeAnalytics() {\n    await Promise.all([\n        loadNetworkHealth(),\n        loadDeviceTrends(),\n        loadAlertTrends(),\n        loadRiskLevels()\n    ]);\n}\n\n// Auto-refresh data every 30 seconds\nsetInterval(initializeAnalytics, 30000);\n\n// Initialize on page load\ndocument.addEventListener('DOMContentLoaded', initializeAnalytics);\n\n","size_bytes":12181},"static/js/devices-list.js":{"content":"let devicesData = [];\nlet selectedDevices = new Set();\n\nfunction loadDevices() {\n    fetch('/api/devices')\n        .then(res => res.json())\n        .then(data => {\n            if (data.success) {\n                devicesData = data.data;\n                renderDeviceTable();\n            }\n        })\n        .catch(err => console.error('Error loading devices:', err));\n}\n\nfunction renderDeviceTable() {\n    const tbody = document.getElementById('devicesTableBody');\n    if (!tbody) return;\n    \n    if (devicesData.length === 0) {\n        tbody.innerHTML = '<tr><td colspan=\"8\" class=\"py-4 text-center text-slate-400\">No devices found</td></tr>';\n        return;\n    }\n    \n    let html = '';\n    \n    devicesData.forEach(device => {\n        const statusClass = device.status === 'online' ? 'status-online' : 'status-offline';\n        const isTrusted = device.is_trusted ? 'checked' : '';\n        // Normalize device name display - show \"Unknown\" if no name/hostname available\n        let deviceName = device.device_name || device.hostname || null;\n        if (!deviceName || deviceName.trim() === '' || deviceName === 'Unknown') {\n            deviceName = 'Unknown';\n        }\n        \n        html += `\n            <tr class=\"hover:bg-slate-800/50 transition\">\n                <td class=\"px-4 py-3\">\n                    <input type=\"checkbox\" class=\"device-checkbox\" value=\"${device.id}\" onchange=\"updateDeleteButton()\">\n                </td>\n                <td class=\"px-4 py-3\">\n                    <input type=\"text\" value=\"${deviceName}\" class=\"bg-slate-800 border border-slate-700 rounded px-2 py-1 text-xs w-32\" onchange=\"updateDeviceName(${device.id}, this.value)\" placeholder=\"Device name\">\n                </td>\n                <td class=\"px-4 py-3 font-mono text-blue-400 text-xs\">${device.ip_address || 'N/A'}</td>\n                <td class=\"px-4 py-3 font-mono text-slate-300 text-xs\">${device.mac_address || 'N/A'}</td>\n                <td class=\"px-4 py-3 text-slate-300 text-xs\">${device.vendor || 'Unknown'}</td>\n                <td class=\"px-4 py-3\">\n                    <span class=\"status-badge ${statusClass}\">${device.status}</span>\n                </td>\n                <td class=\"px-4 py-3\">\n                    <input type=\"checkbox\" ${isTrusted} onchange=\"toggleTrust(${device.id}, this.checked)\">\n                </td>\n                <td class=\"px-4 py-3 text-xs\">\n                    <button onclick=\"deleteDevice(${device.id})\" class=\"text-red-400 hover:text-red-300\">Delete</button>\n                </td>\n            </tr>\n        `;\n    });\n    \n    tbody.innerHTML = html;\n    \n    if (typeof feather !== 'undefined') {\n        feather.replace();\n    }\n}\n\nfunction selectAllDevices() {\n    const checkboxes = document.querySelectorAll('.device-checkbox');\n    const allChecked = Array.from(checkboxes).every(cb => cb.checked);\n    \n    checkboxes.forEach(cb => {\n        cb.checked = !allChecked;\n    });\n    \n    updateDeleteButton();\n}\n\nfunction updateDeleteButton() {\n    const btn = document.getElementById('deleteSelectedBtn');\n    const checkboxes = document.querySelectorAll('.device-checkbox:checked');\n    btn.disabled = checkboxes.length === 0;\n}\n\nfunction deleteSelectedDevices() {\n    const checkboxes = document.querySelectorAll('.device-checkbox:checked');\n    if (checkboxes.length === 0) return;\n    \n    const deviceIds = Array.from(checkboxes).map(cb => parseInt(cb.value));\n    \n    if (!confirm(`Delete ${deviceIds.length} device(s)? This cannot be undone.`)) {\n        return;\n    }\n    \n    fetch('/api/devices/delete', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ device_ids: deviceIds })\n    })\n    .then(res => res.json())\n    .then(data => {\n        if (data.success) {\n            alert(`Deleted ${data.deleted_count} device(s)`);\n            loadDevices();\n        } else {\n            alert('Error deleting devices: ' + data.error);\n        }\n    })\n    .catch(err => {\n        console.error('Delete error:', err);\n        alert('Error deleting devices');\n    });\n}\n\nfunction deleteDevice(deviceId) {\n    if (!confirm('Delete this device? This cannot be undone.')) {\n        return;\n    }\n    \n    fetch('/api/devices/delete', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ device_ids: [deviceId] })\n    })\n    .then(res => res.json())\n    .then(data => {\n        if (data.success) {\n            loadDevices();\n        } else {\n            alert('Error deleting device: ' + data.error);\n        }\n    })\n    .catch(err => {\n        console.error('Delete error:', err);\n        alert('Error deleting device');\n    });\n}\n\nfunction updateDeviceName(deviceId, newName) {\n    fetch(`/api/devices/${deviceId}/name`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ name: newName })\n    })\n    .then(res => res.json())\n    .then(data => {\n        if (!data.success) {\n            alert('Error updating device name: ' + data.error);\n            loadDevices();\n        }\n    })\n    .catch(err => {\n        console.error('Update error:', err);\n        alert('Error updating device name');\n    });\n}\n\nfunction toggleTrust(deviceId, isTrusted) {\n    fetch(`/api/devices/${deviceId}/trust`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ is_trusted: isTrusted ? 1 : 0 })\n    })\n    .then(res => res.json())\n    .then(data => {\n        if (!data.success) {\n            alert('Error updating trust status: ' + data.error);\n            loadDevices();\n        }\n    })\n    .catch(err => {\n        console.error('Trust error:', err);\n        alert('Error updating trust status');\n    });\n}\n\nfunction updatePageData() {\n    console.log('Refreshing devices...');\n    loadDevices();\n    return true;\n}\n\nwindow.updatePageData = updatePageData;\n\n// Make sure it's always available\nif (typeof window.updatePageData === 'undefined') {\n    window.updatePageData = updatePageData;\n}\n\n// Real-time updates via Socket.IO\nfunction setupRealtimeUpdates() {\n    if (typeof io !== 'undefined' && window.netwatchRealtime && window.netwatchRealtime.socket) {\n        // Remove existing listeners to avoid duplicates\n        window.netwatchRealtime.socket.off('device_list_update');\n        window.netwatchRealtime.socket.off('device_status_update');\n        \n        window.netwatchRealtime.socket.on('device_list_update', (data) => {\n            if (data && data.devices) {\n                devicesData = data.devices;\n                renderDeviceTable();\n            }\n        });\n        \n        window.netwatchRealtime.socket.on('device_status_update', (data) => {\n            if (data && data.changes) {\n                // Refresh device list when status changes\n                loadDevices();\n            }\n        });\n    } else {\n        // Retry if socket not ready yet\n        setTimeout(setupRealtimeUpdates, 500);\n    }\n}\n\ndocument.addEventListener('DOMContentLoaded', () => {\n    loadDevices();\n    // Setup real-time updates once socket is ready\n    setupRealtimeUpdates();\n});\n\n// Also setup when socket connects\nif (window.netwatchRealtime) {\n    const originalConnect = window.netwatchRealtime.setupEventHandlers;\n    window.netwatchRealtime.setupEventHandlers = function() {\n        if (originalConnect) originalConnect.call(this);\n        setTimeout(setupRealtimeUpdates, 100);\n    };\n}","size_bytes":7501},"static/js/realtime.js":{"content":"class NetWatchRealtime {\n    constructor() {\n        this.socket = null;\n        this.reconnectAttempts = 0;\n        this.maxReconnectAttempts = 10;\n        this.reconnectDelay = 2000;\n        this.isConnected = false;\n        this.pageReady = false;\n    }\n    \n    start() {\n        if (typeof io === 'undefined') {\n            console.error('Socket.IO not loaded');\n            return;\n        }\n        this.pageReady = true;\n        this.connect();\n    }\n    \n    connect() {\n        if (!this.pageReady) {\n            setTimeout(() => this.connect(), 500);\n            return;\n        }\n        \n        if (this.socket && this.socket.connected) {\n            return;\n        }\n        \n        try {\n            this.socket = io({\n                reconnection: true,\n                reconnectionDelay: 2000,\n                reconnectionDelayMax: 10000,\n                reconnectionAttempts: this.maxReconnectAttempts,\n                transports: ['websocket', 'polling'],\n                forceNew: true,\n                upgrade: true\n            });\n            \n            this.setupEventHandlers();\n            console.log('Socket.IO connection initiated');\n        } catch (error) {\n            console.error('Failed to create socket:', error);\n            this.handleReconnect();\n        }\n    }\n    \n    setupEventHandlers() {\n        this.socket.on('connect', () => {\n            console.log('Connected to NetWatch SIEM');\n            this.isConnected = true;\n            this.reconnectAttempts = 0;\n            this.showConnectionStatus('connected');\n            \n            setTimeout(() => {\n                this.socket.emit('request_dashboard_stats');\n                this.socket.emit('request_device_list');\n            }, 100);\n            \n            // Trigger real-time listener setup on all pages\n            if (typeof setupRealtimeListeners === 'function') {\n                setupRealtimeListeners();\n            }\n            if (typeof setupRealtimeUpdates === 'function') {\n                setupRealtimeUpdates();\n            }\n        });\n        \n        this.socket.on('disconnect', (reason) => {\n            console.log('Disconnected from NetWatch SIEM:', reason);\n            this.isConnected = false;\n            this.showConnectionStatus('disconnected');\n        });\n        \n        this.socket.on('connected', (data) => {\n            console.log('Server message:', data.message);\n        });\n        \n        this.socket.on('dashboard_stats_update', (data) => {\n            if (data && data.stats) {\n                this.updateDashboardStats(data.stats);\n                this.updateLastUpdateTime(data.timestamp);\n            }\n        });\n        \n        this.socket.on('device_status_update', (data) => {\n            if (data && data.changes) {\n                this.handleDeviceStatusChanges(data.changes);\n                this.updateLastUpdateTime(data.timestamp);\n            }\n        });\n        \n        this.socket.on('device_list_update', (data) => {\n            if (data && data.devices) {\n                this.updateDeviceList(data.devices);\n                this.updateLastUpdateTime(data.timestamp);\n                \n                // Force update dashboard stats when device list changes\n                if (typeof updateDashboardStats === 'function') {\n                    updateDashboardStats();\n                }\n            }\n        });\n        \n        this.socket.on('error', (error) => {\n            console.error('Socket error:', error);\n        });\n        \n        this.socket.on('connect_error', (error) => {\n            console.error('Connection error:', error);\n            this.isConnected = false;\n        });\n    }\n    \n    handleReconnect() {\n        if (this.reconnectAttempts < this.maxReconnectAttempts) {\n            this.reconnectAttempts++;\n            console.log(`Reconnect attempt ${this.reconnectAttempts}/${this.maxReconnectAttempts}`);\n            this.showConnectionStatus('reconnecting');\n            \n            setTimeout(() => {\n                this.connect();\n            }, this.reconnectDelay * this.reconnectAttempts);\n        } else {\n            console.error('Max reconnection attempts reached');\n            this.showConnectionStatus('failed');\n        }\n    }\n    \n    updateDashboardStats(stats) {\n        const elements = {\n            'totalDevices': stats.total_devices,\n            'activeDevices': stats.active_devices,\n            'criticalAlerts': stats.critical_alerts,\n            'trustedDevices': stats.trusted_devices\n        };\n        \n        Object.entries(elements).forEach(([id, value]) => {\n            const el = document.getElementById(id);\n            if (el) this.animateNumberChange(el, value);\n        });\n        \n        const sidebarElements = {\n            'onlineCount': stats.active_devices,\n            'totalCount': stats.total_devices,\n            'alertsCount': stats.active_alerts,\n            'alertCount': stats.active_alerts,\n            'newTodayCount': stats.new_today\n        };\n        \n        Object.entries(sidebarElements).forEach(([id, value]) => {\n            const el = document.getElementById(id);\n            if (el) this.animateNumberChange(el, value);\n        });\n        \n        const mobileElements = {\n            'mobileOnlineCount': stats.active_devices,\n            'mobileTotalCount': stats.total_devices,\n            'mobileAlertsCount': stats.active_alerts,\n            'mobileAlertCount': stats.active_alerts,\n            'mobileNewTodayCount': stats.new_today\n        };\n        \n        Object.entries(mobileElements).forEach(([id, value]) => {\n            const el = document.getElementById(id);\n            if (el) this.animateNumberChange(el, value);\n        });\n    }\n    \n    handleDeviceStatusChanges(changes) {\n        changes.forEach(change => {\n            const { ip, change: changeType } = change;\n            let message = '';\n            let type = 'info';\n            \n            if (changeType === 'came_online') {\n                message = `Device ${ip} came online`;\n                type = 'success';\n            } else if (changeType === 'went_offline') {\n                message = `Device ${ip} went offline`;\n                type = 'warning';\n            } else if (changeType === 'new_device') {\n                message = `New device detected: ${ip}`;\n                type = 'info';\n            }\n            \n            this.showNotification(message, type);\n        });\n    }\n    \n    updateDeviceList(devices) {\n        console.log('Device list updated:', devices.length, 'devices');\n        \n        // Update dashboard if on devices page\n        if (typeof updatePageData === 'function') {\n            updatePageData();\n        }\n        \n        // Update active devices on dashboard\n        if (typeof updateActiveDevices === 'function') {\n            updateActiveDevices();\n        }\n    }\n    \n    animateNumberChange(element, newValue) {\n        const currentValue = parseInt(element.textContent) || 0;\n        if (currentValue === newValue) return;\n        \n        element.classList.add('number-change');\n        element.textContent = newValue;\n        \n        setTimeout(() => {\n            element.classList.remove('number-change');\n        }, 300);\n    }\n    \n    updateLastUpdateTime(timestamp) {\n        const el = document.getElementById('lastScanTime');\n        if (el) {\n            const diff = Math.floor((new Date() - new Date(timestamp)) / 1000);\n            \n            if (diff < 60) {\n                el.textContent = 'Just now';\n            } else if (diff < 3600) {\n                el.textContent = `${Math.floor(diff / 60)}m ago`;\n            } else {\n                el.textContent = new Date(timestamp).toLocaleTimeString();\n            }\n        }\n    }\n    \n    showConnectionStatus(status) {\n        let el = document.getElementById('connectionStatus');\n        if (!el) {\n            el = document.createElement('div');\n            el.id = 'connectionStatus';\n            el.style.cssText = 'position:fixed;top:10px;right:10px;padding:8px 12px;border-radius:4px;font-size:12px;font-weight:500;z-index:1000;transition:all 0.3s ease;';\n            document.body.appendChild(el);\n        }\n        \n        const config = {\n            'connected': { text: 'Live', color: '#10b981', bg: '#064e3b' },\n            'disconnected': { text: 'Offline', color: '#ef4444', bg: '#7f1d1d' },\n            'reconnecting': { text: 'Connecting...', color: '#f59e0b', bg: '#78350f' },\n            'failed': { text: 'Failed', color: '#ef4444', bg: '#7f1d1d' }\n        };\n        \n        const c = config[status] || config['disconnected'];\n        el.textContent = c.text;\n        el.style.color = c.color;\n        el.style.backgroundColor = c.bg;\n    }\n    \n    showNotification(message, type = 'info') {\n        const notification = document.createElement('div');\n        notification.style.cssText = 'position:fixed;top:20px;right:20px;padding:12px 16px;border-radius:6px;color:white;font-size:14px;font-weight:500;z-index:1001;max-width:300px;box-shadow:0 4px 12px rgba(0,0,0,0.3);transform:translateX(100%);transition:transform 0.3s ease;';\n        \n        const colors = {\n            'success': '#10b981',\n            'error': '#ef4444',\n            'warning': '#f59e0b',\n            'info': '#3b82f6'\n        };\n        \n        notification.style.backgroundColor = colors[type] || colors['info'];\n        notification.textContent = message;\n        \n        document.body.appendChild(notification);\n        \n        setTimeout(() => {\n            notification.style.transform = 'translateX(0)';\n        }, 10);\n        \n        setTimeout(() => {\n            notification.style.transform = 'translateX(100%)';\n            setTimeout(() => {\n                if (notification.parentNode) {\n                    notification.parentNode.removeChild(notification);\n                }\n            }, 300);\n        }, 5000);\n    }\n    \n    disconnect() {\n        if (this.socket) {\n            this.socket.disconnect();\n            this.socket = null;\n        }\n    }\n}\n\nwindow.netwatchRealtime = new NetWatchRealtime();\n\ndocument.addEventListener('DOMContentLoaded', () => {\n    window.netwatchRealtime.start();\n});\n\nwindow.addEventListener('load', () => {\n    if (!window.netwatchRealtime.isConnected) {\n        console.log('Page fully loaded, ensuring connection...');\n        window.netwatchRealtime.start();\n    }\n});\n\nconst style = document.createElement('style');\nstyle.textContent = '.number-change { animation: numberPulse 0.3s ease-in-out; } @keyframes numberPulse { 0% { transform: scale(1); } 50% { transform: scale(1.1); color: #3b82f6; } 100% { transform: scale(1); } }';\ndocument.head.appendChild(style);","size_bytes":10728},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"dnspython>=2.8.0\",\n    \"flask>=3.1.2\",\n    \"flask-socketio>=5.5.1\",\n    \"psutil>=7.1.0\",\n    \"python-nmap>=0.7.1\",\n    \"requests>=2.32.5\",\n    \"scapy>=2.6.1\",\n    \"werkzeug>=3.1.3\",\n]\n","size_bytes":331},"rules/smart_alert_engine.py":{"content":"# File: rules/smart_alert_engine.py\n# COMPLETE AND CORRECTED VERSION - FIXES \"no such column: ip_address\" ERROR\n\nfrom datetime import datetime, timedelta\nimport json\nimport hashlib\n\nclass SmartAlertEngine:\n    def __init__(self, db):\n        self.db = db\n        self.rules = self._load_rules()\n        self.alert_cache = {}\n        self.device_whitelist = self._load_whitelist()\n        self.learning_data = self._load_learning_data()\n    \n    def _load_rules(self):\n        \"\"\"Load enabled rules with proper ordering\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT * FROM rules \n            WHERE enabled = 1 \n            ORDER BY severity DESC, id ASC\n        \"\"\")\n        rules = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n        return rules\n    \n    def _load_whitelist(self):\n        \"\"\"Load trusted devices and patterns\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute(\"SELECT mac_address, ip_address FROM devices WHERE is_trusted = 1\")\n        whitelist = cursor.fetchall()\n        conn.close()\n        return [dict(device) for device in whitelist]\n    \n    def _load_learning_data(self):\n        \"\"\"Load historical patterns for smart detection\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute(\"\"\"\n            SELECT device_id, COUNT(*) as alert_count, MAX(timestamp) as last_alert\n            FROM alerts \n            WHERE timestamp > datetime('now', '-30 days')\n            GROUP BY device_id\n        \"\"\")\n        learning = cursor.fetchall()\n        conn.close()\n        return {dict(device)['device_id']: dict(device) for device in learning}\n    \n    def _generate_alert_hash(self, device_id, rule_name, condition_data):\n        \"\"\"Generate unique hash to prevent duplicate alerts\"\"\"\n        hash_string = f\"{device_id}_{rule_name}_{json.dumps(condition_data, sort_keys=True)}\"\n        return hashlib.md5(hash_string.encode()).hexdigest()\n    \n    def _is_whitelisted(self, device):\n        \"\"\"Check if device is whitelisted or trusted\"\"\"\n        for trusted in self.device_whitelist:\n            if device['mac_address'] == trusted['mac_address']:\n                return True\n        if device.get('is_trusted', 0) == 1:\n            return True\n        return False\n    \n    def _calculate_risk_score(self, device, rule):\n        \"\"\"Calculate dynamic risk score based on context\"\"\"\n        base_score = {'low': 1, 'medium': 3, 'high': 5}[rule['severity']]\n        \n        if self._is_whitelisted(device):\n            base_score *= 0.3\n        \n        device_id = device['id']\n        if device_id in self.learning_data:\n            alert_history = self.learning_data[device_id]['alert_count']\n            if alert_history > 5:\n                base_score *= 1.5\n        \n        if device.get('vendor') and device['vendor'] != 'Unknown':\n            base_score *= 0.8\n        \n        return min(base_score, 10)\n    \n    def _should_alert(self, device, rule, condition_met):\n        \"\"\"Smart decision on whether to create alert\"\"\"\n        if not condition_met:\n            return False\n        \n        if self._is_whitelisted(device) and rule.get('skip_trusted', True):\n            return False\n        \n        alert_hash = self._generate_alert_hash(\n            device['id'], rule['name'], \n            {'condition': rule['condition'], 'threshold': rule.get('threshold')}\n        )\n        \n        if alert_hash in self.alert_cache:\n            last_alert = self.alert_cache[alert_hash]\n            if (datetime.now() - last_alert).total_seconds() < rule.get('cooldown', 3600):\n                return False\n        \n        return True\n    \n    def _get_ip_history(self, device_id):\n        \"\"\"Get device reconnection history - FIXED: removed ip_address from SELECT\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT timestamp, metadata\n            FROM events \n            WHERE device_id = ? AND event_type IN ('device_online', 'ip_changed')\n            ORDER BY timestamp DESC LIMIT 20\n        ''', (device_id,))\n        history = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n        return history\n    \n    def _count_recent_arp_conflicts(self, device_id):\n        \"\"\"Count ARP conflicts for a device - FIXED: removed unused device_ip parameter\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            SELECT COUNT(*) FROM events\n            WHERE device_id = ? \n            AND event_type = 'arp_conflict'\n            AND datetime(timestamp) >= datetime('now', '-1 hour')\n        ''', (device_id,))\n        count = cursor.fetchone()[0]\n        conn.close()\n        return count\n    \n    def evaluate_smart_rule(self, rule, device):\n        \"\"\"Enhanced rule evaluation with comprehensive condition logic\"\"\"\n        try:\n            condition = rule['condition']\n            threshold = rule.get('threshold', 0)\n            device_id = device['id']\n            \n            # Ensure device has required fields\n            if not device.get('ip_address') or not device.get('mac_address'):\n                return False\n            \n            if not self._should_alert(device, rule, True):\n                return False\n            \n            triggered = False\n            description = \"\"\n            risk_score = self._calculate_risk_score(device, rule)\n            \n            # Device Lifecycle Conditions\n            if condition == 'device_first_seen':\n                first_seen = datetime.strptime(device['first_seen'], '%Y-%m-%d %H:%M:%S')\n                hours_old = (datetime.now() - first_seen).total_seconds() / 3600\n                \n                if hours_old <= threshold and not self._is_whitelisted(device):\n                    triggered = True\n                    description = f\"New untrusted device: {device['ip_address']} ({device['mac_address']})\"\n            \n            elif condition == 'device_disappeared':\n                if device['status'] == 'offline' and self._is_whitelisted(device):\n                    last_seen = datetime.strptime(device['last_seen'], '%Y-%m-%d %H:%M:%S')\n                    hours_offline = (datetime.now() - last_seen).total_seconds() / 3600\n                    \n                    if hours_offline >= threshold:\n                        triggered = True\n                        description = f\"Trusted device offline for {int(hours_offline)} hours: {device['device_name'] or device['ip_address']}\"\n            \n            # Reconnection Conditions\n            elif condition == 'reconnect_count':\n                min_threshold = 50 if self._is_whitelisted(device) else 20\n                if device.get('reconnect_count', 0) >= max(threshold, min_threshold):\n                    triggered = True\n                    description = f\"Device {device['ip_address']} reconnected {device['reconnect_count']} times (threshold: {threshold})\"\n            \n            elif condition == 'reconnect_frequency':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(*) FROM events\n                    WHERE device_id = ? \n                    AND event_type = 'device_online'\n                    AND datetime(timestamp) >= datetime('now', '-10 minutes')\n                ''', (device_id,))\n                recent_reconnects = cursor.fetchone()[0]\n                conn.close()\n                \n                if recent_reconnects >= threshold:\n                    triggered = True\n                    description = f\"Device {device['ip_address']} reconnected {recent_reconnects} times in 10 minutes (threshold: {threshold})\"\n            \n            # MAC Address Conditions\n            elif condition == 'mac_pattern':\n                suspicious_patterns = {\n                    'common_spoof': ['00:00:00', 'FF:FF:FF', '00:11:22', '33:33:33'],\n                    'vm_patterns': ['02:00:00', '03:00:00', '52:54:00', '08:00:27'],\n                    'broadcast': ['FF:FF:FF'],\n                }\n                \n                mac_prefix = device['mac_address'][:8]\n                patterns = suspicious_patterns.get(str(threshold), [])\n                \n                if any(mac_prefix.startswith(p[:8]) for p in patterns) and not self._is_whitelisted(device):\n                    triggered = True\n                    description = f\"Suspicious MAC pattern: {device['mac_address']} on {device['ip_address']}\"\n            \n            elif condition == 'mac_changed':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                \n                # Check if this IP has been associated with different MACs\n                cursor.execute('''\n                    SELECT COUNT(DISTINCT mac_address) \n                    FROM devices \n                    WHERE ip_address = ?\n                ''', (device['ip_address'],))\n                \n                unique_macs = cursor.fetchone()[0]\n                conn.close()\n                \n                if unique_macs > 1:\n                    triggered = True\n                    description = f\"MAC address changed for IP {device['ip_address']}\"\n            \n            # Vendor Conditions\n            elif condition == 'vendor_unknown':\n                if device.get('vendor') == 'Unknown' and not self._is_whitelisted(device):\n                    triggered = True\n                    description = f\"Device with unknown vendor: {device['ip_address']} ({device['mac_address']})\"\n            \n            elif condition == 'suspicious_vendor':\n                # Placeholder for suspicious vendor detection\n                triggered = False\n            \n            # IP Address Conditions\n            elif condition == 'ip_changed':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                \n                # Check if this MAC had different IPs\n                cursor.execute('''\n                    SELECT COUNT(DISTINCT ip_address) \n                    FROM devices \n                    WHERE mac_address = ?\n                ''', (device['mac_address'],))\n                \n                ip_count = cursor.fetchone()[0]\n                conn.close()\n                \n                if ip_count > 1 and self._is_whitelisted(device):\n                    triggered = True\n                    description = f\"Trusted device changed IP address: MAC {device['mac_address']} now at {device['ip_address']}\"\n            \n            elif condition == 'rapid_ip_changes':\n                ip_history = self._get_ip_history(device_id)\n                last_hour_ips = [ip for ip in ip_history \n                                if datetime.strptime(ip['timestamp'], '%Y-%m-%d %H:%M:%S') \n                                > datetime.now() - timedelta(hours=1)]\n                \n                if len(last_hour_ips) >= threshold:\n                    triggered = True\n                    description = f\"Device {device['ip_address']} had {len(last_hour_ips)} reconnections in 1 hour (threshold: {threshold})\"\n            \n            elif condition == 'private_ip_overlap':\n                # Placeholder for IP range anomaly detection\n                triggered = False\n            \n            # Activity Conditions\n            elif condition == 'inactive_duration':\n                if device['status'] == 'offline':\n                    last_seen = datetime.strptime(device['last_seen'], '%Y-%m-%d %H:%M:%S')\n                    inactive_hours = (datetime.now() - last_seen).total_seconds() / 3600\n                    \n                    if inactive_hours >= threshold:\n                        triggered = True\n                        description = f\"Device {device['ip_address']} inactive for {int(inactive_hours)} hours\"\n            \n            elif condition == 'no_activity':\n                # Placeholder for no network activity detection\n                triggered = False\n            \n            # Network Location Conditions\n            elif condition == 'location_change':\n                # Placeholder for location change detection\n                triggered = False\n            \n            elif condition == 'simultaneous_ips':\n                conn = self.db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('''\n                    SELECT COUNT(DISTINCT ip_address) \n                    FROM devices \n                    WHERE mac_address = ? AND status = 'online'\n                ''', (device['mac_address'],))\n                active_ips = cursor.fetchone()[0]\n                conn.close()\n                \n                if active_ips >= threshold:\n                    triggered = True\n                    description = f\"MAC {device['mac_address']} has {active_ips} simultaneous IPs (threshold: {threshold})\"\n            \n            # Behavior Conditions\n            elif condition == 'abnormal_scan':\n                # Placeholder for network scanning detection\n                triggered = False\n            \n            elif condition == 'broadcast_storm':\n                # Placeholder for broadcast storm detection\n                triggered = False\n            \n            elif condition == 'arp_spoofing':\n                arp_conflicts = self._count_recent_arp_conflicts(device_id)\n                \n                if arp_conflicts >= threshold:\n                    triggered = True\n                    description = f\"Detected {arp_conflicts} ARP conflicts for {device['ip_address']} (threshold: {threshold})\"\n            \n            # Device Type Conditions\n            elif condition == 'unexpected_device_type':\n                # Placeholder for unexpected device type detection\n                triggered = False\n            \n            # Multi-Condition Scenarios\n            elif condition == 'new_untrusted_behavior':\n                # Placeholder for new device suspicious behavior\n                triggered = False\n            \n            elif condition == 'repeated_failures':\n                # Placeholder for repeated failures detection\n                triggered = False\n            \n            # Create alert if rule was triggered\n            if triggered:\n                alert_hash = self._generate_alert_hash(device_id, rule['name'], {\n                    'condition': condition, 'threshold': threshold\n                })\n                self.alert_cache[alert_hash] = datetime.now()\n                \n                if risk_score >= 7:\n                    severity = 'high'\n                elif risk_score >= 4:\n                    severity = 'medium'\n                else:\n                    severity = 'low'\n                \n                self.db.add_alert(\n                    alert_type=rule['name'],\n                    severity=severity,\n                    title=f\"Alert: {rule['name']}\",\n                    description=description,\n                    device_id=device_id,\n                    metadata={\n                        'rule_id': rule['id'],\n                        'threshold': threshold,\n                        'risk_score': risk_score,\n                        'condition': condition,\n                        'device_trusted': self._is_whitelisted(device)\n                    }\n                )\n                return True\n            \n            return False\n            \n        except Exception as e:\n            print(f\"Error evaluating smart rule {rule['name']}: {e}\")\n            import traceback\n            traceback.print_exc()\n            return False\n    \n    def process_smart_alerts(self, device_id):\n        \"\"\"Process alerts with smart logic - NO DUPLICATES\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        # Explicitly select all columns to ensure proper dict conversion\n        cursor.execute('''\n            SELECT id, ip_address, mac_address, hostname, vendor, \n                   device_name, is_trusted, risk_score, status, \n                   first_seen, last_seen, reconnect_count, metadata, marked_safe\n            FROM devices WHERE id = ?\n        ''', (device_id,))\n        \n        device_row = cursor.fetchone()\n        conn.close()\n        \n        if not device_row:\n            return\n        \n        device = dict(device_row)\n        \n        # Reload rules and learning data\n        self.rules = self._load_rules()\n        self.learning_data = self._load_learning_data()\n        \n        for rule in self.rules:\n            try:\n                self.evaluate_smart_rule(rule, device)\n            except Exception as e:\n                print(f\"Error processing rule {rule['name']}: {e}\")\n    \n    def run_smart_periodic_checks(self):\n        \"\"\"Run periodic checks with smart logic\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        inactive_threshold = datetime.now() - timedelta(hours=24)\n        cursor.execute('''\n            SELECT id, ip_address, device_name, last_seen \n            FROM devices \n            WHERE datetime(last_seen) < ? AND status = 'online'\n        ''', (inactive_threshold.strftime('%Y-%m-%d %H:%M:%S'),))\n        \n        devices = cursor.fetchall()\n        conn.close()\n        \n        for device in devices:\n            device_dict = dict(device)\n            self.db.update_device_status(device_dict['id'], 'offline')\n            self.db.add_event(\n                event_type='device_offline',\n                severity='info',\n                description=f\"Device {device_dict['ip_address']} went offline\",\n                device_id=device_dict['id']\n            )\n    \n    def add_rule_validation(self, rule_data):\n        \"\"\"Validate new rule before adding\"\"\"\n        errors = []\n        \n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT COUNT(*) FROM rules WHERE name = ?', (rule_data['name'],))\n        if cursor.fetchone()[0] > 0:\n            errors.append(\"Rule name already exists\")\n        \n        condition = rule_data.get('condition')\n        threshold = rule_data.get('threshold')\n        \n        if condition == 'reconnect_count' and threshold < 5:\n            errors.append(\"Reconnect threshold too low (minimum 5)\")\n        \n        if condition == 'inactive_duration' and threshold < 1:\n            errors.append(\"Inactive duration too short (minimum 1 hour)\")\n        \n        conn.close()\n        return errors\n    \n    def test_rule(self, rule_data, test_device_id):\n        \"\"\"Test rule against specific device\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT * FROM devices WHERE id = ?', (test_device_id,))\n        device_row = cursor.fetchone()\n        conn.close()\n        \n        if not device_row:\n            return {\"error\": \"Device not found\"}\n        \n        device = dict(device_row)\n        \n        temp_rule = {\n            'id': 'test',\n            'name': rule_data['name'],\n            'condition': rule_data['condition'],\n            'threshold': rule_data.get('threshold', 0),\n            'severity': rule_data['severity'],\n            'enabled': 1\n        }\n        \n        result = self.evaluate_smart_rule(temp_rule, device)\n        \n        return {\n            \"would_trigger\": result,\n            \"device_info\": {\n                \"ip\": device['ip_address'],\n                \"mac\": device['mac_address'],\n                \"vendor\": device.get('vendor', 'Unknown'),\n                \"trusted\": device.get('is_trusted', 0)\n            }\n        }","size_bytes":19676},"security/__init__.py":{"content":"\"\"\"\nSecurity package for NetWatch SIEM\nProvides authentication, authorization, and security utilities\n\"\"\"\n\nfrom .auth import SecurityManager, require_auth, require_admin, rate_limit, validate_input, sanitize_input\nfrom .rbac import has_permission, require_permission, require_any_permission, get_user_role, is_admin, ROLE_PERMISSIONS\n\n__all__ = [\n    'SecurityManager',\n    'require_auth', \n    'require_admin',\n    'rate_limit',\n    'validate_input',\n    'sanitize_input',\n    'has_permission',\n    'require_permission',\n    'require_any_permission',\n    'get_user_role',\n    'is_admin',\n    'ROLE_PERMISSIONS'\n]\n","size_bytes":614},"database/models.py":{"content":"import sqlite3\nfrom datetime import datetime, timezone, timedelta\nimport json\nfrom werkzeug.security import generate_password_hash, check_password_hash\nimport secrets\n\n# Kenya timezone \nKENYA_TZ = timezone(timedelta(hours=3))\n\ndef get_kenya_time():\n    \"\"\"Get current time in Kenya timezone\"\"\"\n    return datetime.now(KENYA_TZ).strftime('%Y-%m-%d %H:%M:%S')\n\nclass Database:\n    def __init__(self, db_path='netwatch.db'):\n        self.db_path = db_path\n        self.init_database()\n    \n    def get_connection(self):\n        \"\"\"\n        Creates and returns a thread-safe SQLite connection - FAST and SIMPLE\n        WAL mode enabled for concurrency without retries (faster)\n        \"\"\"\n        conn = sqlite3.connect(\n            self.db_path,\n            timeout=5,                # Short timeout - fail fast\n            check_same_thread=False\n        )\n        conn.row_factory = sqlite3.Row\n        \n        # Enable WAL mode - fast concurrent access\n        conn.execute('PRAGMA journal_mode=WAL')\n        conn.execute('PRAGMA busy_timeout=5000')   # 5 seconds max wait\n        conn.execute('PRAGMA synchronous=NORMAL')\n        conn.execute('PRAGMA foreign_keys=ON')\n        conn.execute('PRAGMA temp_store=MEMORY')   # Faster temp operations\n        \n        return conn\n    \n    def init_database(self):\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            # Devices table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS devices (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    ip_address TEXT NOT NULL,\n                    mac_address TEXT UNIQUE NOT NULL,\n                    hostname TEXT,\n                    vendor TEXT,\n                    device_name TEXT,\n                    is_trusted INTEGER DEFAULT 1,\n                    risk_score INTEGER DEFAULT 0,\n                    status TEXT DEFAULT 'offline',\n                    first_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    last_seen TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    reconnect_count INTEGER DEFAULT 0,\n                    metadata TEXT,\n                    marked_safe INTEGER DEFAULT 0\n                )\n            ''')\n            \n            # Events table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS events (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    event_type TEXT NOT NULL,\n                    severity TEXT DEFAULT 'info',\n                    description TEXT,\n                    device_id INTEGER,\n                    metadata TEXT,\n                    FOREIGN KEY (device_id) REFERENCES devices(id)\n                )\n            ''')\n            \n            # Alerts table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS alerts (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    alert_type TEXT NOT NULL,\n                    severity TEXT NOT NULL,\n                    title TEXT NOT NULL,\n                    description TEXT,\n                    device_id INTEGER,\n                    status TEXT DEFAULT 'active',\n                    resolved_at TIMESTAMP,\n                    metadata TEXT,\n                    marked_safe INTEGER DEFAULT 0,\n                    FOREIGN KEY (device_id) REFERENCES devices(id)\n                )\n            ''')\n            \n            # Rules table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS rules (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    name TEXT UNIQUE NOT NULL,\n                    rule_type TEXT NOT NULL,\n                    condition TEXT NOT NULL,\n                    threshold INTEGER,\n                    severity TEXT DEFAULT 'medium',\n                    enabled INTEGER DEFAULT 1,\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    metadata TEXT\n                )\n            ''')\n            \n            # Licenses table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS licenses (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    license_key TEXT UNIQUE,\n                    license_type TEXT DEFAULT 'LITE',\n                    activated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    expires_at TIMESTAMP,\n                    status TEXT DEFAULT 'active'\n                )\n            ''')\n            \n            # System logs table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS system_logs (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    action TEXT NOT NULL,\n                    user TEXT DEFAULT 'system',\n                    details TEXT,\n                    metadata TEXT\n                )\n            ''')\n            \n            # System config table\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS system_config (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    config_key TEXT UNIQUE NOT NULL,\n                    config_value TEXT NOT NULL,\n                    data_type TEXT DEFAULT 'string',\n                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                )\n            ''')\n            \n            # Users table (NEW)\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS users (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    username TEXT UNIQUE NOT NULL,\n                    email TEXT UNIQUE NOT NULL,\n                    password_hash TEXT NOT NULL,\n                    role TEXT DEFAULT 'viewer',\n                    is_active INTEGER DEFAULT 1,\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    last_login TIMESTAMP,\n                    failed_attempts INTEGER DEFAULT 0,\n                    locked_until TIMESTAMP\n                )\n            ''')\n            \n            # User sessions table (NEW)\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS user_sessions (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    user_id INTEGER NOT NULL,\n                    session_token TEXT UNIQUE NOT NULL,\n                    ip_address TEXT,\n                    user_agent TEXT,\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    expires_at TIMESTAMP,\n                    FOREIGN KEY (user_id) REFERENCES users(id)\n                )\n            ''')\n            \n            # User activity table (NEW)\n            cursor.execute('''\n                CREATE TABLE IF NOT EXISTS user_activity (\n                    id INTEGER PRIMARY KEY AUTOINCREMENT,\n                    user_id INTEGER,\n                    username TEXT,\n                    action TEXT NOT NULL,\n                    timestamp TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    ip_address TEXT,\n                    details TEXT,\n                    FOREIGN KEY (user_id) REFERENCES users(id)\n                )\n            ''')\n            \n            # Adding new columns if they don't exist\n            try:\n                cursor.execute('ALTER TABLE alerts ADD COLUMN marked_safe INTEGER DEFAULT 0')\n            except sqlite3.OperationalError:\n                pass\n            \n            try:\n                cursor.execute('ALTER TABLE devices ADD COLUMN marked_safe INTEGER DEFAULT 0')\n            except sqlite3.OperationalError:\n                pass\n            \n            conn.commit()\n            \n        except Exception as e:\n            conn.rollback()\n            print(f\"Database initialization error: {e}\")\n            raise\n        finally:\n            conn.close()\n        \n        # Create default configuration and admin user\n        self._create_default_config()\n        self._create_default_admin()\n    \n    def _create_default_config(self):\n        \"\"\"Initialize default configuration settings\"\"\"\n        default_config = [\n            ('scan_interval', '60', 'integer'),\n            ('scan_timeout', '5', 'integer'),\n            ('alert_retention_days', '90', 'integer'),\n            ('log_retention_days', '365', 'integer'),\n            ('traffic_monitoring', 'true', 'boolean'),\n            ('extended_logs', 'true', 'boolean'),\n            ('email_alerts', 'true', 'boolean'),\n            ('scanning_active', 'true', 'boolean')\n        ]\n        \n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            for key, value, data_type in default_config:\n                cursor.execute('''\n                    INSERT OR IGNORE INTO system_config (config_key, config_value, data_type)\n                    VALUES (?, ?, ?)\n                ''', (key, value, data_type))\n            conn.commit()\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error creating default config: {e}\")\n        finally:\n            conn.close()\n    \n    def _create_default_admin(self):\n        \"\"\"Create default admin user if none exists\"\"\"\n        import os\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('SELECT COUNT(*) FROM users')\n            user_count = cursor.fetchone()[0]\n            \n            if user_count == 0:\n                admin_username = os.environ.get('DEFAULT_ADMIN_USERNAME', 'admin')\n                admin_password = os.environ.get('DEFAULT_ADMIN_PASSWORD', 'admin123')\n                admin_email = os.environ.get('DEFAULT_ADMIN_EMAIL', 'admin@netwatch.local')\n                \n                password_hash = generate_password_hash(admin_password)\n                kenya_time = get_kenya_time()\n                \n                cursor.execute('''\n                    INSERT INTO users (username, email, password_hash, role, is_active, created_at)\n                    VALUES (?, ?, ?, ?, ?, ?)\n                ''', (admin_username, admin_email, password_hash, 'admin', 1, kenya_time))\n                \n                conn.commit()\n                print(f\"\\n✓ Default admin user created: {admin_username} / {admin_password}\")\n                print(\"  Please change the password after first login!\\n\")\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error creating default admin: {e}\")\n        finally:\n            conn.close()\n    \n    def get_config(self, key=None):\n        \"\"\"Get configuration value(s) from database\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            if key:\n                cursor.execute('SELECT config_value, data_type FROM system_config WHERE config_key = ?', (key,))\n                result = cursor.fetchone()\n                \n                if result:\n                    value, data_type = result\n                    if data_type == 'integer':\n                        return int(value)\n                    elif data_type == 'boolean':\n                        return value.lower() == 'true'\n                    return value\n                return None\n            else:\n                cursor.execute('SELECT config_key, config_value, data_type FROM system_config')\n                results = cursor.fetchall()\n                \n                config = {}\n                for row in results:\n                    key, value, data_type = row\n                    if data_type == 'integer':\n                        config[key] = int(value)\n                    elif data_type == 'boolean':\n                        config[key] = value.lower() == 'true'\n                    else:\n                        config[key] = value\n                return config\n        finally:\n            conn.close()\n    \n    def set_config(self, key, value):\n        \"\"\"Set configuration value in database\"\"\"\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            # Determine data type\n            data_type = 'string'\n            if isinstance(value, bool):\n                data_type = 'boolean'\n                value = 'true' if value else 'false'\n            elif isinstance(value, int):\n                data_type = 'integer'\n                value = str(value)\n            \n            cursor.execute('''\n                INSERT OR REPLACE INTO system_config (config_key, config_value, data_type, updated_at)\n                VALUES (?, ?, ?, ?)\n            ''', (key, value, data_type, kenya_time))\n            \n            conn.commit()\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error setting config: {e}\")\n        finally:\n            conn.close()\n    \n    def add_device(self, ip, mac, hostname=None, vendor=None):\n        \"\"\"\n        Add or update device silently. Returns device_id.\n        Handles UNIQUE constraint gracefully with proper transaction management.\n        \"\"\"\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            # Check if device exists by MAC address\n            cursor.execute('SELECT id FROM devices WHERE mac_address = ?', (mac,))\n            existing = cursor.fetchone()\n            \n            if existing:\n                # Update existing device\n                device_id = existing[0]\n                cursor.execute('''\n                    UPDATE devices \n                    SET ip_address = ?, \n                        last_seen = ?, \n                        status = 'online',\n                        reconnect_count = reconnect_count + 1,\n                        hostname = COALESCE(?, hostname),\n                        vendor = COALESCE(?, vendor)\n                    WHERE id = ?\n                ''', (ip, kenya_time, hostname, vendor, device_id))\n                conn.commit()\n                return device_id\n            \n            # Check by IP (for devices with generated MACs)\n            cursor.execute('SELECT id FROM devices WHERE ip_address = ?', (ip,))\n            existing_by_ip = cursor.fetchone()\n            \n            if existing_by_ip:\n                # Update existing device found by IP\n                device_id = existing_by_ip[0]\n                cursor.execute('''\n                    UPDATE devices \n                    SET mac_address = ?, \n                        last_seen = ?, \n                        status = 'online',\n                        reconnect_count = reconnect_count + 1,\n                        hostname = COALESCE(?, hostname),\n                        vendor = COALESCE(?, vendor)\n                    WHERE id = ?\n                ''', (mac, kenya_time, hostname, vendor, device_id))\n                conn.commit()\n                return device_id\n            \n            # Insert new device - default to trusted\n            cursor.execute('''\n                INSERT INTO devices (ip_address, mac_address, hostname, vendor, status, first_seen, last_seen, is_trusted)\n                VALUES (?, ?, ?, ?, 'online', ?, ?, 1)\n            ''', (ip, mac, hostname, vendor, kenya_time, kenya_time))\n            device_id = cursor.lastrowid\n            conn.commit()\n            return device_id\n                \n        except sqlite3.IntegrityError:\n            # UNIQUE constraint failed - try to get the device_id\n            conn.rollback()\n            try:\n                cursor.execute('SELECT id FROM devices WHERE mac_address = ? OR ip_address = ?', (mac, ip))\n                result = cursor.fetchone()\n                if result:\n                    return result[0]\n            except:\n                pass\n            return None\n            \n        except Exception as e:\n            conn.rollback()\n            print(f\"Error adding device: {e}\")\n            return None\n        finally:\n            conn.close()\n    \n    def update_device_status(self, device_id, status):\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                UPDATE devices \n                SET status = ?, last_seen = ?\n                WHERE id = ?\n            ''', (status, kenya_time, device_id))\n            conn.commit()\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error updating device status: {e}\")\n        finally:\n            conn.close()\n    \n    def delete_devices(self, device_ids):\n        \"\"\"Delete multiple devices by ID list\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            placeholders = ','.join('?' * len(device_ids))\n            \n            # Delete related alerts first\n            cursor.execute(f'DELETE FROM alerts WHERE device_id IN ({placeholders})', device_ids)\n            \n            # Delete related events\n            cursor.execute(f'DELETE FROM events WHERE device_id IN ({placeholders})', device_ids)\n            \n            # Delete devices\n            cursor.execute(f'DELETE FROM devices WHERE id IN ({placeholders})', device_ids)\n            \n            deleted_count = cursor.rowcount\n            conn.commit()\n            return deleted_count\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error deleting devices: {e}\")\n            return 0\n        finally:\n            conn.close()\n    \n    def add_event(self, event_type, severity, description, device_id=None, metadata=None):\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                INSERT INTO events (timestamp, event_type, severity, description, device_id, metadata)\n                VALUES (?, ?, ?, ?, ?, ?)\n            ''', (kenya_time, event_type, severity, description, device_id, json.dumps(metadata) if metadata else None))\n            event_id = cursor.lastrowid\n            conn.commit()\n            return event_id\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error adding event: {e}\")\n            return None\n        finally:\n            conn.close()\n    \n    def delete_events(self, event_ids=None):\n        \"\"\"Delete events... if no IDs provided, delete all\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            if event_ids:\n                placeholders = ','.join('?' * len(event_ids))\n                cursor.execute(f'DELETE FROM events WHERE id IN ({placeholders})', event_ids)\n            else:\n                cursor.execute('DELETE FROM events')\n            \n            deleted_count = cursor.rowcount\n            conn.commit()\n            return deleted_count\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error deleting events: {e}\")\n            return 0\n        finally:\n            conn.close()\n    \n    def add_alert(self, alert_type, severity, title, description, device_id=None, metadata=None):\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                INSERT INTO alerts (timestamp, alert_type, severity, title, description, device_id, metadata)\n                VALUES (?, ?, ?, ?, ?, ?, ?)\n            ''', (kenya_time, alert_type, severity, title, description, device_id, json.dumps(metadata) if metadata else None))\n            alert_id = cursor.lastrowid\n            conn.commit()\n            return alert_id\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error adding alert: {e}\")\n            return None\n        finally:\n            conn.close()\n    \n    def mark_alert_safe(self, alert_id):\n        \"\"\"Mark an alert as safe/false positive\"\"\"\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                UPDATE alerts \n                SET marked_safe = 1, status = 'resolved', resolved_at = ?\n                WHERE id = ?\n            ''', (kenya_time, alert_id))\n            conn.commit()\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error marking alert safe: {e}\")\n        finally:\n            conn.close()\n    \n    def delete_alerts(self, alert_ids=None):\n        \"\"\"Delete alerts... if no IDs provided, delete all resolved ones\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            if alert_ids:\n                placeholders = ','.join('?' * len(alert_ids))\n                cursor.execute(f'DELETE FROM alerts WHERE id IN ({placeholders})', alert_ids)\n            else:\n                cursor.execute(\"DELETE FROM alerts WHERE status = 'resolved'\")\n            \n            deleted_count = cursor.rowcount\n            conn.commit()\n            return deleted_count\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error deleting alerts: {e}\")\n            return 0\n        finally:\n            conn.close()\n    \n    def get_all_devices(self):\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('SELECT * FROM devices ORDER BY last_seen DESC')\n            devices = []\n            for row in cursor.fetchall():\n                device = dict(row)\n                # Normalize device name for display - if no device_name or hostname, mark as None (will show as \"Unknown\" in frontend)\n                if not device.get('device_name') and not device.get('hostname'):\n                    device['display_name'] = None\n                elif device.get('device_name'):\n                    device['display_name'] = device['device_name']\n                else:\n                    device['display_name'] = device.get('hostname')\n                devices.append(device)\n            return devices\n        finally:\n            conn.close()\n\n    def search_devices(self, query):\n        \"\"\"Search devices by IP, MAC, device name, hostname, or vendor\"\"\"\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            search_term = f\"%{query}%\"\n            \n            cursor.execute('''\n                SELECT * FROM devices \n                WHERE ip_address LIKE ? \n                   OR mac_address LIKE ? \n                   OR device_name LIKE ? \n                   OR hostname LIKE ? \n                   OR vendor LIKE ?\n                ORDER BY last_seen DESC\n            ''', (search_term, search_term, search_term, search_term, search_term))\n            \n            devices = [dict(row) for row in cursor.fetchall()]\n            return devices\n        finally:\n            conn.close()\n    \n    def get_active_devices(self):\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute(\"SELECT * FROM devices WHERE status = 'online' ORDER BY last_seen DESC\")\n            devices = [dict(row) for row in cursor.fetchall()]\n            return devices\n        finally:\n            conn.close()\n    \n    def get_recent_alerts(self, limit=50):\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                SELECT a.*, d.ip_address, d.mac_address, d.device_name \n                FROM alerts a\n                LEFT JOIN devices d ON a.device_id = d.id\n                WHERE a.status = 'active'\n                ORDER BY a.timestamp DESC\n                LIMIT ?\n            ''', (limit,))\n            alerts = [dict(row) for row in cursor.fetchall()]\n            return alerts\n        finally:\n            conn.close()\n    \n    def get_recent_events(self, limit=100):\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                SELECT e.*, d.ip_address, d.device_name \n                FROM events e\n                LEFT JOIN devices d ON e.device_id = d.id\n                ORDER BY e.timestamp DESC\n                LIMIT ?\n            ''', (limit,))\n            events = [dict(row) for row in cursor.fetchall()]\n            return events\n        finally:\n            conn.close()\n    \n    def resolve_alert(self, alert_id):\n        kenya_time = get_kenya_time()\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                UPDATE alerts \n                SET status = 'resolved', resolved_at = ?\n                WHERE id = ?\n            ''', (kenya_time, alert_id))\n            conn.commit()\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error resolving alert: {e}\")\n        finally:\n            conn.close()\n    \n    def get_dashboard_stats(self):\n        conn = self.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute(\"SELECT COUNT(*) as total FROM devices\")\n            total_devices = cursor.fetchone()[0]\n            \n            cursor.execute(\"SELECT COUNT(*) as active FROM devices WHERE status = 'online'\")\n            active_devices = cursor.fetchone()[0]\n            \n            cursor.execute(\"SELECT COUNT(*) as alerts FROM alerts WHERE status = 'active'\")\n            active_alerts = cursor.fetchone()[0]\n            \n            cursor.execute(\"SELECT COUNT(*) as critical FROM alerts WHERE status = 'active' AND severity = 'high'\")\n            critical_alerts = cursor.fetchone()[0]\n            \n            cursor.execute(\"SELECT COUNT(*) as trusted FROM devices WHERE is_trusted = 1\")\n            trusted_devices = cursor.fetchone()[0]\n            \n            cursor.execute(\"SELECT COUNT(*) as new_today FROM devices WHERE DATE(first_seen) = DATE('now', '+3 hours')\")\n            new_today = cursor.fetchone()[0]\n            \n            return {\n                'total_devices': total_devices,\n                'active_devices': active_devices,\n                'active_alerts': active_alerts,\n                'critical_alerts': critical_alerts,\n                'trusted_devices': trusted_devices,\n                'new_today': new_today\n            }\n        finally:\n            conn.close()\n\n\nclass UserManager:\n    \"\"\"Manages user authentication, sessions, and activity\"\"\"\n    \n    def __init__(self, db):\n        self.db = db\n    \n    def register_user(self, username, email, password, role='viewer'):\n        \"\"\"Register a new user - FAST and SIMPLE with immediate commits\"\"\"\n        conn = None\n        try:\n            # Get connection with immediate mode for faster writes\n            conn = self.db.get_connection()\n            conn.execute('BEGIN IMMEDIATE')  # Immediate mode - faster, less locking\n            cursor = conn.cursor()\n            \n            # Quick check if username exists\n            cursor.execute('SELECT id FROM users WHERE username = ? LIMIT 1', (username,))\n            if cursor.fetchone():\n                conn.rollback()\n                conn.close()\n                return {'success': False, 'error': 'Username already exists'}\n            \n            # Quick check if email exists\n            cursor.execute('SELECT id FROM users WHERE email = ? LIMIT 1', (email,))\n            if cursor.fetchone():\n                conn.rollback()\n                conn.close()\n                return {'success': False, 'error': 'Email already exists'}\n            \n            # Hash password and insert\n            password_hash = generate_password_hash(password)\n            kenya_time = get_kenya_time()\n            \n            cursor.execute('''\n                INSERT INTO users (username, email, password_hash, role, is_active, created_at)\n                VALUES (?, ?, ?, ?, 1, ?)\n            ''', (username, email, password_hash, role, kenya_time))\n            \n            user_id = cursor.lastrowid\n            conn.commit()\n            conn.close()\n            conn = None\n            \n            # Log activity in separate, fast transaction (don't wait for it)\n            try:\n                self._log_activity_async(user_id, username, 'user_registered', None, 'New user account created')\n            except:\n                pass\n            \n            return {'success': True, 'user_id': user_id}\n            \n        except sqlite3.IntegrityError:\n            if conn:\n                try:\n                    conn.rollback()\n                    conn.close()\n                except:\n                    pass\n            return {'success': False, 'error': 'Username or email already exists'}\n        except Exception as e:\n            if conn:\n                try:\n                    conn.rollback()\n                    conn.close()\n                except:\n                    pass\n            return {'success': False, 'error': f'Error: {str(e)}'}\n    \n    def authenticate_user(self, username, password, ip_address=None):\n        \"\"\"Authenticate user credentials\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                SELECT id, username, email, password_hash, role, is_active, failed_attempts, locked_until\n                FROM users WHERE username = ?\n            ''', (username,))\n            \n            user = cursor.fetchone()\n            \n            if not user:\n                return {'success': False, 'error': 'Invalid username or password'}\n            \n            user_dict = dict(user)\n            \n            # Check if account is locked\n            if user_dict['locked_until']:\n                locked_until = datetime.fromisoformat(user_dict['locked_until'])\n                if datetime.now(KENYA_TZ) < locked_until:\n                    return {'success': False, 'error': 'Account is locked. Try again later.'}\n            \n            # Check if account is active\n            if not user_dict['is_active']:\n                return {'success': False, 'error': 'Account is disabled'}\n            \n            # Verify password\n            if not check_password_hash(user_dict['password_hash'], password):\n                # Increment failed attempts\n                cursor.execute('''\n                    UPDATE users SET failed_attempts = failed_attempts + 1\n                    WHERE id = ?\n                ''', (user_dict['id'],))\n                \n                # Lock account after 5 failed attempts\n                if user_dict['failed_attempts'] >= 4:\n                    locked_until = (datetime.now(KENYA_TZ) + timedelta(minutes=15)).strftime('%Y-%m-%d %H:%M:%S')\n                    cursor.execute('''\n                        UPDATE users SET locked_until = ?\n                        WHERE id = ?\n                    ''', (locked_until, user_dict['id']))\n                \n                conn.commit()\n                return {'success': False, 'error': 'Invalid username or password'}\n            \n            # Success - reset failed attempts and update last login\n            kenya_time = get_kenya_time()\n            cursor.execute('''\n                UPDATE users \n                SET failed_attempts = 0, locked_until = NULL, last_login = ?\n                WHERE id = ?\n            ''', (kenya_time, user_dict['id']))\n            conn.commit()\n            \n            # Log activity\n            self._log_activity(user_dict['id'], username, 'user_login', ip_address, 'User logged in')\n            \n            return {\n                'success': True,\n                'user': {\n                    'id': user_dict['id'],\n                    'username': user_dict['username'],\n                    'email': user_dict['email'],\n                    'role': user_dict['role']\n                }\n            }\n            \n        except Exception as e:\n            conn.rollback()\n            return {'success': False, 'error': str(e)}\n        finally:\n            conn.close()\n    \n    def create_session(self, user_id, ip_address, user_agent):\n        \"\"\"Create a new session token for user\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            session_token = secrets.token_urlsafe(32)\n            kenya_time = get_kenya_time()\n            expires_at = (datetime.now(KENYA_TZ) + timedelta(days=7)).strftime('%Y-%m-%d %H:%M:%S')\n            \n            cursor.execute('''\n                INSERT INTO user_sessions (user_id, session_token, ip_address, user_agent, created_at, expires_at)\n                VALUES (?, ?, ?, ?, ?, ?)\n            ''', (user_id, session_token, ip_address, user_agent, kenya_time, expires_at))\n            \n            conn.commit()\n            return session_token\n            \n        except Exception as e:\n            conn.rollback()\n            print(f\"Error creating session: {e}\")\n            return None\n        finally:\n            conn.close()\n    \n    def get_all_users(self):\n        \"\"\"Get all users for admin panel\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                SELECT id, username, email, role, is_active, created_at, last_login\n                FROM users\n                ORDER BY created_at DESC\n            ''')\n            \n            users = [dict(row) for row in cursor.fetchall()]\n            return users\n        finally:\n            conn.close()\n    \n    def deactivate_user(self, user_id):\n        \"\"\"Deactivate a user account\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('UPDATE users SET is_active = 0 WHERE id = ?', (user_id,))\n            conn.commit()\n            return True\n        except Exception as e:\n            conn.rollback()\n            print(f\"Error deactivating user: {e}\")\n            return False\n        finally:\n            conn.close()\n    \n    def get_user_activity(self, limit=100):\n        \"\"\"Get recent user activity\"\"\"\n        conn = self.db.get_connection()\n        cursor = conn.cursor()\n        \n        try:\n            cursor.execute('''\n                SELECT username, action, timestamp, ip_address, details\n                FROM user_activity\n                ORDER BY timestamp DESC\n                LIMIT ?\n            ''', (limit,))\n            \n            activity = [dict(row) for row in cursor.fetchall()]\n            return activity\n        finally:\n            conn.close()\n    \n    def _log_activity(self, user_id, username, action, ip_address, details):\n        \"\"\"Log user activity - synchronous\"\"\"\n        try:\n            conn = self.db.get_connection()\n            cursor = conn.cursor()\n            kenya_time = get_kenya_time()\n            cursor.execute('''\n                INSERT INTO user_activity (user_id, username, action, timestamp, ip_address, details)\n                VALUES (?, ?, ?, ?, ?, ?)\n            ''', (user_id, username, action, kenya_time, ip_address, details))\n            conn.commit()\n            conn.close()\n        except:\n            pass  # Silent fail - don't block on logging\n    \n    def _log_activity_async(self, user_id, username, action, ip_address, details):\n        \"\"\"Log user activity - async version (doesn't block)\"\"\"\n        import threading\n        def log():\n            try:\n                self._log_activity(user_id, username, action, ip_address, details)\n            except:\n                pass\n        threading.Thread(target=log, daemon=True).start()","size_bytes":35675},"monitoring/__init__.py":{"content":"\"\"\"\nMonitoring package for NetWatch SIEM\nProvides advanced network monitoring, traffic analysis, and threat detection\n\"\"\"\n\nfrom .advanced_scanner import AdvancedNetworkScanner\nfrom .traffic_analyzer import TrafficAnalyzer, ThreatDetector, AnomalyDetector\n\n__all__ = [\n    'AdvancedNetworkScanner',\n    'TrafficAnalyzer', \n    'ThreatDetector',\n    'AnomalyDetector'\n]\n","size_bytes":368},"rules/__init__.py":{"content":"","size_bytes":0},"static/js/dashboard.js":{"content":"let activityChart = null;\n\nfunction updateDashboardStats() {\n    const el = document.getElementById('totalDevices');\n    if (!el) return;\n    \n    fetch('/api/dashboard/stats')\n        .then(res => res.json())\n        .then(data => {\n            if (data.success) {\n                document.getElementById('totalDevices').textContent = data.data.total_devices;\n                document.getElementById('activeDevices').textContent = data.data.active_devices;\n                document.getElementById('criticalAlerts').textContent = data.data.critical_alerts;\n                document.getElementById('trustedDevices').textContent = data.data.trusted_devices;\n            }\n        })\n        .catch(err => console.error('Stats error:', err));\n}\n\nfunction updateRecentAlerts() {\n    const container = document.getElementById('alertsList');\n    if (!container) return;\n    \n    fetch('/api/alerts?limit=5')\n        .then(res => res.json())\n        .then(data => {\n            if (data.success && data.data.length > 0) {\n                container.innerHTML = data.data.map(alert => `\n                    <div class=\"alert-box ${alert.severity} fade-in\">\n                        <i data-feather=\"${\n                            alert.severity === 'high' ? 'alert-octagon' :\n                            alert.severity === 'medium' ? 'alert-triangle' : 'info'\n                        }\" class=\"text-${\n                            alert.severity === 'high' ? 'red' :\n                            alert.severity === 'medium' ? 'amber' : 'blue'\n                        }-400\"></i>\n                        <div class=\"flex-1\">\n                            <p class=\"font-medium\">${alert.title}</p>\n                            <p class=\"text-xs text-slate-400\">${alert.description} • ${formatTime(alert.timestamp)}</p>\n                        </div>\n                    </div>\n                `).join('');\n                feather.replace();\n            } else {\n                container.innerHTML = '<p class=\"text-slate-400 text-sm\">No alerts</p>';\n            }\n        })\n        .catch(err => console.error('Alerts error:', err));\n}\n\nfunction updateActiveDevices() {\n    const container = document.getElementById('devicesList');\n    if (!container) return;\n    \n    fetch('/api/devices/active')\n        .then(res => res.json())\n        .then(data => {\n            if (data.success && data.data.length > 0) {\n                container.innerHTML = data.data.slice(0, 5).map(device => {\n                    // Normalize device name\n                    let deviceName = device.device_name || device.hostname || null;\n                    if (!deviceName || deviceName.trim() === '' || deviceName === 'Unknown') {\n                        deviceName = 'Unknown';\n                    }\n                    \n                    return `\n                    <div class=\"device-card fade-in\">\n                        <div class=\"flex items-center justify-between\">\n                            <div class=\"flex items-center gap-3\">\n                                <div class=\"w-8 h-8 rounded-full bg-emerald-500/20 flex items-center justify-center\">\n                                    <i data-feather=\"wifi\" class=\"w-4 h-4 text-emerald-400\"></i>\n                                </div>\n                                <div>\n                                    <p class=\"font-medium\">${deviceName}</p>\n                                    <p class=\"text-xs text-slate-400\">${device.ip_address} • ${device.vendor || 'Unknown'}</p>\n                                </div>\n                            </div>\n                            <span class=\"status-badge status-online\">Online</span>\n                        </div>\n                    </div>\n                `;\n                }).join('');\n                feather.replace();\n            } else {\n                container.innerHTML = '<p class=\"text-slate-400 text-sm\">No devices detected</p>';\n            }\n        })\n        .catch(err => console.error('Devices error:', err));\n}\n\nfunction updateActivityChart() {\n    const ctx = document.getElementById('networkChart');\n    if (!ctx) return;\n    \n    fetch('/api/activity/timeline')\n        .then(res => res.json())\n        .then(data => {\n            if (data.success) {\n                const canvasContext = ctx.getContext('2d');\n                \n                const chartData = {\n                    labels: data.data.map(d => {\n                        const time = new Date(d.time);\n                        return time.toLocaleTimeString('en-US', { \n                            hour: '2-digit', \n                            minute: '2-digit',\n                            hour12: false \n                        });\n                    }),\n                    datasets: [{\n                        label: 'Network Events',\n                        data: data.data.map(d => d.count),\n                        borderColor: '#3b82f6',\n                        backgroundColor: 'rgba(59, 130, 246, 0.1)',\n                        borderWidth: 2,\n                        fill: true,\n                        tension: 0.4,\n                        pointRadius: 4,\n                        pointBackgroundColor: '#3b82f6',\n                        pointBorderColor: '#ffffff',\n                        pointBorderWidth: 2,\n                        pointHoverRadius: 6\n                    }]\n                };\n                \n                if (activityChart) {\n                    activityChart.destroy();\n                }\n                \n                activityChart = new Chart(canvasContext, {\n                    type: 'line',\n                    data: chartData,\n                    options: {\n                        responsive: true,\n                        maintainAspectRatio: false,\n                        animation: { duration: 300 },\n                        plugins: {\n                            legend: { display: false },\n                            tooltip: {\n                                backgroundColor: 'rgba(15, 23, 42, 0.8)',\n                                borderColor: '#3b82f6',\n                                borderWidth: 1,\n                                titleColor: '#e2e8f0',\n                                bodyColor: '#cbd5e1',\n                                padding: 12,\n                                cornerRadius: 6\n                            }\n                        },\n                        scales: {\n                            y: {\n                                beginAtZero: true,\n                                grid: {\n                                    color: 'rgba(51, 65, 85, 0.3)',\n                                    drawBorder: false\n                                },\n                                ticks: {\n                                    color: '#94a3b8',\n                                    font: { size: 12 }\n                                }\n                            },\n                            x: {\n                                grid: {\n                                    color: 'rgba(51, 65, 85, 0.2)',\n                                    drawBorder: false\n                                },\n                                ticks: {\n                                    color: '#94a3b8',\n                                    font: { size: 12 },\n                                    maxTicksLimit: 12\n                                }\n                            }\n                        }\n                    }\n                });\n            }\n        })\n        .catch(err => console.error('Timeline error:', err));\n}\n\nfunction formatTime(timestamp) {\n    const now = new Date();\n    const time = new Date(timestamp);\n    const diff = Math.floor((now - time) / 1000);\n    \n    if (diff < 60) return 'Just now';\n    if (diff < 3600) return `${Math.floor(diff / 60)} min ago`;\n    if (diff < 86400) return `${Math.floor(diff / 3600)}h ago`;\n    return time.toLocaleDateString();\n}\n\nasync function updateQuickAnalytics() {\n    try {\n        const healthEl = document.getElementById('quickHealthScore');\n        if (!healthEl) return;\n        \n        const healthResponse = await fetch('/api/analytics/network-health');\n        const healthData = await healthResponse.json();\n        \n        if (healthData.success) {\n            const healthScore = healthData.data.health_score;\n            document.getElementById('quickHealthScore').textContent = healthScore;\n            \n            if (healthScore >= 80) {\n                healthEl.className = 'text-2xl font-bold text-emerald-400';\n            } else if (healthScore >= 60) {\n                healthEl.className = 'text-2xl font-bold text-yellow-400';\n            } else {\n                healthEl.className = 'text-2xl font-bold text-red-400';\n            }\n        }\n        \n        const trendsResponse = await fetch('/api/analytics/device-trends');\n        const trendsData = await trendsResponse.json();\n        \n        if (trendsData.success && trendsData.data.vendor_distribution.length > 0) {\n            const topVendor = trendsData.data.vendor_distribution[0];\n            const vendorEl = document.getElementById('topVendor');\n            if (vendorEl) vendorEl.textContent = topVendor.vendor;\n        }\n        \n        const alertResponse = await fetch('/api/analytics/alert-trends');\n        const alertData = await alertResponse.json();\n        \n        if (alertData.success && alertData.data.alert_trends.length > 0) {\n            const recentAlerts = alertData.data.alert_trends.slice(-7);\n            const totalAlerts = recentAlerts.reduce((sum, day) => sum + day.total, 0);\n            const alertRate = Math.round(totalAlerts / 7);\n            const rateEl = document.getElementById('alertRate');\n            if (rateEl) rateEl.textContent = `${alertRate}/d`;\n        }\n        \n    } catch (error) {\n        console.error('Error loading quick analytics:', error);\n    }\n}\n\nfunction updatePageData() {\n    updateRecentAlerts();\n    updateActiveDevices();\n}\n\nwindow.updatePageData = updatePageData;\n\nfunction initializeDashboard() {\n    const dashboardEl = document.getElementById('totalDevices');\n    if (!dashboardEl) return;\n    \n    updateDashboardStats();\n    updateRecentAlerts();\n    updateActiveDevices();\n    updateActivityChart();\n    updateQuickAnalytics();\n    \n    // Setup real-time Socket.IO listeners\n    setupRealtimeListeners();\n}\n\nfunction setupRealtimeListeners() {\n    // Wait for socket to be ready\n    function setup() {\n        if (typeof io !== 'undefined' && window.netwatchRealtime && window.netwatchRealtime.socket && window.netwatchRealtime.socket.connected) {\n            // Remove existing listeners to avoid duplicates\n            window.netwatchRealtime.socket.off('dashboard_stats_update');\n            window.netwatchRealtime.socket.off('device_list_update');\n            window.netwatchRealtime.socket.off('device_status_update');\n            \n            // Listen for dashboard stats updates\n            window.netwatchRealtime.socket.on('dashboard_stats_update', (data) => {\n                if (data && data.stats) {\n                    updateDashboardStats();\n                }\n            });\n            \n            // Listen for device list updates\n            window.netwatchRealtime.socket.on('device_list_update', (data) => {\n                if (data && data.devices) {\n                    updateActiveDevices();\n                    updateDashboardStats();\n                }\n            });\n            \n            // Listen for device status changes\n            window.netwatchRealtime.socket.on('device_status_update', (data) => {\n                if (data && data.changes) {\n                    updateActiveDevices();\n                    updateDashboardStats();\n                }\n            });\n            \n            console.log('Real-time listeners setup for dashboard');\n        } else {\n            // Retry after a short delay\n            setTimeout(setup, 500);\n        }\n    }\n    \n    setup();\n}\n\ndocument.addEventListener('DOMContentLoaded', () => {\n    initializeDashboard();\n});\n\n// Fallback polling (only if socket not connected)\nlet fallbackInterval = null;\nfunction startFallbackPolling() {\n    if (fallbackInterval) return;\n    \n    fallbackInterval = setInterval(() => {\n        // Only poll if socket is not connected\n        if (!window.netwatchRealtime || !window.netwatchRealtime.isConnected) {\n            if (document.getElementById('totalDevices')) {\n                updateRecentAlerts();\n                updateActiveDevices();\n                updateDashboardStats();\n            }\n        }\n    }, 5000);  // Poll every 5 seconds as fallback\n}\n\n// Start fallback polling after initial load\nsetTimeout(startFallbackPolling, 2000);","size_bytes":12742},"security/rbac.py":{"content":"\"\"\"\nRole-Based Access Control (RBAC) for NetWatch SIEM\nDefines permissions for each role and checks access\n\"\"\"\n\nfrom functools import wraps\nfrom flask import session, jsonify, redirect, url_for, flash\n\n# Define role permissions - SIMPLIFIED: only admin and viewer\nROLE_PERMISSIONS = {\n    'admin': {\n        'all': True,  # Admins have all permissions\n        'view_devices': True,\n        'manage_devices': True,\n        'view_alerts': True,\n        'manage_alerts': True,\n        'view_logs': True,\n        'manage_logs': True,\n        'view_analytics': True,\n        'manage_rules': True,\n        'manage_users': True,\n        'manage_config': True,\n        'scan_network': True\n    },\n    'viewer': {\n        'view_devices': True,\n        'view_alerts': True,\n        'view_logs': True,\n        'view_analytics': True\n    }\n}\n\ndef has_permission(permission):\n    \"\"\"Check if current user has a specific permission\"\"\"\n    if 'logged_in' not in session:\n        return False\n    \n    role = session.get('role', 'viewer')\n    \n    # Admin has all permissions\n    if role == 'admin':\n        return True\n    \n    # Check role permissions\n    role_perms = ROLE_PERMISSIONS.get(role, {})\n    return role_perms.get(permission, False) or role_perms.get('all', False)\n\ndef require_permission(permission, redirect_on_fail=True):\n    \"\"\"Decorator to require a specific permission\"\"\"\n    def decorator(f):\n        @wraps(f)\n        def decorated_function(*args, **kwargs):\n            if not has_permission(permission):\n                if redirect_on_fail:\n                    flash('Insufficient permissions', 'error')\n                    return redirect(url_for('index'))\n                return jsonify({'success': False, 'error': 'Insufficient permissions'}), 403\n            return f(*args, **kwargs)\n        return decorated_function\n    return decorator\n\ndef require_any_permission(*permissions):\n    \"\"\"Require at least one of the given permissions\"\"\"\n    def decorator(f):\n        @wraps(f)\n        def decorated_function(*args, **kwargs):\n            if 'logged_in' not in session:\n                flash('Please log in', 'error')\n                return redirect(url_for('login'))\n            \n            if any(has_permission(perm) for perm in permissions):\n                return f(*args, **kwargs)\n            \n            flash('Insufficient permissions', 'error')\n            return redirect(url_for('index'))\n        return decorated_function\n    return decorator\n\ndef get_user_role():\n    \"\"\"Get current user's role\"\"\"\n    return session.get('role', 'viewer')\n\ndef is_admin():\n    \"\"\"Check if current user is admin\"\"\"\n    return session.get('is_admin', False) or session.get('role') == 'admin'\n\n","size_bytes":2703},"static/js/alerts.js":{"content":"function updateAlertsList() {\n    fetch('/api/alerts')\n        .then(res => res.json())\n        .then(data => {\n            const container = document.getElementById('alertsContainer');\n            if (data.success && data.data.length > 0) {\n                container.innerHTML = data.data.map(alert => `\n                    <div class=\"alert-box ${alert.severity} fade-in\">\n                        <i data-feather=\"${\n                            alert.severity === 'high' ? 'alert-octagon' :\n                            alert.severity === 'medium' ? 'alert-triangle' : 'info'\n                        }\" class=\"text-${\n                            alert.severity === 'high' ? 'red' :\n                            alert.severity === 'medium' ? 'amber' : 'blue'\n                        }-400 mt-0.5\"></i>\n                        <div class=\"flex-1\">\n                            <p class=\"font-medium\">${alert.title}</p>\n                            <p class=\"text-sm text-slate-300 mt-1\">${alert.description}</p>\n                            <div class=\"flex items-center gap-4 mt-2 text-xs text-slate-400\">\n                                <span>${formatTime(alert.timestamp)}</span>\n                                ${alert.ip_address ? `<span>Device: ${alert.ip_address}</span>` : ''}\n                                <span class=\"px-2 py-0.5 rounded ${\n                                    alert.severity === 'high' ? 'bg-red-500/20 text-red-400' :\n                                    alert.severity === 'medium' ? 'bg-amber-500/20 text-amber-400' :\n                                    'bg-blue-500/20 text-blue-400'\n                                }\">${alert.severity.toUpperCase()}</span>\n                            </div>\n                        </div>\n                        <div class=\"flex gap-2\">\n                            ${alert.status === 'active' ? `\n                                <button onclick=\"markAlertSafe(${alert.id})\" \n                                        class=\"px-3 py-1 bg-emerald-600 hover:bg-emerald-700 rounded text-sm flex items-center gap-1\"\n                                        title=\"Mark as safe/false positive\">\n                                    <i data-feather=\"shield\" class=\"w-3 h-3\"></i>\n                                    Safe\n                                </button>\n                                <button onclick=\"resolveAlert(${alert.id})\" \n                                        class=\"px-3 py-1 bg-blue-600 hover:bg-blue-700 rounded text-sm flex items-center gap-1\">\n                                    <i data-feather=\"check\" class=\"w-3 h-3\"></i>\n                                    Resolve\n                                </button>\n                            ` : `\n                                <span class=\"px-3 py-1 bg-slate-700 rounded text-sm text-slate-400\">Resolved</span>\n                            `}\n                        </div>\n                    </div>\n                `).join('');\n                feather.replace();\n            } else {\n                container.innerHTML = '<p class=\"text-slate-400 text-sm\">No alerts found</p>';\n            }\n        });\n}\n\nfunction markAlertSafe(alertId) {\n    if (!confirm('Mark this alert as safe/false positive? This will resolve it permanently.')) {\n        return;\n    }\n    \n    fetch(`/api/alerts/${alertId}/mark-safe`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' }\n    })\n    .then(res => res.json())\n    .then(data => {\n        if (data.success) {\n            updateAlertsList();\n            showNotification('Alert marked as safe', 'success');\n        } else {\n            showNotification('Error: ' + data.error, 'error');\n        }\n    });\n}\n\nfunction resolveAlert(alertId) {\n    fetch(`/api/alerts/${alertId}/resolve`, {\n        method: 'POST'\n    })\n    .then(res => res.json())\n    .then(data => {\n        if (data.success) {\n            updateAlertsList();\n            showNotification('Alert resolved', 'success');\n        }\n    });\n}\n\nfunction formatTime(timestamp) {\n    try {\n        return new Date(timestamp).toLocaleString('en-KE', {\n            timeZone: 'Africa/Nairobi',\n            year: 'numeric',\n            month: 'short',\n            day: 'numeric',\n            hour: '2-digit',\n            minute: '2-digit'\n        });\n    } catch {\n        return new Date(timestamp).toLocaleString();\n    }\n}\n\nfunction showNotification(message, type = 'info') {\n    const notification = document.createElement('div');\n    notification.className = `fixed top-4 right-4 px-4 py-3 rounded shadow-lg ${\n        type === 'success' ? 'bg-emerald-500' : 'bg-red-500'\n    } text-white z-50`;\n    notification.textContent = message;\n    document.body.appendChild(notification);\n    \n    setTimeout(() => notification.remove(), 3000);\n}\n\nwindow.updatePageData = updateAlertsList;\n\nupdateAlertsList();\nsetInterval(updateAlertsList, 5000);","size_bytes":4894},"scanner/device_scanner.py":{"content":"import socket\nimport subprocess\nimport re\nfrom scapy.all import ARP, Ether, srp\nimport psutil\nfrom datetime import datetime\nimport threading\nimport time\nimport ipaddress\nimport logging\nimport hashlib\nimport os\nimport concurrent.futures\n\nclass Colors:\n    CYAN = '\\033[96m'\n    GREEN = '\\033[92m'\n    MAGENTA = '\\033[95m'\n    YELLOW = '\\033[93m'\n    RED = '\\033[91m'\n    BLUE = '\\033[94m'\n    WHITE = '\\033[97m'\n    DARK_GRAY = '\\033[90m'\n    LIGHT_CYAN = '\\033[96m'\n    RESET = '\\033[0m'\n    BOLD = '\\033[1m'\n    DIM = '\\033[2m'\n    BRIGHT_GREEN = '\\033[92m'\n    BRIGHT_CYAN = '\\033[96m'\n    BRIGHT_MAGENTA = '\\033[95m'\n\nclass DynamicNetworkDetector:\n    def __init__(self, verbose=False):\n        self.previous_network = None\n        self.network_cache = {}\n        self.verbose = verbose\n    \n    def auto_detect_network(self):\n        current_network = self._get_current_network_context()\n        \n        if current_network in self.network_cache:\n            return self.network_cache[current_network]\n        \n        network_info = self._discover_network_properties()\n        self.network_cache[current_network] = network_info\n        return network_info\n    \n    def _get_current_network_context(self):\n        default_gateway = self._get_default_gateway()\n        interface = self._get_active_interface()\n        ssid = self._get_wifi_ssid() if self._is_wifi() else \"wired\"\n        \n        network_id = f\"{interface}:{default_gateway}:{ssid}\"\n        return hashlib.md5(network_id.encode()).hexdigest()\n    \n    def _discover_network_properties(self):\n        network_info = {\n            'interface': self._get_active_interface(),\n            'ip_address': self._get_my_ip(),\n            'subnet': self._calculate_subnet(),\n            'network_range': self._get_network_range(),\n            'gateway': self._get_default_gateway(),\n            'network_type': self._determine_network_type(),\n            'optimal_scan_methods': self._determine_best_scan_methods(),\n            'estimated_size': self._estimate_network_size(),\n            'discovery_time': datetime.now()\n        }\n        \n        return network_info\n\n    def _get_active_interface(self):\n        try:\n            interfaces = psutil.net_if_stats()\n            valid_interfaces = []\n            \n            for iface, stats in interfaces.items():\n                if not stats.isup:\n                    continue\n                    \n                iface_lower = iface.lower()\n                \n                if iface_lower.startswith(('lo', 'docker', 'veth', 'br-')):\n                    continue\n                if any(bad in iface_lower for bad in ['vmware', 'vmnet', 'virtual', 'vbox', 'hyper-v', 'virtualbox']):\n                    continue\n                \n                addrs = psutil.net_if_addrs().get(iface, [])\n                for addr in addrs:\n                    if addr.family == socket.AF_INET:\n                        ip = addr.address\n                        \n                        if ip.startswith('127.'):\n                            continue\n                        \n                        priority = self._calculate_interface_priority(iface_lower, ip)\n                        valid_interfaces.append((iface, ip, priority))\n                        break\n            \n            if not valid_interfaces:\n                return \"unknown\"\n            \n            valid_interfaces.sort(key=lambda x: x[2])\n            best_iface = valid_interfaces[0][0]\n            return best_iface\n            \n        except Exception as e:\n            return \"unknown\"\n\n    def _calculate_interface_priority(self, iface_lower, ip):\n        priority = 100\n        \n        if ip.startswith('169.254.'):\n            priority += 1000\n        elif ip.startswith('192.168.'):\n            priority -= 50\n        elif ip.startswith('10.'):\n            priority -= 40\n        elif ip.startswith('172.'):\n            priority -= 30\n        \n        if any(term in iface_lower for term in ['ethernet', 'eth']):\n            priority -= 20\n        if any(term in iface_lower for term in ['wi-fi', 'wlan', 'wireless', 'wifi']):\n            priority -= 15\n        \n        return priority\n\n    def _get_my_ip(self):\n        try:\n            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n            s.connect((\"8.8.8.8\", 80))\n            ip = s.getsockname()[0]\n            s.close()\n            \n            if not ip.startswith('169.254.'):\n                return ip\n        except:\n            pass\n        \n        try:\n            active_iface = self._get_active_interface()\n            if active_iface != \"unknown\":\n                interfaces = psutil.net_if_addrs()\n                for iface, addrs in interfaces.items():\n                    if iface == active_iface:\n                        for addr in addrs:\n                            if addr.family == socket.AF_INET and not addr.address.startswith('127.'):\n                                return addr.address\n            \n            for iface, addrs in psutil.net_if_addrs().items():\n                iface_lower = iface.lower()\n                \n                if any(bad in iface_lower for bad in ['lo', 'docker', 'veth', 'vmware', 'vbox', 'virtual']):\n                    continue\n                \n                for addr in addrs:\n                    if addr.family == socket.AF_INET:\n                        ip = addr.address\n                        if not ip.startswith(('127.', '169.254.')):\n                            return ip\n        except:\n            pass\n        \n        return \"127.0.0.1\"\n\n    def _calculate_subnet(self):\n        try:\n            interfaces = psutil.net_if_addrs()\n            active_iface = self._get_active_interface()\n            \n            if active_iface == \"unknown\":\n                return \"192.168.1.0/24\"\n            \n            for iface, addrs in interfaces.items():\n                if iface == active_iface:\n                    for addr in addrs:\n                        if addr.family == socket.AF_INET:\n                            if addr.address.startswith('169.254.'):\n                                continue\n                            \n                            try:\n                                ip = ipaddress.IPv4Interface(f\"{addr.address}/{addr.netmask}\")\n                                network = str(ip.network)\n                                \n                                net_obj = ipaddress.IPv4Network(network)\n                                if net_obj.num_addresses > 1024:\n                                    base_ip = addr.address.rsplit('.', 1)[0]\n                                    return f\"{base_ip}.0/24\"\n                                \n                                return network\n                            except:\n                                continue\n            \n            my_ip = self._get_my_ip()\n            if not my_ip.startswith(('127.', '169.254.')):\n                return f\"{my_ip.rsplit('.', 1)[0]}.0/24\"\n            \n            return \"192.168.1.0/24\"\n            \n        except Exception as e:\n            return \"192.168.1.0/24\"\n\n    def _get_network_range(self):\n        return self._calculate_subnet()\n\n    def _get_default_gateway(self):\n        try:\n            if os.name == 'nt':\n                result = subprocess.run(['ipconfig'], capture_output=True, text=True, shell=True)\n                for line in result.stdout.split('\\n'):\n                    if 'Default Gateway' in line and '.' in line:\n                        parts = line.split(':')\n                        if len(parts) > 1:\n                            gateway = parts[1].strip()\n                            if gateway and gateway not in ['0.0.0.0', ''] and not gateway.startswith('169.254.'):\n                                return gateway\n            else:\n                result = subprocess.run(['ip', 'route'], capture_output=True, text=True)\n                for line in result.stdout.split('\\n'):\n                    if 'default' in line:\n                        parts = line.split()\n                        if len(parts) > 2:\n                            return parts[2]\n            return \"unknown\"\n        except:\n            return \"unknown\"\n\n    def _is_wifi(self):\n        try:\n            interfaces = psutil.net_if_addrs()\n            for iface in interfaces:\n                iface_lower = iface.lower()\n                if any(wireless_term in iface_lower for wireless_term in ['wireless', 'wlan', 'wi-fi', 'wi fi', 'wifi']):\n                    return True\n            return False\n        except:\n            return False\n\n    def _get_wifi_ssid(self):\n        try:\n            if os.name == 'nt':\n                result = subprocess.run(['netsh', 'wlan', 'show', 'interfaces'], capture_output=True, text=True, shell=True)\n                for line in result.stdout.split('\\n'):\n                    if 'SSID' in line and 'BSSID' not in line:\n                        parts = line.split(':')\n                        if len(parts) > 1:\n                            return parts[1].strip()\n            else:\n                try:\n                    result = subprocess.run(['iwgetid', '-r'], capture_output=True, text=True)\n                    if result.stdout.strip():\n                        return result.stdout.strip()\n                except:\n                    pass\n        except:\n            pass\n        return \"unknown\"\n\n    def _determine_network_type(self):\n        my_ip = self._get_my_ip()\n        \n        if my_ip.startswith('10.'):\n            return \"Corporate Network\"\n        elif my_ip.startswith('192.168.'):\n            return \"Home/Small Business\"\n        elif my_ip.startswith('172.'):\n            try:\n                octets = my_ip.split('.')\n                second = int(octets[1])\n                if 16 <= second <= 31:\n                    return \"Enterprise Network\"\n            except:\n                pass\n            return \"Public Network\"\n        elif my_ip.startswith('169.254.'):\n            return \"Link-Local (APIPA)\"\n        else:\n            return \"Public Network\"\n\n    def _determine_best_scan_methods(self):\n        network_type = self._determine_network_type()\n        my_ip = self._get_my_ip()\n        \n        if my_ip.startswith('169.254.'):\n            return ['ping_sweep']\n        \n        method_profiles = {\n            \"Home/Small Business\": ['arp_scan', 'ping_sweep'],\n            \"Corporate Network\": ['ping_sweep', 'arp_scan'],\n            \"Enterprise Network\": ['arp_scan', 'ping_sweep'],\n            \"Public Network\": ['ping_sweep'],\n            \"Link-Local (APIPA)\": ['ping_sweep']\n        }\n        \n        return method_profiles.get(network_type, ['arp_scan', 'ping_sweep'])\n\n    def _estimate_network_size(self):\n        network_type = self._determine_network_type()\n        size_estimates = {\n            \"Home/Small Business\": 50,\n            \"Corporate Network\": 1000,\n            \"Enterprise Network\": 500,\n            \"Public Network\": 200,\n            \"Link-Local (APIPA)\": 10\n        }\n        return size_estimates.get(network_type, 100)\n\nclass DeviceScanner:\n    def __init__(self, db, verbose=False, show_banner=True):\n        self.db = db\n        self.scanning = False\n        self.scan_thread = None\n        self.mac_vendors = self._load_mac_vendors()\n        self.network_detector = DynamicNetworkDetector(verbose=verbose)\n        self.verbose = verbose\n        self.banner_shown = False\n        self.show_banner = show_banner\n        \n        # Initialize hostname resolver\n        self.hostname_resolver = None\n        try:\n            from .hostname_resolver import hostname_resolver\n            self.hostname_resolver = hostname_resolver\n        except ImportError:\n            pass  # Will use fallback method\n        \n        if self.show_banner and not self.banner_shown:\n            self._print_startup_banner()\n\n    def _print_startup_banner(self):\n        \"\"\"Clean, beautiful startup banner\"\"\"\n        width = 80\n        # Use ASCII characters for Windows compatibility\n        print(f\"\\n{Colors.CYAN}{'=' * width}{Colors.RESET}\")\n        print(f\"{Colors.CYAN}|{Colors.RESET}{' ' * (width - 2)}{Colors.CYAN}|{Colors.RESET}\")\n        \n        title = \"NETWATCH SIEM\"\n        print(f\"{Colors.CYAN}|{Colors.RESET}{Colors.BRIGHT_CYAN}{Colors.BOLD}{title.center(width - 2)}{Colors.RESET}{Colors.CYAN}|{Colors.RESET}\")\n        \n        subtitle = \"NETWORK SCANNER\"\n        print(f\"{Colors.CYAN}|{Colors.RESET}{Colors.MAGENTA}{subtitle.center(width - 2)}{Colors.RESET}{Colors.CYAN}|{Colors.RESET}\")\n        \n        tagline = \">>> ACTIVE NETWORK DISCOVERY TOOL <<<\"\n        print(f\"{Colors.CYAN}|{Colors.RESET}{Colors.GREEN}{tagline.center(width - 2)}{Colors.RESET}{Colors.CYAN}|{Colors.RESET}\")\n        \n        print(f\"{Colors.CYAN}|{Colors.RESET}{' ' * (width - 2)}{Colors.CYAN}|{Colors.RESET}\")\n        \n        author = \"Created by: John O. Mark\"\n        print(f\"{Colors.CYAN}|{Colors.RESET}{Colors.YELLOW}{author.center(width - 2)}{Colors.RESET}{Colors.CYAN}|{Colors.RESET}\")\n        \n        division = \"Security Research Division\"\n        print(f\"{Colors.CYAN}|{Colors.RESET}{Colors.YELLOW}{division.center(width - 2)}{Colors.RESET}{Colors.CYAN}|{Colors.RESET}\")\n        \n        print(f\"{Colors.CYAN}|{Colors.RESET}{' ' * (width - 2)}{Colors.CYAN}|{Colors.RESET}\")\n        print(f\"{Colors.CYAN}{'=' * width}{Colors.RESET}\\n\")\n        \n        print(f\"{Colors.GREEN}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} {Colors.BRIGHT_GREEN}[OK] NetWatch SIEM initialized successfully{Colors.RESET}\")\n        print(f\"{Colors.CYAN}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} {Colors.BRIGHT_CYAN}Ready to monitor your network...{Colors.RESET}\\n\")\n        self.banner_shown = True\n\n    def smart_scan(self):\n        \"\"\"Silent scanning - only prints scan completion\"\"\"\n        network_info = self.network_detector.auto_detect_network()\n        \n        if network_info['interface'] == 'unknown':\n            return []\n        \n        # Single line scanning indicator\n        print(f\"{Colors.CYAN}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} Scanning network {network_info['network_range']}...\", end='\\r')\n        \n        devices = self._adaptive_scan(network_info)\n        enriched_devices = self._add_network_context(devices, network_info)\n        \n        # Clean completion message\n        print(f\"{Colors.GREEN}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} {Colors.BRIGHT_GREEN}[OK] Scan completed - Found {len(enriched_devices)} devices{Colors.RESET}          \")\n        \n        return enriched_devices\n\n    def _adaptive_scan(self, network_info):\n        \"\"\"Enhanced adaptive scanning with multiple methods\"\"\"\n        all_devices = []\n        \n        # Try multiple scanning approaches for better coverage\n        scan_methods = [\n            ('ping_sweep', self.ping_sweep),\n            ('arp_scan', lambda: self.arp_scan(network_info['network_range'])),\n            ('aggressive_ping', lambda: self._aggressive_ping_scan(network_info))\n        ]\n        \n        with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n            future_to_method = {}\n            \n            for method_name, method_func in scan_methods:\n                future = executor.submit(method_func)\n                future_to_method[future] = method_name\n\n            for future in concurrent.futures.as_completed(future_to_method, timeout=90):\n                method_name = future_to_method[future]\n                try:\n                    devices = future.result(timeout=5)\n                    if devices:\n                        for device in devices:\n                            # Avoid duplicates by IP\n                            if not any(d.get('ip') == device.get('ip') for d in all_devices):\n                                all_devices.append(device)\n                except Exception as e:\n                    if self.verbose:\n                        print(f\"Scan method {method_name} failed: {e}\")\n                    pass  # Silent failure\n        \n        return all_devices\n    \n    def _aggressive_ping_scan(self, network_info):\n        \"\"\"More aggressive ping scanning for mobile devices\"\"\"\n        devices = []\n        \n        try:\n            network = ipaddress.ip_network(network_info['network_range'])\n            \n            # Scan more hosts with shorter timeouts\n            max_hosts = min(150, network.num_addresses - 2)\n            targets = [str(ip) for ip in list(network.hosts())[:max_hosts]]\n            \n            # Use more threads for faster scanning\n            import concurrent.futures\n            with concurrent.futures.ThreadPoolExecutor(max_workers=20) as executor:\n                future_to_ip = {\n                    executor.submit(self._fast_ping, ip): ip \n                    for ip in targets\n                }\n                \n                for future in concurrent.futures.as_completed(future_to_ip, timeout=45):\n                    ip = future_to_ip[future]\n                    try:\n                        result = future.result()\n                        if result:\n                            devices.append(result)\n                    except Exception:\n                        continue\n                    \n        except Exception as e:\n            if self.verbose:\n                print(f\"Aggressive ping scan error: {e}\")\n        \n        return devices\n    \n    def _fast_ping(self, ip):\n        \"\"\"Fast ping with minimal timeout for mobile devices\"\"\"\n        try:\n            if os.name == 'nt':\n                # Very fast Windows ping\n                result = subprocess.run(['ping', '-n', '1', '-w', '200', ip], \n                                      capture_output=True, text=True, timeout=1)\n            else:\n                result = subprocess.run(['ping', '-c', '1', '-W', '1', ip], \n                                      capture_output=True, text=True, timeout=1)\n            \n            if (result.returncode == 0 and \n                (\"Reply from\" in result.stdout or \"1 received\" in result.stdout or \n                 \"bytes from\" in result.stdout or \"ttl=\" in result.stdout.lower())):\n                \n                return {\n                    'ip': ip,\n                    'mac': 'Unknown',\n                    'vendor': 'Unknown',\n                    'hostname': self.get_hostname(ip),\n                    'discovery_method': 'aggressive_ping'\n                }\n        except Exception:\n            pass\n        \n        return None\n\n    def scan_network(self):\n        return self.smart_scan()\n\n    def _load_mac_vendors(self):\n        return {\n            '00:50:56': 'VMware', '00:0C:29': 'VMware', '00:05:69': 'VMware',\n            '00:1C:14': 'VMware', '08:00:27': 'VirtualBox', '52:54:00': 'QEMU/KVM',\n            '00:16:3E': 'Xen', 'DC:A6:32': 'Raspberry Pi', 'B8:27:EB': 'Raspberry Pi',\n            'E4:5F:01': 'Raspberry Pi', '00:1A:7D': 'Kindle', '00:17:88': 'Philips',\n        }\n\n    def get_vendor_from_mac(self, mac):\n        if not mac or mac == 'Unknown':\n            return 'Unknown'\n        mac_prefix = mac.upper()[:8]\n        return self.mac_vendors.get(mac_prefix, 'Unknown')\n    \n    def _enhance_device_info(self, device):\n        \"\"\"Enhance device information with better identification\"\"\"\n        enhanced = device.copy()\n        \n        # Try to get better hostname\n        if device.get('ip') and not device.get('hostname'):\n            hostname = self.get_hostname(device['ip'])\n            if hostname:\n                enhanced['hostname'] = hostname\n        \n        # Try to identify device type based on IP and hostname\n        device_type = self._identify_device_type(device)\n        enhanced['device_type'] = device_type\n        \n        # Try to get better vendor info\n        if device.get('mac') and device.get('mac') != 'Unknown':\n            vendor = self.get_vendor_from_mac(device['mac'])\n            enhanced['vendor'] = vendor\n        \n        return enhanced\n    \n    def _identify_device_type(self, device):\n        \"\"\"Identify device type based on available information\"\"\"\n        ip = device.get('ip', '')\n        hostname = device.get('hostname', '').lower()\n        mac = device.get('mac', '').upper()\n        \n        # Gateway detection\n        if ip.endswith('.1') or 'gateway' in hostname or 'router' in hostname:\n            return 'Gateway/Router'\n        \n        # Computer detection\n        if any(keyword in hostname for keyword in ['pc', 'computer', 'desktop', 'laptop', 'workstation']):\n            return 'Computer'\n        \n        # Mobile device detection\n        if any(keyword in hostname for keyword in ['phone', 'mobile', 'android', 'iphone']):\n            return 'Mobile Device'\n        \n        # IoT device detection\n        if any(keyword in hostname for keyword in ['iot', 'smart', 'sensor', 'camera']):\n            return 'IoT Device'\n        \n        # Printer detection\n        if any(keyword in hostname for keyword in ['printer', 'print', 'hp-', 'canon', 'epson']):\n            return 'Printer'\n        \n        # Default\n        return 'Unknown Device'\n\n    def arp_scan(self, target_ip):\n        \"\"\"Silent ARP scanning with Windows compatibility\"\"\"\n        try:\n            # Check if we're on Windows and ARP scanning is likely to fail\n            import platform\n            if platform.system() == \"Windows\":\n                if self.verbose:\n                    print(\"Windows detected - ARP scanning may require administrator privileges\")\n                # Try ARP scan but don't fail completely\n                try:\n                    return self._attempt_arp_scan(target_ip)\n                except Exception as e:\n                    if self.verbose:\n                        print(f\"ARP scan failed: {e}\")\n                    return []\n            else:\n                return self._attempt_arp_scan(target_ip)\n        except Exception as e:\n            if self.verbose:\n                print(f\"ARP scan error: {e}\")\n            return []\n    \n    def _attempt_arp_scan(self, target_ip):\n        \"\"\"Attempt ARP scanning with proper error handling\"\"\"\n        try:\n            network = ipaddress.IPv4Network(target_ip)\n            if network.num_addresses > 1024:\n                base = str(network.network_address).rsplit('.', 1)[0]\n                target_ip = f\"{base}.0/24\"\n        except:\n            pass\n        \n        arp = ARP(pdst=target_ip)\n        ether = Ether(dst=\"ff:ff:ff:ff:ff:ff\")\n        packet = ether / arp\n\n        iface = self.network_detector._get_active_interface()\n        if iface == \"unknown\":\n            return []\n\n        result = srp(packet, iface=iface, timeout=3, retry=1, verbose=0)[0]\n\n        devices = []\n        for sent, received in result:\n            devices.append({\n                'ip': received.psrc,\n                'mac': received.hwsrc.upper(),\n                'vendor': self.get_vendor_from_mac(received.hwsrc),\n                'discovery_method': 'arp_scan'\n            })\n\n        return devices\n\n    def ping_sweep(self, network_info):\n        \"\"\"Enhanced ping sweep with better device detection\"\"\"\n        devices = []\n        \n        try:\n            network = ipaddress.ip_network(network_info['network_range'])\n            \n            # Increase scan range for better coverage\n            max_hosts = min(100, network.num_addresses - 2)  # Increased from 30 to 100\n            targets = [str(ip) for ip in list(network.hosts())[:max_hosts]]\n            \n            # Use concurrent scanning for better performance\n            import concurrent.futures\n            with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n                future_to_ip = {\n                    executor.submit(self._ping_single_host, ip): ip \n                    for ip in targets\n                }\n                \n                for future in concurrent.futures.as_completed(future_to_ip, timeout=30):\n                    ip = future_to_ip[future]\n                    try:\n                        result = future.result()\n                        if result:\n                            devices.append(result)\n                    except Exception as e:\n                        if self.verbose:\n                            print(f\"Ping failed for {ip}: {e}\")\n                        continue\n                    \n        except Exception as e:\n            if self.verbose:\n                print(f\"Ping sweep error: {e}\")\n        \n        return devices\n    \n    def _ping_single_host(self, ip):\n        \"\"\"Ping a single host with enhanced detection\"\"\"\n        try:\n            if os.name == 'nt':\n                # Windows ping with shorter timeout for faster scanning\n                result = subprocess.run(['ping', '-n', '1', '-w', '500', ip], \n                                      capture_output=True, text=True, timeout=2)\n            else:\n                result = subprocess.run(['ping', '-c', '1', '-W', '1', ip], \n                                      capture_output=True, text=True, timeout=2)\n            \n            # Check for successful ping response\n            if (result.returncode == 0 and \n                (\"Reply from\" in result.stdout or \"1 received\" in result.stdout or \n                 \"bytes from\" in result.stdout or \"ttl=\" in result.stdout.lower())):\n                \n                # Try to get hostname for better identification\n                hostname = self.get_hostname(ip)\n                \n                return {\n                    'ip': ip,\n                    'mac': 'Unknown',\n                    'vendor': 'Unknown',\n                    'hostname': hostname,\n                    'discovery_method': 'ping_sweep'\n                }\n        except Exception:\n            pass\n        \n        return None\n\n    def get_hostname(self, ip):\n        \"\"\"Enhanced hostname resolution with multiple fallback methods\"\"\"\n        # Try enhanced resolver first\n        if self.hostname_resolver:\n            try:\n                hostname = self.hostname_resolver.resolve_hostname(ip)\n                if hostname:\n                    return hostname\n            except Exception:\n                pass\n        \n        # Fallback to basic DNS lookup\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            return hostname.split('.')[0] if hostname else None\n        except:\n            return None\n\n    def _add_network_context(self, devices, network_info):\n        \"\"\"Silent device context enrichment and saving\"\"\"\n        saved_count = 0\n        \n        # Collect all IPs for batch hostname resolution\n        device_ips = [d['ip'] for d in devices if d.get('ip') and d['ip'] != 'Unknown']\n        \n        # Batch resolve hostnames if enhanced resolver available\n        hostname_map = {}\n        if self.hostname_resolver and device_ips:\n            try:\n                hostname_map = self.hostname_resolver.resolve_multiple_hostnames(device_ips)\n            except Exception:\n                pass  # Will fall back to individual resolution\n        \n        for device in devices:\n            try:\n                # Enhance device information\n                enhanced_device = self._enhance_device_info(device)\n                device.update(enhanced_device)\n                \n                device['network_context'] = {\n                    'network_type': network_info['network_type'],\n                    'subnet': network_info['network_range'],\n                    'scan_location': self._infer_location(network_info),\n                    'trust_level': self._calculate_trust_level(device, network_info),\n                }\n                \n                # Get hostname from batch resolution or individual lookup\n                device_ip = device.get('ip')\n                hostname = None\n                if device_ip and device_ip in hostname_map:\n                    hostname = hostname_map[device_ip]\n                else:\n                    try:\n                        hostname = self.get_hostname(device_ip) if device_ip else None\n                    except:\n                        hostname = None\n                \n                # Normalize hostname - don't store \"Unknown\" string, use None instead\n                if not hostname or hostname.strip() == '' or hostname.lower() == 'unknown':\n                    hostname = None\n                \n                device['hostname'] = hostname\n                \n                if not device.get('ip') or device['ip'] == 'Unknown':\n                    continue\n                \n                mac = device.get('mac')\n                if not mac or mac == 'Unknown':\n                    try:\n                        ip_parts = device['ip'].split('.')\n                        mac = f\"00:00:00:{int(ip_parts[-3]):02x}:{int(ip_parts[-2]):02x}:{int(ip_parts[-1]):02x}\".upper()\n                        device['mac'] = mac\n                    except:\n                        mac = \"00:00:00:00:00:00\"\n                        device['mac'] = mac\n                \n                try:\n                    device_id = self.db.add_device(\n                        ip=device['ip'],\n                        mac=mac,\n                        hostname=device.get('hostname'),\n                        vendor=device.get('vendor', 'Unknown')\n                    )\n                    \n                    if device_id:\n                        saved_count += 1\n                        device['device_id'] = device_id\n                        \n                        self.db.add_event(\n                            event_type='device_scan',\n                            severity='info',\n                            description=f\"Device detected: {device['ip']} ({mac}) via {device.get('discovery_method', 'unknown')}\",\n                            device_id=device_id\n                        )\n                        \n                except Exception as db_error:\n                    pass  # Silent DB errors\n                    \n            except Exception as e:\n                continue\n        \n        return devices\n\n    def _infer_location(self, network_info):\n        if network_info['network_type'] == 'Home/Small Business':\n            return \"home_office\"\n        elif network_info['network_type'] == 'Corporate Network':\n            return \"enterprise\"\n        else:\n            return \"unknown\"\n\n    def _calculate_trust_level(self, device, network_info):\n        if device['ip'] == network_info['gateway']:\n            return \"gateway\"\n        elif device['vendor'] in ['Apple', 'Samsung', 'Microsoft']:\n            return \"trusted_vendor\"\n        else:\n            return \"unknown\"\n\n    def start_continuous_scan(self, interval=300):\n        self.scanning = True\n        \n        def scan_loop():\n            while self.scanning:\n                self.smart_scan()\n                time.sleep(interval)\n        \n        self.scan_thread = threading.Thread(target=scan_loop, daemon=True)\n        self.scan_thread.start()\n        \n        print(f\"{Colors.GREEN}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} {Colors.BRIGHT_GREEN}[OK] Continuous scanning started (interval: {interval}s){Colors.RESET}\")\n\n    def stop_scan(self):\n        self.scanning = False\n        if self.scan_thread:\n            self.scan_thread.join(timeout=5)\n        \n        print(f\"{Colors.YELLOW}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} {Colors.YELLOW}⚠ Continuous scanning stopped{Colors.RESET}\")","size_bytes":31377},"static/css/cyber-theme.css":{"content":":root {\n    --primary: #3b82f6;\n    --secondary: #10b981;\n    --danger: #ef4444;\n    --warning: #f59e0b;\n    --dark: #0f172a;\n    --darker: #020617;\n}\n\n.bg-darker {\n    background-color: var(--darker);\n}\n\n.cyber-card {\n    background: rgba(15, 23, 42, 0.7);\n    backdrop-filter: blur(10px);\n    border: 1px solid rgba(255, 255, 255, 0.05);\n}\n\n.status-online {\n    background: rgba(16, 185, 129, 0.1);\n    border-left: 4px solid var(--secondary);\n}\n\n.status-offline {\n    background: rgba(239, 68, 68, 0.1);\n    border-left: 4px solid var(--danger);\n}\n\n.status-unknown {\n    background: rgba(245, 158, 11, 0.1);\n    border-left: 4px solid var(--warning);\n}\n\n.active_scanning {\n    font-size: 10px;\n    animation: activeScanning 1.5s infinite alternate;\n    text-shadow: 0 0 5px currentColor;\n}\n\n@keyframes activeScanning {\n    0% {\n        color: rgba(0, 255, 255, 1.0);\n        transform: scale(1);\n        text-shadow: 0 0 5px rgba(0, 255, 255, 0.8);\n    }\n    20% {\n        color: rgba(0, 255, 0, 1.0); \n        transform: scale(1.15);\n        text-shadow: 0 0 15px rgba(0, 255, 0, 0.9);\n    }\n    40% {\n        color: rgba(255, 255, 0, 1.0);  \n        transform: scale(1.1);\n        text-shadow: 0 0 12px rgba(255, 255, 0, 0.8);\n    }\n    60% {\n        color: rgba(255, 165, 0, 1.0); \n        transform: scale(1.2);\n        text-shadow: 0 0 20px rgba(255, 165, 0, 0.9);\n    }\n    80% {\n        color: rgba(255, 0, 0, 1.0); \n        transform: scale(1.1);\n        text-shadow: 0 0 18px rgba(255, 0, 0, 0.9);\n    }\n    100% {\n        color: rgba(75, 0, 130, 1.0);         t\n        ransform: scale(1);\n        text-shadow: 0 0 25px rgba(75, 0, 130, 0.8);\n    }\n}\n\n\n\n.active_scanning_smooth {\n    font-size: 10px;\n    animation: smoothScanning 0.3s infinite;\n}\n\n@keyframes smoothScanning {\n    0% {\n        color: rgba(255, 0, 0, 1.0);\n        text-shadow: 0 0 15px rgba(255, 0, 0, 0.7);\n    }\n    50% {\n        color: rgba(0, 240, 10, 1.0);\n        text-shadow: 0 0 15px rgba(0, 240, 10, 0.7);\n    }\n    100% {\n        color: rgba(0, 100, 255, 1.0);\n        text-shadow: 0 0 15px rgba(0, 100, 255, 0.7);\n    }\n}\n\n.active_scanning {\n    display: inline-block;\n    width: 10px;\n    height: 10px;\n    border-radius: 50%;\n    animation: dotPulse 2s infinite;\n}\n\n@keyframes dotPulse {\n    0% {\n        background-color: #ff0000;\n        transform: scale(1);\n        box-shadow: 0 0 0 0 rgba(255, 0, 0, 0.7);\n    }\n    33% {\n        background-color: #00f00a;\n        transform: scale(1.2);\n        box-shadow: 0 0 0 10px rgba(0, 240, 10, 0);\n    }\n    66% {\n        background-color: #0064ff;\n        transform: scale(1.1);\n        box-shadow: 0 0 0 0 rgba(0, 100, 255, 0.7);\n    }\n    100% {\n        background-color: #ff0000;\n        transform: scale(1);\n        box-shadow: 0 0 0 0 rgba(255, 0, 0, 0);\n    }\n}\n\n.alert-critical {\n    animation: pulse 2s infinite;\n}\n\n@keyframes pulse {\n    0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.4); }\n    70% { box-shadow: 0 0 0 10px rgba(239, 68, 68, 0); }\n    100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }\n}\n\n.network-graph {\n    background: linear-gradient(135deg, rgba(15, 23, 42, 0.8) 0%, rgba(15, 23, 42, 0.5) 100%);\n}\n\n.alert-box {\n    padding: 0.75rem;\n    border-radius: 0.5rem;\n    margin-bottom: 0.5rem;\n    display: flex;\n    align-items: start;\n    gap: 0.75rem;\n}\n\n.alert-box.high {\n    background-color: rgba(239, 68, 68, 0.1);\n    border: 1px solid rgba(239, 68, 68, 0.3);\n}\n\n.alert-box.medium {\n    background-color: rgba(245, 158, 11, 0.1);\n    border: 1px solid rgba(245, 158, 11, 0.3);\n}\n\n.alert-box.low {\n    background-color: rgba(59, 130, 246, 0.1);\n    border: 1px solid rgba(59, 130, 246, 0.3);\n}\n\n.device-card {\n    padding: 0.75rem;\n    border-radius: 0.5rem;\n    background-color: rgba(30, 41, 59, 0.5);\n    border: 1px solid rgba(51, 65, 85, 0.5);\n    transition: all 0.2s;\n}\n\n.device-card:hover {\n    border-color: rgba(59, 130, 246, 0.5);\n    background-color: rgba(30, 41, 59, 0.7);\n}\n\n.glow-blue {\n    box-shadow: 0 0 20px rgba(59, 130, 246, 0.3);\n}\n\n.glow-green {\n    box-shadow: 0 0 20px rgba(16, 185, 129, 0.3);\n}\n\n.glow-red {\n    box-shadow: 0 0 20px rgba(239, 68, 68, 0.3);\n}\n\n.fade-in {\n    animation: fadeIn 0.3s ease-in;\n}\n\n@keyframes fadeIn {\n    from { opacity: 0; transform: translateY(-10px); }\n    to { opacity: 1; transform: translateY(0); }\n}\n\n@media (max-width: 1024px) {\n    .cyber-card {\n        backdrop-filter: blur(5px);\n    }\n    \n    .network-graph {\n        background: linear-gradient(135deg, rgba(15, 23, 42, 0.9) 0%, rgba(15, 23, 42, 0.7) 100%);\n    }\n}\n\n@media (max-width: 768px) {\n    .active_scanning {\n        font-size: 16px;\n        width: 16px;\n        height: 16px;\n    }\n    \n    .active_scanning_smooth {\n        font-size: 24px;\n    }\n    \n    .alert-box {\n        padding: 0.5rem;\n        gap: 0.5rem;\n        flex-direction: column;\n        align-items: stretch;\n    }\n    \n    .device-card {\n        padding: 0.5rem;\n    }\n    \n    .glow-blue,\n    .glow-green,\n    .glow-red {\n        box-shadow: 0 0 10px rgba(59, 130, 246, 0.2);\n    }\n    \n    .status-online,\n    .status-offline,\n    .status-unknown {\n        border-left-width: 2px;\n    }\n}\n\n@media (max-width: 480px) {\n    .active_scanning {\n        font-size: 14px;\n        width: 14px;\n        height: 14px;\n    }\n    \n    .active_scanning_smooth {\n        font-size: 20px;\n    }\n    \n    .alert-box {\n        padding: 0.375rem;\n        gap: 0.375rem;\n        border-radius: 0.375rem;\n    }\n    \n    .device-card {\n        padding: 0.375rem;\n        border-radius: 0.375rem;\n    }\n    \n    .cyber-card {\n        border-radius: 0.375rem;\n    }\n    \n    @keyframes pulse {\n        0% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.4); }\n        70% { box-shadow: 0 0 0 5px rgba(239, 68, 68, 0); }\n        100% { box-shadow: 0 0 0 0 rgba(239, 68, 68, 0); }\n    }\n    \n    @keyframes dotPulse {\n        0% {\n            background-color: #ff0000;\n            transform: scale(1);\n            box-shadow: 0 0 0 0 rgba(255, 0, 0, 0.7);\n        }\n        33% {\n            background-color: #00f00a;\n            transform: scale(1.2);\n            box-shadow: 0 0 0 5px rgba(0, 240, 10, 0);\n        }\n        66% {\n            background-color: #0064ff;\n            transform: scale(1.1);\n            box-shadow: 0 0 0 0 rgba(0, 100, 255, 0.7);\n        }\n        100% {\n            background-color: #ff0000;\n            transform: scale(1);\n            box-shadow: 0 0 0 0 rgba(255, 0, 0, 0);\n        }\n    }\n}","size_bytes":6472},"rules/condition_metadata.py":{"content":"# COMPLETE FILE WITH 20+ CONDITIONS FOR FALSE POSITIVE REDUCTION\n\nCONDITION_METADATA = {\n    # DEVICE LIFECYCLE CONDITIONS\n    'device_first_seen': {\n        'label': 'New Device Detected',\n        'description': 'Alert when a new device joins the network (first 1 hour window)',\n        'threshold_type': 'number',\n        'threshold_unit': 'hours',\n        'threshold_min': 1,\n        'threshold_max': 168,\n        'threshold_default': 1,\n        'threshold_help': 'Alert on devices detected within this many hours',\n        'validation_text': 'Must be between 1 and 168 hours',\n        'example': 'Alert on any device seen within the last 1 hour',\n        'step': 1\n    },\n    \n    'device_disappeared': {\n        'label': 'Device Disappeared from Network',\n        'description': 'Alert when a trusted device goes offline unexpectedly',\n        'threshold_type': 'number',\n        'threshold_unit': 'hours',\n        'threshold_min': 1,\n        'threshold_max': 168,\n        'threshold_default': 4,\n        'threshold_help': 'Alert if trusted device offline for X hours',\n        'validation_text': 'Must be between 1 and 168 hours',\n        'example': 'Alert if laptop offline for more than 4 hours',\n        'step': 1\n    },\n\n    # RECONNECTION CONDITIONS\n    'reconnect_count': {\n        'label': 'Excessive Reconnections',\n        'description': 'Alert when device reconnects too many times (possible spoofing or instability)',\n        'threshold_type': 'number',\n        'threshold_unit': 'reconnections',\n        'threshold_min': 5,\n        'threshold_max': 100,\n        'threshold_default': 20,\n        'threshold_help': 'Number of reconnections before alert (untrusted: 20+, trusted: 50+)',\n        'validation_text': 'Must be between 5 and 100 reconnections',\n        'example': 'Alert if device reconnects more than 20 times',\n        'step': 1\n    },\n    \n    'reconnect_frequency': {\n        'label': 'Frequent Reconnections in Short Time',\n        'description': 'Alert when device reconnects multiple times within a short period',\n        'threshold_type': 'number',\n        'threshold_unit': 'reconnections per 10 minutes',\n        'threshold_min': 2,\n        'threshold_max': 20,\n        'threshold_default': 5,\n        'threshold_help': 'How many reconnections in 10-minute window triggers alert',\n        'validation_text': 'Must be between 2 and 20',\n        'example': 'Alert if device reconnects 5+ times in 10 minutes',\n        'step': 1\n    },\n\n    # MAC ADDRESS CONDITIONS\n    'mac_pattern': {\n        'label': 'Suspicious MAC Address Pattern',\n        'description': 'Alert on known MAC spoofing and suspicious patterns',\n        'threshold_type': 'select',\n        'threshold_options': [\n            {'value': 'common_spoof', 'label': 'Common spoofing (00:00:00, FF:FF:FF, etc.)'},\n            {'value': 'vm_patterns', 'label': 'Virtual machine patterns (02:xx:xx, 52:54:xx)'},\n            {'value': 'broadcast', 'label': 'Broadcast MAC (FF:FF:FF:FF:FF:FF)'},\n            {'value': 'all_suspicious', 'label': 'All suspicious patterns'}\n        ],\n        'threshold_default': 'common_spoof',\n        'threshold_help': 'Which MAC patterns should trigger alert',\n        'validation_text': 'Select one pattern type',\n        'example': 'Alert on MAC addresses like 00:00:00:00:00:00'\n    },\n    \n    'mac_changed': {\n        'label': 'MAC Address Changed',\n        'description': 'Alert when device changes MAC address (spoofing indicator)',\n        'threshold_type': 'boolean',\n        'threshold_default': True,\n        'threshold_help': 'Alert when same IP suddenly has different MAC',\n        'validation_text': 'No threshold needed',\n        'example': 'Alert if IP 192.168.1.100 switches MAC addresses'\n    },\n\n    # VENDOR CONDITIONS\n    'vendor_unknown': {\n        'label': 'Unknown Device Vendor',\n        'description': 'Alert on devices with unidentifiable manufacturers (only for untrusted)',\n        'threshold_type': 'boolean',\n        'threshold_default': True,\n        'threshold_help': 'Alert on devices with unknown vendors (skips trusted devices)',\n        'validation_text': 'No threshold needed',\n        'example': 'Alert on devices with unknown manufacturers'\n    },\n    \n    'suspicious_vendor': {\n        'label': 'Suspicious Device Manufacturer',\n        'description': 'Alert on known malicious or risky device vendors',\n        'threshold_type': 'select',\n        'threshold_options': [\n            {'value': 'generic', 'label': 'Generic/Unrecognized (high risk)'},\n            {'value': 'china_origin', 'label': 'Devices from China origin vendors'},\n            {'value': 'iot_generic', 'label': 'Generic IoT devices (esp. cameras)'},\n            {'value': 'all', 'label': 'All suspicious manufacturers'}\n        ],\n        'threshold_default': 'generic',\n        'threshold_help': 'Which vendor categories to alert on',\n        'validation_text': 'Select vendor risk category',\n        'example': 'Alert on generic unrecognized vendors'\n    },\n\n    # IP ADDRESS CONDITIONS\n    'ip_changed': {\n        'label': 'IP Address Changed',\n        'description': 'Alert when trusted device gets new IP (possible compromised/spoofed)',\n        'threshold_type': 'boolean',\n        'threshold_default': True,\n        'threshold_help': 'Alert when previously seen MAC gets different IP',\n        'validation_text': 'No threshold needed',\n        'example': 'Alert if trusted device switches to new IP address'\n    },\n    \n    'rapid_ip_changes': {\n        'label': 'Rapid IP Address Changes',\n        'description': 'Alert when device cycles through IPs rapidly (DHCP exhaustion/spoofing)',\n        'threshold_type': 'number',\n        'threshold_unit': 'IP changes per hour',\n        'threshold_min': 2,\n        'threshold_max': 50,\n        'threshold_default': 5,\n        'threshold_help': 'How many different IPs for same MAC triggers alert',\n        'validation_text': 'Must be between 2 and 50',\n        'example': 'Alert if MAC has 5+ different IPs in an hour'\n    },\n    \n    'private_ip_overlap': {\n        'label': 'Private IP Range Anomaly',\n        'description': 'Alert when device uses unusual private IP ranges',\n        'threshold_type': 'select',\n        'threshold_options': [\n            {'value': 'unexpected_range', 'label': 'IPs outside normal subnet'},\n            {'value': 'loopback', 'label': 'Loopback addresses (127.x.x.x)'},\n            {'value': 'link_local', 'label': 'Link-local addresses (169.254.x.x)'},\n            {'value': 'reserved', 'label': 'Reserved/invalid ranges'}\n        ],\n        'threshold_default': 'unexpected_range',\n        'threshold_help': 'Which IP anomalies to alert on',\n        'validation_text': 'Select IP range type',\n        'example': 'Alert if device uses IP outside normal subnet'\n    },\n\n    # ACTIVITY CONDITIONS\n    'inactive_duration': {\n        'label': 'Device Offline Too Long',\n        'description': 'Alert when device stays offline longer than expected',\n        'threshold_type': 'number',\n        'threshold_unit': 'hours',\n        'threshold_min': 1,\n        'threshold_max': 720,\n        'threshold_default': 24,\n        'threshold_help': 'Hours offline before alert (for tracking dormant devices)',\n        'validation_text': 'Must be between 1 and 720 hours',\n        'example': 'Alert if device offline for more than 24 hours'\n    },\n    \n    'no_activity': {\n        'label': 'No Network Activity',\n        'description': 'Alert when online device sends no traffic (possible compromise)',\n        'threshold_type': 'number',\n        'threshold_unit': 'minutes',\n        'threshold_min': 5,\n        'threshold_max': 480,\n        'threshold_default': 60,\n        'threshold_help': 'Minutes without traffic before alert',\n        'validation_text': 'Must be between 5 and 480 minutes',\n        'example': 'Alert if device online but silent for 60+ minutes'\n    },\n\n    # NETWORK LOCATION CONDITIONS\n    'location_change': {\n        'label': 'Device Physical Location Changed',\n        'description': 'Alert when device connects from different network segment (VLAN/subnet)',\n        'threshold_type': 'boolean',\n        'threshold_default': True,\n        'threshold_help': 'Alert when MAC appears on different subnet/VLAN',\n        'validation_text': 'No threshold needed',\n        'example': 'Alert if laptop moves from office VLAN to guest VLAN'\n    },\n    \n    'simultaneous_ips': {\n        'label': 'Same MAC Multiple IPs Simultaneously',\n        'description': 'Alert when single MAC has multiple IPs at same time (spoofing/DHCP issue)',\n        'threshold_type': 'number',\n        'threshold_unit': 'simultaneous IPs',\n        'threshold_min': 2,\n        'threshold_max': 10,\n        'threshold_default': 2,\n        'threshold_help': 'How many IPs from same MAC trigger alert',\n        'validation_text': 'Must be between 2 and 10',\n        'example': 'Alert if one MAC has 2+ active IPs at same time'\n    },\n\n    # BEHAVIOR CONDITIONS\n    'abnormal_scan': {\n        'label': 'Network Scanning Detected',\n        'description': 'Alert when device performs port scanning or network reconnaissance',\n        'threshold_type': 'number',\n        'threshold_unit': 'ports scanned',\n        'threshold_min': 10,\n        'threshold_max': 1000,\n        'threshold_default': 50,\n        'threshold_help': 'How many unique ports accessed in 5 min window',\n        'validation_text': 'Must be between 10 and 1000 ports',\n        'example': 'Alert if device probes 50+ ports in 5 minutes'\n    },\n    \n    'broadcast_storm': {\n        'label': 'Broadcast Storm Detected',\n        'description': 'Alert when device floods network with broadcast packets',\n        'threshold_type': 'number',\n        'threshold_unit': 'packets per second',\n        'threshold_min': 100,\n        'threshold_max': 10000,\n        'threshold_default': 1000,\n        'threshold_help': 'Broadcast packets per second threshold',\n        'validation_text': 'Must be between 100 and 10000 pps',\n        'example': 'Alert if device sends 1000+ broadcast packets/sec'\n    },\n    \n    'arp_spoofing': {\n        'label': 'ARP Spoofing Detected',\n        'description': 'Alert on multiple devices claiming same IP or MAC-IP mismatches',\n        'threshold_type': 'number',\n        'threshold_unit': 'ARP conflicts',\n        'threshold_min': 1,\n        'threshold_max': 20,\n        'threshold_default': 3,\n        'threshold_help': 'How many ARP conflicts trigger alert',\n        'validation_text': 'Must be between 1 and 20',\n        'example': 'Alert after 3+ ARP conflicts for same IP'\n    },\n\n    # DEVICE TYPE CONDITIONS\n    'unexpected_device_type': {\n        'label': 'Unexpected Device Type',\n        'description': 'Alert on devices of unexpected types in specific network areas',\n        'threshold_type': 'select',\n        'threshold_options': [\n            {'value': 'phone_on_secure', 'label': 'Mobile device on secure network'},\n            {'value': 'iot_on_corp', 'label': 'IoT device on corporate network'},\n            {'value': 'camera_unusual', 'label': 'Cameras in unexpected locations'},\n            {'value': 'iot_any', 'label': 'Any IoT device detected'}\n        ],\n        'threshold_default': 'iot_any',\n        'threshold_help': 'Which unexpected device types to alert on',\n        'validation_text': 'Select device type anomaly',\n        'example': 'Alert when IoT camera detected on network'\n    },\n\n    # MULTI-CONDITION SCENARIOS\n    'new_untrusted_behavior': {\n        'label': 'New Device + Suspicious Behavior',\n        'description': 'Alert when new device shows suspicious activity immediately',\n        'threshold_type': 'select',\n        'threshold_options': [\n            {'value': 'immediate_scan', 'label': 'New device scans network immediately'},\n            {'value': 'immediate_spoof', 'label': 'New device with spoofed MAC/IP'},\n            {'value': 'immediate_high_traffic', 'label': 'New device with high traffic'},\n            {'value': 'any_suspicious', 'label': 'Any suspicious activity'}\n        ],\n        'threshold_default': 'any_suspicious',\n        'threshold_help': 'What suspicious behavior triggers alert',\n        'validation_text': 'Select suspicious behavior type',\n        'example': 'Alert if new device starts port scanning'\n    },\n    \n    'repeated_failures': {\n        'label': 'Repeated Connection Failures',\n        'description': 'Alert when device repeatedly fails to authenticate or connect',\n        'threshold_type': 'number',\n        'threshold_unit': 'failures in 10 minutes',\n        'threshold_min': 3,\n        'threshold_max': 50,\n        'threshold_default': 10,\n        'threshold_help': 'How many auth failures trigger alert',\n        'validation_text': 'Must be between 3 and 50',\n        'example': 'Alert after 10 failed auth attempts in 10 min'\n    }\n}\n\n\ndef get_condition_label(condition_key):\n    \"\"\"Get user-friendly label for a condition\"\"\"\n    return CONDITION_METADATA.get(condition_key, {}).get('label', condition_key)\n\n\ndef get_condition_metadata(condition_key):\n    \"\"\"Get full metadata for a condition\"\"\"\n    return CONDITION_METADATA.get(condition_key, {})\n\n\ndef validate_threshold(condition_key, threshold_value):\n    \"\"\"Validate threshold value for a condition\"\"\"\n    meta = CONDITION_METADATA.get(condition_key, {})\n    threshold_type = meta.get('threshold_type')\n    \n    if threshold_type == 'boolean':\n        return True, \"Valid\"\n    \n    elif threshold_type == 'select':\n        options = meta.get('threshold_options', [])\n        valid_values = [opt['value'] for opt in options]\n        if threshold_value in valid_values:\n            return True, \"Valid\"\n        return False, f\"Invalid selection. Must be one of: {', '.join(valid_values)}\"\n    \n    elif threshold_type == 'number':\n        try:\n            if not threshold_value and threshold_value != 0:\n                return False, \"Threshold value is required\"\n                \n            threshold_val = int(threshold_value)\n            threshold_min = meta.get('threshold_min', 0)\n            threshold_max = meta.get('threshold_max', 1000000)\n            \n            if threshold_val < threshold_min:\n                return False, f\"Threshold too low (minimum: {threshold_min})\"\n            if threshold_val > threshold_max:\n                return False, f\"Threshold too high (maximum: {threshold_max})\"\n            \n            return True, \"Valid\"\n        except (ValueError, TypeError):\n            return False, \"Threshold must be a number\"\n    \n    return False, \"Unknown threshold type\"\n\n\ndef validate_threshold_for_condition(condition_key, threshold_value):\n    \"\"\"Alias for validate_threshold - used by API endpoint\"\"\"\n    return validate_threshold(condition_key, threshold_value)","size_bytes":14741},"monitoring/advanced_scanner.py":{"content":"\"\"\"\nAdvanced Network Scanner for NetWatch SIEM\nImplements enterprise-grade network discovery and monitoring\n\"\"\"\n\nimport asyncio\nimport concurrent.futures\nimport ipaddress\nimport json\nimport logging\nimport socket\nimport subprocess\nimport threading\nimport time\nfrom collections import defaultdict, deque\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Set, Tuple\nimport psutil\nimport nmap\nfrom scapy.all import *\nfrom scapy.layers.inet import IP, ICMP, TCP, UDP\nfrom scapy.layers.l2 import ARP, Ether\ntry:\n    import requests\nexcept ImportError:\n    requests = None\n\ntry:\n    import dns.resolver\nexcept ImportError:\n    dns = None\n\nlogger = logging.getLogger(__name__)\n\nclass AdvancedNetworkScanner:\n    \"\"\"Enterprise-grade network scanner with multiple detection methods\"\"\"\n    \n    def __init__(self, db, config=None):\n        self.db = db\n        self.config = config or {}\n        self.active_devices = {}\n        self.device_history = defaultdict(list)\n        self.network_topology = {}\n        self.traffic_monitor = TrafficMonitor()\n        self.threat_detector = ThreatDetector()\n        \n        # Performance settings\n        self.max_threads = 50\n        self.scan_timeout = 3\n        self.ping_timeout = 1\n        self.arp_timeout = 2\n        \n        # Detection methods\n        self.detection_methods = [\n            'arp_scan',\n            'ping_sweep', \n            'port_scan',\n            'dhcp_monitor',\n            'dns_monitor',\n            'traffic_analysis',\n            'passive_discovery'\n        ]\n        \n        # Device fingerprinting\n        self.device_fingerprints = {}\n        self.vendor_database = self._load_vendor_database()\n        \n        # Real-time monitoring\n        self.monitoring_active = False\n        self.monitor_thread = None\n        \n    def _load_vendor_database(self):\n        \"\"\"Load MAC vendor database for device identification\"\"\"\n        try:\n            # Load from local file or online source\n            with open('data/oui_database.json', 'r') as f:\n                return json.load(f)\n        except:\n            # Fallback to basic vendor detection\n            return {}\n    \n    async def comprehensive_network_scan(self) -> List[Dict]:\n        \"\"\"Perform comprehensive network discovery using multiple methods\"\"\"\n        logger.info(\"Starting comprehensive network scan...\")\n        \n        # Get network information\n        network_info = self._get_network_info()\n        if not network_info:\n            logger.error(\"Could not determine network configuration\")\n            return []\n        \n        # Run all detection methods concurrently\n        tasks = []\n        for method in self.detection_methods:\n            if hasattr(self, f'_{method}'):\n                task = asyncio.create_task(getattr(self, f'_{method}')(network_info))\n                tasks.append(task)\n        \n        # Wait for all scans to complete\n        results = await asyncio.gather(*tasks, return_exceptions=True)\n        \n        # Merge and deduplicate results\n        all_devices = {}\n        for result in results:\n            if isinstance(result, list):\n                for device in result:\n                    if device.get('mac_address'):\n                        key = device['mac_address']\n                        if key not in all_devices:\n                            all_devices[key] = device\n                        else:\n                            # Merge device information\n                            all_devices[key].update(device)\n        \n        # Enhanced device analysis\n        enhanced_devices = []\n        for device in all_devices.values():\n            enhanced_device = await self._enhance_device_info(device)\n            # Transform field names to match app.py expectations\n            if 'ip_address' in enhanced_device:\n                enhanced_device['ip'] = enhanced_device['ip_address']\n            if 'mac_address' in enhanced_device:\n                enhanced_device['mac'] = enhanced_device['mac_address']\n            enhanced_devices.append(enhanced_device)\n        \n        logger.info(f\"Comprehensive scan completed. Found {len(enhanced_devices)} devices\")\n        return enhanced_devices\n    \n    def _get_network_info(self) -> Optional[Dict]:\n        \"\"\"Get comprehensive network information\"\"\"\n        try:\n            # Check for Windows and warn about limitations\n            import platform\n            if platform.system() == \"Windows\":\n                logger.warning(\"Windows detected: ARP scanning requires administrator privileges\")\n                logger.warning(\"Consider running as administrator or install Npcap for full functionality\")\n            \n            # Get active network interfaces\n            interfaces = psutil.net_if_addrs()\n            active_interfaces = []\n            \n            for interface, addresses in interfaces.items():\n                if interface.startswith(('lo', 'docker', 'veth')):\n                    continue\n                \n                for addr in addresses:\n                    if addr.family == socket.AF_INET and not addr.address.startswith('127.'):\n                        active_interfaces.append({\n                            'interface': interface,\n                            'ip': addr.address,\n                            'netmask': addr.netmask,\n                            'broadcast': addr.broadcast\n                        })\n                        break\n            \n            if not active_interfaces:\n                return None\n            \n            # Use the first active interface\n            primary_interface = active_interfaces[0]\n            \n            # Calculate network range\n            network = ipaddress.IPv4Network(\n                f\"{primary_interface['ip']}/{primary_interface['netmask']}\", \n                strict=False\n            )\n            \n            return {\n                'interface': primary_interface['interface'],\n                'ip': primary_interface['ip'],\n                'network': str(network.network_address),\n                'netmask': primary_interface['netmask'],\n                'broadcast': primary_interface['broadcast'],\n                'network_range': str(network),\n                'host_count': network.num_addresses\n            }\n            \n        except Exception as e:\n            logger.error(f\"Error getting network info: {e}\")\n            return None\n    \n    async def _arp_scan(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Enhanced ARP scanning with better error handling\"\"\"\n        devices = []\n        \n        try:\n            # Create ARP request for entire subnet\n            network = ipaddress.IPv4Network(network_info['network_range'])\n            \n            # Split into chunks for better performance\n            ip_chunks = list(self._chunk_list(list(network.hosts()), 50))\n            \n            for chunk in ip_chunks:\n                chunk_devices = await self._arp_scan_chunk(chunk)\n                devices.extend(chunk_devices)\n                await asyncio.sleep(0.1)  # Small delay between chunks\n            \n        except Exception as e:\n            logger.error(f\"ARP scan error: {e}\")\n        \n        return devices\n    \n    async def _arp_scan_chunk(self, ip_list: List) -> List[Dict]:\n        \"\"\"Scan a chunk of IP addresses with proper layer-2 ARP scanning\"\"\"\n        devices = []\n        \n        try:\n            # Check if we're on Windows and handle accordingly\n            import platform\n            if platform.system() == \"Windows\":\n                # On Windows, ARP scanning requires administrator privileges\n                # Fall back to ping-based discovery\n                logger.info(\"Windows detected - using ping-based discovery instead of ARP\")\n                return await self._ping_scan_chunk(ip_list)\n            \n            # Create ARP requests with Ethernet broadcast frame (layer 2)\n            # This is the CRITICAL fix - ARP is layer 2, needs Ethernet header\n            for ip in ip_list:\n                try:\n                    arp_req = ARP(pdst=str(ip))\n                    ether = Ether(dst=\"ff:ff:ff:ff:ff:ff\")\n                    packet = ether / arp_req\n                    \n                    # Use srp (send/receive at layer 2) instead of sr (layer 3)\n                    answered, unanswered = srp(packet, timeout=self.arp_timeout, verbose=0, retry=0)\n                    \n                    for sent, received in answered:\n                        device = {\n                            'ip_address': received.psrc,\n                            'mac_address': received.hwsrc,\n                            'vendor': self._get_vendor(received.hwsrc),\n                            'detection_method': 'arp_scan',\n                            'timestamp': datetime.now().isoformat()\n                        }\n                        devices.append(device)\n                except (PermissionError, OSError):\n                    # No raw socket privileges - fall back immediately\n                    return await self._ping_scan_chunk(ip_list)\n                except:\n                    continue\n                \n        except (PermissionError, OSError) as e:\n            # Silently fall back to ping-based discovery for permission errors\n            return await self._ping_scan_chunk(ip_list)\n        except Exception as e:\n            # Log other errors but still fall back\n            logger.debug(f\"ARP chunk scan error: {e}\")\n            # Fall back to ping-based discovery\n            return await self._ping_scan_chunk(ip_list)\n        \n        return devices\n    \n    async def _ping_scan_chunk(self, ip_list: List) -> List[Dict]:\n        \"\"\"Ping-based device discovery for Windows compatibility\"\"\"\n        devices = []\n        \n        try:\n            for ip in ip_list:\n                if self._ping_host(str(ip)):\n                    # Generate pseudo-MAC from IP for cloud environments\n                    mac = self._generate_mac_from_ip(str(ip))\n                    device = {\n                        'ip_address': str(ip),\n                        'mac_address': mac,\n                        'vendor': self._get_vendor(mac),\n                        'detection_method': 'ping_scan',\n                        'timestamp': datetime.now().isoformat()\n                    }\n                    devices.append(device)\n        except Exception as e:\n            logger.error(f\"Ping scan chunk error: {e}\")\n        \n        return devices\n    \n    def _generate_mac_from_ip(self, ip: str) -> str:\n        \"\"\"Generate a pseudo-MAC address from IP for cloud environments\"\"\"\n        try:\n            parts = ip.split('.')\n            # Use a recognizable prefix for generated MACs\n            mac = f\"02:00:00:{int(parts[1]):02x}:{int(parts[2]):02x}:{int(parts[3]):02x}\"\n            return mac.upper()\n        except:\n            return \"02:00:00:00:00:00\"\n    \n    async def _ping_sweep(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Enhanced ping sweep with parallel processing\"\"\"\n        devices = []\n        \n        try:\n            network = ipaddress.IPv4Network(network_info['network_range'])\n            \n            # Use concurrent futures for parallel pings\n            with concurrent.futures.ThreadPoolExecutor(max_workers=self.max_threads) as executor:\n                futures = []\n                \n                for ip in network.hosts():\n                    future = executor.submit(self._ping_host, str(ip))\n                    futures.append((str(ip), future))\n                \n                for ip, future in futures:\n                    try:\n                        # CRITICAL FIX: Don't use timeout here - ping command already has timeout\n                        # future.result(timeout=1) would timeout before ping completes\n                        if future.result():\n                            # Generate pseudo-MAC from IP for cloud environments\n                            mac = self._generate_mac_from_ip(ip)\n                            device = {\n                                'ip_address': ip,\n                                'mac_address': mac,\n                                'vendor': self._get_vendor(mac),\n                                'detection_method': 'ping_sweep',\n                                'timestamp': datetime.now().isoformat()\n                            }\n                            devices.append(device)\n                    except Exception as e:\n                        # Silently skip failed pings\n                        pass\n                        \n        except Exception as e:\n            logger.error(f\"Ping sweep error: {e}\")\n        \n        return devices\n    \n    def _ping_host(self, ip: str) -> bool:\n        \"\"\"Ping a single host with cross-platform support\"\"\"\n        try:\n            import platform\n            # Windows uses different ping syntax\n            if platform.system() == \"Windows\":\n                # Windows: ping -n 1 -w 1000 (timeout in milliseconds)\n                result = subprocess.run(\n                    ['ping', '-n', '1', '-w', '1000', ip],\n                    capture_output=True,\n                    timeout=self.ping_timeout + 1\n                )\n            else:\n                # Linux/Unix: ping -c 1 -W 1 (timeout in seconds)\n                result = subprocess.run(\n                    ['ping', '-c', '1', '-W', '1', ip],\n                    capture_output=True,\n                    timeout=self.ping_timeout + 1\n                )\n            return result.returncode == 0\n        except:\n            return False\n    \n    async def _port_scan(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Port scanning for service discovery\"\"\"\n        devices = []\n        \n        try:\n            # Common ports to scan\n            common_ports = [22, 23, 53, 80, 135, 139, 443, 445, 993, 995]\n            \n            network = ipaddress.IPv4Network(network_info['network_range'])\n            \n            # Use nmap for port scanning\n            nm = nmap.PortScanner()\n            \n            # Scan in chunks to avoid overwhelming the network\n            ip_chunks = list(self._chunk_list(list(network.hosts()), 20))\n            \n            for chunk in ip_chunks:\n                ip_range = ','.join(str(ip) for ip in chunk)\n                port_range = ','.join(str(port) for port in common_ports)\n                \n                try:\n                    nm.scan(ip_range, port_range, arguments='-sS -T4 --max-retries 1')\n                    \n                    for host in nm.all_hosts():\n                        if nm[host].state() == 'up':\n                            open_ports = []\n                            for port in nm[host]['tcp']:\n                                if nm[host]['tcp'][port]['state'] == 'open':\n                                    open_ports.append(port)\n                            \n                            if open_ports:\n                                device = {\n                                    'ip_address': host,\n                                    'open_ports': open_ports,\n                                    'services': self._identify_services(open_ports),\n                                    'detection_method': 'port_scan',\n                                    'timestamp': datetime.now().isoformat()\n                                }\n                                devices.append(device)\n                                \n                except (PermissionError, nmap.PortScannerError) as e:\n                    # Silently skip port scan chunks that require privileges\n                    logger.debug(f\"Port scan chunk error (privileged operation): {e}\")\n                except Exception as e:\n                    logger.debug(f\"Port scan chunk error: {e}\")\n                \n                await asyncio.sleep(0.5)  # Delay between chunks\n                \n        except Exception as e:\n            logger.debug(f\"Port scan error: {e}\")\n        \n        return devices\n    \n    async def _dhcp_monitor(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Monitor DHCP traffic for new devices\"\"\"\n        devices = []\n        \n        try:\n            # This would require packet capture capabilities\n            # For now, we'll implement a basic version\n            logger.info(\"DHCP monitoring not fully implemented yet\")\n            \n        except Exception as e:\n            logger.error(f\"DHCP monitor error: {e}\")\n        \n        return devices\n    \n    async def _dns_monitor(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Monitor DNS queries for device discovery\"\"\"\n        devices = []\n        \n        try:\n            # Monitor local DNS cache or queries\n            # This is a simplified version\n            logger.info(\"DNS monitoring not fully implemented yet\")\n            \n        except Exception as e:\n            logger.error(f\"DNS monitor error: {e}\")\n        \n        return devices\n    \n    async def _traffic_analysis(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Analyze network traffic for device discovery\"\"\"\n        devices = []\n        \n        try:\n            # This would require packet capture and analysis\n            # For now, we'll implement basic traffic monitoring\n            logger.info(\"Traffic analysis not fully implemented yet\")\n            \n        except Exception as e:\n            logger.error(f\"Traffic analysis error: {e}\")\n        \n        return devices\n    \n    async def _passive_discovery(self, network_info: Dict) -> List[Dict]:\n        \"\"\"Passive device discovery through network monitoring\"\"\"\n        devices = []\n        \n        try:\n            # Monitor ARP table changes\n            arp_table = self._get_arp_table()\n            \n            for entry in arp_table:\n                device = {\n                    'ip_address': entry['ip'],\n                    'mac_address': entry['mac'],\n                    'vendor': self._get_vendor(entry['mac']),\n                    'detection_method': 'passive_discovery',\n                    'timestamp': datetime.now().isoformat()\n                }\n                devices.append(device)\n                \n        except Exception as e:\n            logger.error(f\"Passive discovery error: {e}\")\n        \n        return devices\n    \n    async def _enhance_device_info(self, device: Dict) -> Dict:\n        \"\"\"Enhance device information with additional details\"\"\"\n        enhanced = device.copy()\n        \n        try:\n            # Get hostname\n            if device.get('ip_address'):\n                hostname = await self._resolve_hostname(device['ip_address'])\n                if hostname:\n                    enhanced['hostname'] = hostname\n            \n            # Get device type\n            enhanced['device_type'] = self._identify_device_type(device)\n            \n            # Get operating system info\n            if device.get('open_ports'):\n                enhanced['os_info'] = self._identify_os(device['open_ports'])\n            \n            # Calculate risk score\n            enhanced['risk_score'] = self._calculate_risk_score(device)\n            \n            # Get device status\n            enhanced['status'] = await self._check_device_status(device)\n            \n            # Add fingerprint\n            enhanced['fingerprint'] = self._generate_device_fingerprint(device)\n            \n        except Exception as e:\n            logger.error(f\"Error enhancing device info: {e}\")\n        \n        return enhanced\n    \n    async def _resolve_hostname(self, ip: str) -> Optional[str]:\n        \"\"\"Resolve hostname for IP address\"\"\"\n        try:\n            hostname = socket.gethostbyaddr(ip)[0]\n            return hostname\n        except:\n            return None\n    \n    def _identify_device_type(self, device: Dict) -> str:\n        \"\"\"Identify device type based on available information\"\"\"\n        mac = device.get('mac_address', '').upper()\n        vendor = device.get('vendor', '').lower()\n        ports = device.get('open_ports', [])\n        \n        # Router/Gateway detection\n        if any(port in ports for port in [80, 443, 8080]):\n            if 'cisco' in vendor or 'netgear' in vendor or 'linksys' in vendor:\n                return 'router'\n        \n        # Server detection\n        if any(port in ports for port in [22, 3389, 5985, 5986]):\n            return 'server'\n        \n        # Printer detection\n        if any(port in ports for port in [515, 631, 9100]):\n            return 'printer'\n        \n        # IoT device detection\n        if 'unknown' in vendor or not vendor:\n            return 'iot_device'\n        \n        # Default\n        return 'unknown'\n    \n    def _identify_services(self, ports: List[int]) -> List[str]:\n        \"\"\"Identify services running on open ports\"\"\"\n        service_map = {\n            22: 'SSH',\n            23: 'Telnet',\n            53: 'DNS',\n            80: 'HTTP',\n            135: 'RPC',\n            139: 'NetBIOS',\n            443: 'HTTPS',\n            445: 'SMB',\n            993: 'IMAPS',\n            995: 'POP3S'\n        }\n        \n        return [service_map.get(port, f'Port-{port}') for port in ports]\n    \n    def _identify_os(self, ports: List[int]) -> str:\n        \"\"\"Identify operating system based on open ports\"\"\"\n        # This is a simplified OS detection\n        if 135 in ports and 445 in ports:\n            return 'Windows'\n        elif 22 in ports and 80 in ports:\n            return 'Linux/Unix'\n        else:\n            return 'Unknown'\n    \n    def _calculate_risk_score(self, device: Dict) -> int:\n        \"\"\"Calculate risk score for device\"\"\"\n        score = 0\n        \n        # Unknown vendor increases risk\n        if not device.get('vendor') or device.get('vendor') == 'Unknown':\n            score += 3\n        \n        # Suspicious ports\n        suspicious_ports = [23, 135, 139, 445]\n        if any(port in device.get('open_ports', []) for port in suspicious_ports):\n            score += 2\n        \n        # No hostname\n        if not device.get('hostname'):\n            score += 1\n        \n        return min(score, 10)\n    \n    async def _check_device_status(self, device: Dict) -> str:\n        \"\"\"Check if device is currently online\"\"\"\n        try:\n            if device.get('ip_address'):\n                result = subprocess.run(\n                    ['ping', '-c', '1', '-W', '1', device['ip_address']],\n                    capture_output=True,\n                    timeout=2\n                )\n                return 'online' if result.returncode == 0 else 'offline'\n        except:\n            pass\n        \n        return 'unknown'\n    \n    def _generate_device_fingerprint(self, device: Dict) -> str:\n        \"\"\"Generate unique fingerprint for device\"\"\"\n        fingerprint_data = {\n            'mac': device.get('mac_address', ''),\n            'vendor': device.get('vendor', ''),\n            'ports': sorted(device.get('open_ports', [])),\n            'services': sorted(device.get('services', []))\n        }\n        \n        fingerprint = json.dumps(fingerprint_data, sort_keys=True)\n        return hashlib.md5(fingerprint.encode()).hexdigest()\n    \n    def _get_vendor(self, mac: str) -> str:\n        \"\"\"Get vendor from MAC address\"\"\"\n        if not mac:\n            return 'Unknown'\n        \n        # Extract OUI (first 3 bytes)\n        oui = mac.replace(':', '').replace('-', '')[:6].upper()\n        \n        # Check vendor database\n        if oui in self.vendor_database:\n            return self.vendor_database[oui]\n        \n        return 'Unknown'\n    \n    def _get_arp_table(self) -> List[Dict]:\n        \"\"\"Get system ARP table\"\"\"\n        arp_entries = []\n        \n        try:\n            # Read ARP table\n            with open('/proc/net/arp', 'r') as f:\n                lines = f.readlines()[1:]  # Skip header\n                \n                for line in lines:\n                    parts = line.split()\n                    if len(parts) >= 4:\n                        arp_entries.append({\n                            'ip': parts[0],\n                            'mac': parts[3],\n                            'type': parts[1]\n                        })\n        except:\n            pass\n        \n        return arp_entries\n    \n    def _chunk_list(self, lst: List, chunk_size: int) -> List[List]:\n        \"\"\"Split list into chunks\"\"\"\n        for i in range(0, len(lst), chunk_size):\n            yield lst[i:i + chunk_size]\n    \n    def start_real_time_monitoring(self):\n        \"\"\"Start real-time network monitoring\"\"\"\n        if self.monitoring_active:\n            return\n        \n        self.monitoring_active = True\n        self.monitor_thread = threading.Thread(target=self._monitoring_loop, daemon=True)\n        self.monitor_thread.start()\n        logger.info(\"Real-time monitoring started\")\n    \n    def stop_real_time_monitoring(self):\n        \"\"\"Stop real-time network monitoring\"\"\"\n        self.monitoring_active = False\n        if self.monitor_thread:\n            self.monitor_thread.join(timeout=5)\n        logger.info(\"Real-time monitoring stopped\")\n    \n    def _monitoring_loop(self):\n        \"\"\"Main monitoring loop\"\"\"\n        while self.monitoring_active:\n            try:\n                # Perform quick device status checks\n                self._update_device_status()\n                \n                # Monitor for new devices\n                self._detect_new_devices()\n                \n                # Update device information\n                self._update_device_info()\n                \n                time.sleep(30)  # Check every 30 seconds\n                \n            except Exception as e:\n                logger.error(f\"Monitoring loop error: {e}\")\n                time.sleep(60)  # Wait longer on error\n    \n    def _update_device_status(self):\n        \"\"\"Update status of known devices\"\"\"\n        # Implementation for updating device status\n        pass\n    \n    def _detect_new_devices(self):\n        \"\"\"Detect new devices on the network\"\"\"\n        # Implementation for detecting new devices\n        pass\n    \n    def _update_device_info(self):\n        \"\"\"Update information for existing devices\"\"\"\n        # Implementation for updating device information\n        pass\n\n\nclass TrafficMonitor:\n    \"\"\"Monitor network traffic for threat detection\"\"\"\n    \n    def __init__(self):\n        self.traffic_stats = defaultdict(int)\n        self.anomaly_detector = AnomalyDetector()\n    \n    def analyze_traffic(self, packet):\n        \"\"\"Analyze network packet for threats\"\"\"\n        # Implementation for traffic analysis\n        pass\n\n\nclass ThreatDetector:\n    \"\"\"Detect security threats and anomalies\"\"\"\n    \n    def __init__(self):\n        self.threat_patterns = self._load_threat_patterns()\n    \n    def _load_threat_patterns(self):\n        \"\"\"Load threat detection patterns\"\"\"\n        return {\n            'port_scan': {'threshold': 10, 'time_window': 60},\n            'brute_force': {'threshold': 5, 'time_window': 300},\n            'suspicious_traffic': {'threshold': 100, 'time_window': 60}\n        }\n    \n    def detect_threats(self, device_data):\n        \"\"\"Detect threats based on device behavior\"\"\"\n        threats = []\n        \n        # Implementation for threat detection\n        return threats\n\n\nclass AnomalyDetector:\n    \"\"\"Detect anomalous network behavior\"\"\"\n    \n    def __init__(self):\n        self.baseline = {}\n        self.deviation_threshold = 2.0\n    \n    def update_baseline(self, metric, value):\n        \"\"\"Update baseline for anomaly detection\"\"\"\n        if metric not in self.baseline:\n            self.baseline[metric] = deque(maxlen=100)\n        \n        self.baseline[metric].append(value)\n    \n    def detect_anomaly(self, metric, value):\n        \"\"\"Detect if value is anomalous\"\"\"\n        if metric not in self.baseline or len(self.baseline[metric]) < 10:\n            return False\n        \n        baseline_values = list(self.baseline[metric])\n        mean = sum(baseline_values) / len(baseline_values)\n        std_dev = (sum((x - mean) ** 2 for x in baseline_values) / len(baseline_values)) ** 0.5\n        \n        if std_dev == 0:\n            return False\n        \n        z_score = abs(value - mean) / std_dev\n        return z_score > self.deviation_threshold\n\n","size_bytes":28172},"app.py":{"content":"from flask import Flask, render_template, jsonify, request, session, redirect, url_for, flash\nfrom flask_socketio import SocketIO, emit, disconnect\nfrom functools import wraps\nfrom database.models import Database, get_kenya_time\n# Legacy scanner import removed - using NetworkScanner now\n\nfrom rules.alert_engine import AlertEngine\nfrom rules.smart_alert_engine import SmartAlertEngine\nfrom flask.signals import appcontext_pushed\nfrom i18n import I18nManager\nfrom security import SecurityManager, require_auth, require_admin, validate_input, sanitize_input, require_permission\nfrom security.schemas import *\nfrom models import UserManager\nfrom monitoring import AdvancedNetworkScanner, TrafficAnalyzer\nimport threading\nimport time\nimport asyncio\nfrom datetime import datetime, timedelta\nimport os\nfrom scanner.device_scanner import Colors\nimport logging\n\nlog = logging.getLogger('werkzeug')\nlog.setLevel(logging.ERROR)\nlogging.getLogger('socketio').setLevel(logging.ERROR)\nlogging.getLogger('engineio').setLevel(logging.ERROR)\n\napp = Flask(__name__)\napp.config['SECRET_KEY'] = os.environ.get('SESSION_SECRET', 'netwatch-siem-secret-key-2024')\napp.logger.setLevel(logging.ERROR)\n\n# Initialize security manager\nsecurity_manager = SecurityManager(app)\n\nsocketio = SocketIO(\n    app, \n    cors_allowed_origins=\"*\", \n    logger=False, \n    engineio_logger=False,\n    async_mode='threading',\n    ping_timeout=20,          # Faster timeout\n    ping_interval=10,         # More frequent pings\n    max_http_buffer_size=1000000,  # Smaller buffer = faster\n    allow_upgrades=True,\n    transports=['websocket'],  # WebSocket only - faster than polling\n    engineio_logger_level='ERROR',\n    always_connect=True\n)\n\ndef safe_emit(event, data, **kwargs):\n    try:\n        socketio.emit(event, data, **kwargs)\n    except Exception as e:\n        pass\n\nactive_clients = set()\n\ni18n = I18nManager()\ni18n.init_app(app)\n\n# Make gettext available in all templates\n@app.context_processor\ndef inject_i18n():\n    \"\"\"Inject translation functions into all templates\"\"\"\n    def gettext(key):\n        \"\"\"Get translated text or return key if not found\"\"\"\n        try:\n            return i18n.get_text(key)\n        except:\n            # Fallback to readable text if translation fails\n            return key.replace('_', ' ').title()\n    \n    return dict(gettext=gettext)\n\n\ndef login_required(f):\n    @wraps(f)\n    def decorated_function(*args, **kwargs):\n        if 'logged_in' not in session:\n            return redirect(url_for('login'))\n        \n        # Check if user is still active - REAL-TIME CHECK\n        user_id = session.get('user_id')\n        if user_id:\n            try:\n                conn = db.get_connection()\n                cursor = conn.cursor()\n                cursor.execute('SELECT is_active FROM users WHERE id = ?', (user_id,))\n                result = cursor.fetchone()\n                conn.close()\n                \n                if result and not result[0]:  # User is deactivated\n                    session.clear()\n                    flash('Your account has been deactivated', 'error')\n                    return redirect(url_for('login'))\n            except:\n                pass  # Don't fail on check\n        \n        return f(*args, **kwargs)\n    return decorated_function\n\n\ndb = Database()\n\n# Initialize user manager\nuser_manager = UserManager(db)\n\n# Initialize enhanced monitoring systems\nadvanced_scanner = AdvancedNetworkScanner(db)\ntraffic_analyzer = TrafficAnalyzer(db)\n\ndb.set_config('scanning_active', True)\nprint(f\"[{datetime.now().strftime('%H:%M:%S')}] Auto-enabling network scanner...\")\n\n# Legacy scanner removed - using NetworkScanner on-demand\nsmart_alert_engine = SmartAlertEngine(db)\nalert_engine = AlertEngine(db)\n\nscan_interval = db.get_config('scan_interval') or 60\nscanning_active = db.get_config('scanning_active') or False\nSCAN_INTERVAL = scan_interval\n\nscanner_thread = None\n_scanner_started = False\n\n\ndef _scanner_loop(app):\n    with app.app_context():\n        global SCAN_INTERVAL\n        previous_devices = set()\n        \n        while True:\n            current_scanning_active = db.get_config('scanning_active')\n            if current_scanning_active is None:\n                current_scanning_active = True\n                \n            if not current_scanning_active:\n                break\n            \n            try:\n                current_interval = db.get_config('scan_interval') or 60\n                SCAN_INTERVAL = current_interval\n                \n                # Use FAST NetworkScanner\n                from scanner.network_scanner import NetworkScanner\n                scanner = NetworkScanner(db)\n                devices = scanner.scan_network()\n\n                current_devices = set()\n                device_status_changes = []\n                \n                for device_dict in devices:\n                    conn = db.get_connection()\n                    cursor = conn.cursor()\n                    # Get existing device info including device_name\n                    cursor.execute('SELECT id, status, device_name, hostname, vendor FROM devices WHERE mac_address = ?', (device_dict['mac'],))\n                    result = cursor.fetchone()\n\n                    if result:\n                        device_id, old_status, existing_name, existing_hostname, existing_vendor = result\n                        current_devices.add(device_id)\n                        \n                        # Normalize hostname - use \"Unknown\" if not available\n                        hostname = device_dict.get('hostname') or existing_hostname or None\n                        if hostname and (hostname.strip() == '' or hostname == 'Unknown'):\n                            hostname = None\n                        \n                        # Only set device_name to \"Unknown\" if it's not user-set and hostname is missing\n                        device_name = existing_name if existing_name else None\n                        \n                        # Update device information while preserving user-set name\n                        kenya_time = get_kenya_time()\n                        cursor.execute('''\n                            UPDATE devices \n                            SET ip_address = ?, hostname = ?, vendor = ?, status = 'online', last_seen = ?\n                            WHERE id = ?\n                        ''', (\n                            device_dict['ip'], \n                            hostname,\n                            device_dict.get('vendor') or existing_vendor or 'Unknown',\n                            kenya_time,\n                            device_id\n                        ))\n                        conn.commit()\n                        \n                        if old_status == 'offline':\n                            device_status_changes.append({\n                                'device_id': device_id,\n                                'ip': device_dict['ip'],\n                                'mac': device_dict['mac'],\n                                'status': 'online',\n                                'change': 'came_online'\n                            })\n                            print(f\"[{datetime.now().strftime('%H:%M:%S')}] [ONLINE] {device_dict['ip']} ({device_dict['mac']})\")\n                        \n                        smart_alert_engine.process_smart_alerts(device_id)\n                    else:\n                        # Normalize hostname for new device\n                        hostname = device_dict.get('hostname')\n                        if not hostname or hostname.strip() == '' or hostname == 'Unknown':\n                            hostname = None\n                        \n                        vendor = device_dict.get('vendor') or 'Unknown'\n                        \n                        # Add new device\n                        device_id = db.add_device(\n                            device_dict['ip'], \n                            device_dict['mac'], \n                            hostname,\n                            vendor\n                        )\n                        if device_id:\n                            current_devices.add(device_id)\n                            device_status_changes.append({\n                                'device_id': device_id,\n                                'ip': device_dict['ip'],\n                                'mac': device_dict['mac'],\n                                'status': 'online',\n                                'change': 'new_device'\n                            })\n                            print(f\"[{datetime.now().strftime('%H:%M:%S')}] [NEW] {device_dict['ip']} ({device_dict['mac']}) - {vendor}\")\n\n                    conn.close()\n\n                offline_devices = previous_devices - current_devices\n                for device_id in offline_devices:\n                    conn = db.get_connection()\n                    cursor = conn.cursor()\n                    cursor.execute('SELECT ip_address, mac_address FROM devices WHERE id = ?', (device_id,))\n                    result = cursor.fetchone()\n                    if result:\n                        ip, mac = result\n                        \n                        db.update_device_status(device_id, 'offline')\n                        \n                        device_status_changes.append({\n                            'device_id': device_id,\n                            'ip': ip,\n                            'mac': mac,\n                            'status': 'offline',\n                            'change': 'went_offline'\n                        })\n                        print(f\"[{datetime.now().strftime('%H:%M:%S')}] [OFFLINE] {ip} ({mac})\")\n                    conn.close()\n\n                if device_status_changes:\n                    safe_emit('device_status_update', {\n                        'changes': device_status_changes,\n                        'timestamp': datetime.now().isoformat(),\n                        'total_devices': len(current_devices)\n                    })\n                \n                # Always emit device list update after scanning for real-time sync\n                all_devices = db.get_all_devices()\n                safe_emit('device_list_update', {\n                    'devices': all_devices,\n                    'timestamp': datetime.now().isoformat()\n                })\n                \n                stats = db.get_dashboard_stats()\n                safe_emit('dashboard_stats_update', {\n                    'stats': stats,\n                    'timestamp': datetime.now().isoformat()\n                })\n\n                previous_devices = current_devices\n\n                smart_alert_engine.run_smart_periodic_checks()\n\n            except Exception as e:\n                print(f\"[{datetime.now().strftime('%H:%M:%S')}] [ERROR] Scanner error: {e}\")\n\n            time.sleep(SCAN_INTERVAL)\n\ndef start_background_scanner():\n    global scanner_thread, _scanner_started\n    \n    if _scanner_started:\n        return\n    \n    _scanner_started = True\n    \n    scanning_enabled = db.get_config('scanning_active')\n    if scanning_enabled is None:\n        scanning_enabled = True\n        db.set_config('scanning_active', True)\n    \n    if scanning_enabled:\n        scanner_thread = threading.Thread(target=_scanner_loop, args=(app,), daemon=True)\n        scanner_thread.start()\n        print(f\"[{datetime.now().strftime('%H:%M:%S')}] [OK] Background scanning: ACTIVE\\n\")\n    else:\n        print(f\"[{datetime.now().strftime('%H:%M:%S')}] ⚠ Background scanning: DISABLED\\n\")\n\n\ndef _on_appcontext_pushed(sender, **extra):\n    start_background_scanner()\n\nappcontext_pushed.connect(_on_appcontext_pushed, app)\n\n\n@app.route('/login', methods=['GET', 'POST'])\ndef login():\n    client_ip = request.remote_addr\n    \n    # Check if IP is locked out\n    if security_manager.is_locked_out(client_ip):\n        return render_template('login.html', error='Too many failed attempts. Please try again later.')\n    \n    if request.method == 'POST':\n        username = request.form.get('username', '').strip()\n        password = request.form.get('password', '')\n        \n        # Sanitize input\n        username = sanitize_input(username)\n        \n        # Validate input\n        if not username or not password:\n            security_manager.record_failed_attempt(client_ip)\n            return render_template('login.html', error='Username and password are required')\n        \n        if len(username) > 50 or len(password) > 100:\n            security_manager.record_failed_attempt(client_ip)\n            return render_template('login.html', error='Invalid input length')\n        \n        # Authenticate user using user manager\n        auth_result = user_manager.authenticate_user(username, password, client_ip)\n        \n        if auth_result['success']:\n            user = auth_result['user']\n            \n            # Clear failed attempts on successful login\n            security_manager.clear_failed_attempts(client_ip)\n            \n            # Create secure session\n            session_token = user_manager.create_session(user['id'], client_ip, request.headers.get('User-Agent'))\n            \n            session['logged_in'] = True\n            session['user_id'] = user['id']\n            session['username'] = user['username']\n            session['role'] = user['role']\n            session['is_admin'] = user['role'] == 'admin'\n            session['last_activity'] = datetime.now().isoformat()\n            session['csrf_token'] = security_manager.generate_csrf_token()\n            session['session_token'] = session_token\n            \n            return redirect(url_for('index'))\n        else:\n            security_manager.record_failed_attempt(client_ip)\n            return render_template('login.html', error=auth_result['error'])\n    \n    if 'logged_in' in session:\n        return redirect(url_for('index'))\n    \n    return render_template('login.html')\n\n\n@app.route('/logout')\ndef logout():\n    # Log logout event\n    if 'username' in session:\n        db.add_event(\n            event_type='user_logout',\n            severity='info',\n            description=f'User {session[\"username\"]} logged out'\n        )\n    \n    session.clear()\n    return redirect(url_for('login'))\n\n\n@app.route('/')\n@login_required\ndef index():\n    return render_template('dashboard.html')\n\n\n@app.route('/devices')\n@login_required\ndef devices_page():\n    return render_template('devices.html')\n\n\n@app.route('/alerts')\n@login_required\ndef alerts_page():\n    return render_template('alerts.html')\n\n\n@app.route('/logs')\n@login_required\ndef logs_page():\n    return render_template('logs.html')\n\n\n@app.route('/config')\n@login_required\ndef config_page():\n    return render_template('config.html')\n\n\n@app.route('/api/dashboard/stats')\n@login_required\ndef get_dashboard_stats():\n    try:\n        stats = db.get_dashboard_stats()\n        return jsonify({'success': True, 'data': stats})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/devices')\n@login_required\ndef get_devices():\n    try:\n        devices = db.get_all_devices()\n        return jsonify({'success': True, 'data': devices})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n@app.route('/api/devices/search')\n@login_required\ndef search_devices():\n    try:\n        query = request.args.get('q', '').strip()\n        \n        if not query:\n            devices = db.get_all_devices()\n        else:\n            devices = db.search_devices(query)\n        \n        return jsonify({'success': True, 'data': devices})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/devices/active')\n@login_required\ndef get_active_devices():\n    try:\n        devices = db.get_active_devices()\n        return jsonify({'success': True, 'data': devices})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/devices/<int:device_id>/trust', methods=['POST'])\n@require_permission('manage_devices')\ndef toggle_device_trust(device_id):\n    try:\n        data = request.json or {}\n        data = sanitize_input(data)\n        \n        # Validate input\n        errors = validate_input(data, DEVICE_TRUST_SCHEMA)\n        if errors:\n            return jsonify({'success': False, 'error': '; '.join(errors)}), 400\n        \n        is_trusted = data.get('is_trusted', 0)\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('UPDATE devices SET is_trusted = ? WHERE id = ?', (is_trusted, device_id))\n        conn.commit()\n        conn.close()\n        \n        db.add_event(\n            event_type='device_trust_changed',\n            severity='info',\n            description=f\"Device trust status changed to {'trusted' if is_trusted else 'untrusted'}\",\n            device_id=device_id\n        )\n        \n        # Emit real-time update\n        all_devices = db.get_all_devices()\n        safe_emit('device_list_update', {\n            'devices': all_devices,\n            'timestamp': datetime.now().isoformat()\n        })\n        \n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/devices/<int:device_id>/name', methods=['POST'])\n@login_required\ndef update_device_name(device_id):\n    try:\n        data = request.json\n        device_name = data.get('name', '').strip()\n        \n        # Normalize empty names\n        if not device_name or device_name == '':\n            device_name = None\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('UPDATE devices SET device_name = ? WHERE id = ?', (device_name, device_id))\n        conn.commit()\n        conn.close()\n        \n        # Emit real-time update\n        all_devices = db.get_all_devices()\n        safe_emit('device_list_update', {\n            'devices': all_devices,\n            'timestamp': datetime.now().isoformat()\n        })\n        \n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/alerts')\n@login_required\ndef get_alerts():\n    try:\n        limit = request.args.get('limit', 50, type=int)\n        alerts = db.get_recent_alerts(limit)\n        return jsonify({'success': True, 'data': alerts})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/alerts/<int:alert_id>/resolve', methods=['POST'])\n@require_permission('manage_alerts')\ndef resolve_alert(alert_id):\n    try:\n        db.resolve_alert(alert_id)\n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/events')\n@login_required\ndef get_events():\n    try:\n        limit = request.args.get('limit', 100, type=int)\n        events = db.get_recent_events(limit)\n        return jsonify({'success': True, 'data': events})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/scan/status')\n@login_required\ndef scan_status():\n    current_interval = db.get_config('scan_interval') or 60\n    current_scanning = db.get_config('scanning_active')\n    if current_scanning is None:\n        current_scanning = True\n    return jsonify({'success': True, 'scanning': current_scanning, 'interval': current_interval})\n\n\n@app.route('/api/scan/now', methods=['POST'])\n@require_permission('scan_network')\ndef scan_now():\n    try:\n        # Use FAST NetworkScanner\n        from scanner.network_scanner import NetworkScanner\n        scanner = NetworkScanner(db)\n        devices = scanner.scan_network()\n        \n        # Process devices and update database\n        device_ids = []\n        for device_dict in devices:\n            # Normalize hostname\n            hostname = device_dict.get('hostname')\n            if not hostname or hostname.strip() == '' or hostname == 'Unknown':\n                hostname = None\n            \n            vendor = device_dict.get('vendor') or 'Unknown'\n            \n            # Add or update device\n            device_id = db.add_device(\n                device_dict['ip'],\n                device_dict.get('mac', '00:00:00:00:00:00'),\n                hostname,\n                vendor\n            )\n            \n            if device_id:\n                device_ids.append(device_id)\n        \n        # Emit real-time updates IMMEDIATELY\n        all_devices = db.get_all_devices()\n        safe_emit('device_list_update', {\n            'devices': all_devices,\n            'timestamp': datetime.now().isoformat()\n        })\n        \n        stats = db.get_dashboard_stats()\n        safe_emit('dashboard_stats_update', {\n            'stats': stats,\n            'timestamp': datetime.now().isoformat()\n        })\n        \n        return jsonify({\n            'success': True,\n            'message': f'Scan complete. Found {len(devices)} devices.',\n            'devices_count': len(devices)\n        })\n    except Exception as e:\n        import traceback\n        print(f\"Scan error: {traceback.format_exc()}\")\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/activity/timeline')\n@login_required\ndef get_activity_timeline():\n    try:\n        conn = db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT \n                strftime('%Y-%m-%d %H:%M:00', timestamp) as minute,\n                COUNT(*) as count\n            FROM events\n            WHERE datetime(timestamp) >= datetime('now', '-120 minutes')\n            GROUP BY minute\n            ORDER BY minute ASC\n        ''')\n        \n        timeline_data = [{'time': row[0], 'count': row[1]} for row in cursor.fetchall()]\n        conn.close()\n        \n        return jsonify({'success': True, 'data': timeline_data})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/analytics/device-trends')\n@login_required\ndef get_device_trends():\n    try:\n        conn = db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT \n                DATE(first_seen) as date,\n                COUNT(*) as new_devices\n            FROM devices\n            WHERE datetime(first_seen) >= datetime('now', '-7 days')\n            GROUP BY DATE(first_seen)\n            ORDER BY date ASC\n        ''')\n        \n        device_trends = [{'date': row[0], 'count': row[1]} for row in cursor.fetchall()]\n        \n        cursor.execute('''\n            SELECT status, COUNT(*) as count\n            FROM devices\n            GROUP BY status\n        ''')\n        \n        status_distribution = [{'status': row[0], 'count': row[1]} for row in cursor.fetchall()]\n        \n        cursor.execute('''\n            SELECT vendor, COUNT(*) as count\n            FROM devices\n            WHERE vendor != 'Unknown'\n            GROUP BY vendor\n            ORDER BY count DESC\n            LIMIT 10\n        ''')\n        \n        vendor_distribution = [{'vendor': row[0], 'count': row[1]} for row in cursor.fetchall()]\n        \n        conn.close()\n        \n        return jsonify({\n            'success': True,\n            'data': {\n                'device_trends': device_trends,\n                'status_distribution': status_distribution,\n                'vendor_distribution': vendor_distribution\n            }\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/analytics/alert-trends')\n@login_required\ndef get_alert_trends():\n    try:\n        conn = db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute('''\n            SELECT \n                DATE(timestamp) as date,\n                COUNT(*) as total_alerts,\n                COUNT(CASE WHEN severity = 'high' THEN 1 END) as high_alerts,\n                COUNT(CASE WHEN severity = 'medium' THEN 1 END) as medium_alerts,\n                COUNT(CASE WHEN severity = 'low' THEN 1 END) as low_alerts\n            FROM alerts\n            WHERE datetime(timestamp) >= datetime('now', '-7 days')\n            GROUP BY DATE(timestamp)\n            ORDER BY date ASC\n        ''')\n        \n        alert_trends = []\n        for row in cursor.fetchall():\n            alert_trends.append({\n                'date': row[0],\n                'total': row[1],\n                'high': row[2],\n                'medium': row[3],\n                'low': row[4]\n            })\n        \n        cursor.execute('''\n            SELECT alert_type, COUNT(*) as count\n            FROM alerts\n            WHERE datetime(timestamp) >= datetime('now', '-7 days')\n            GROUP BY alert_type\n            ORDER BY count DESC\n        ''')\n        \n        alert_types = [{'type': row[0], 'count': row[1]} for row in cursor.fetchall()]\n        \n        cursor.execute('''\n            SELECT \n                strftime('%H', timestamp) as hour,\n                COUNT(*) as count\n            FROM alerts\n            WHERE datetime(timestamp) >= datetime('now', '-7 days')\n            GROUP BY strftime('%H', timestamp)\n            ORDER BY hour ASC\n        ''')\n        \n        hourly_alerts = [{'hour': int(row[0]), 'count': row[1]} for row in cursor.fetchall()]\n        \n        conn.close()\n        \n        return jsonify({\n            'success': True,\n            'data': {\n                'alert_trends': alert_trends,\n                'alert_types': alert_types,\n                'hourly_alerts': hourly_alerts\n            }\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/analytics/network-health')\n@login_required\ndef get_network_health():\n    try:\n        conn = db.get_connection()\n        cursor = conn.cursor()\n        \n        cursor.execute(\"SELECT COUNT(*) FROM devices\")\n        total_devices = cursor.fetchone()[0]\n        \n        cursor.execute(\"SELECT COUNT(*) FROM devices WHERE status = 'online'\")\n        online_devices = cursor.fetchone()[0]\n        \n        cursor.execute(\"SELECT COUNT(*) FROM devices WHERE is_trusted = 1\")\n        trusted_devices = cursor.fetchone()[0]\n        \n        cursor.execute(\"SELECT COUNT(*) FROM alerts WHERE status = 'active'\")\n        active_alerts = cursor.fetchone()[0]\n        \n        if total_devices > 0:\n            online_ratio = online_devices / total_devices\n            trusted_ratio = trusted_devices / total_devices\n            alert_ratio = min(active_alerts / total_devices, 1.0)\n            \n            health_score = (\n                online_ratio * 40 +\n                trusted_ratio * 30 +\n                (1 - alert_ratio) * 30\n            ) * 100\n        else:\n            health_score = 100\n        \n        cursor.execute('''\n            SELECT \n                CASE \n                    WHEN reconnect_count > 20 THEN 'high'\n                    WHEN reconnect_count > 10 THEN 'medium'\n                    WHEN reconnect_count > 5 THEN 'low'\n                    ELSE 'minimal'\n                END as risk_level,\n                COUNT(*) as count\n            FROM devices\n            GROUP BY risk_level\n        ''')\n        \n        risk_levels = [{'level': row[0], 'count': row[1]} for row in cursor.fetchall()]\n        \n        cursor.execute('''\n            SELECT COUNT(*) FROM events\n            WHERE datetime(timestamp) >= datetime('now', '-24 hours')\n        ''')\n        recent_activity = cursor.fetchone()[0]\n        \n        conn.close()\n        \n        return jsonify({\n            'success': True,\n            'data': {\n                'total_devices': total_devices,\n                'online_devices': online_devices,\n                'trusted_devices': trusted_devices,\n                'active_alerts': active_alerts,\n                'health_score': round(health_score, 1),\n                'risk_levels': risk_levels,\n                'recent_activity': recent_activity\n            }\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/config')\n@login_required\ndef get_config():\n    try:\n        db_config = db.get_config() or {}\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT name, enabled FROM rules')\n        rules_data = cursor.fetchall()\n        rules_dict = {row['name']: bool(row['enabled']) for row in rules_data}\n        conn.close()\n        \n        config_data = {\n            'scan_interval': db_config.get('scan_interval', 60),\n            'scanning_active': db_config.get('scanning_active', True),\n            'license_type': 'FULL',\n            'traffic_monitoring': db_config.get('traffic_monitoring', True),\n            'extended_logs': db_config.get('extended_logs', True),\n            'email_alerts': db_config.get('email_alerts', True),\n            'rules': {\n                'new_device_alert': rules_dict.get('new_device_detected', True),\n                'reconnect_alert': rules_dict.get('frequent_reconnect', True),\n                'suspicious_mac_alert': rules_dict.get('suspicious_mac', True),\n                'traffic_monitoring': db_config.get('traffic_monitoring', True),\n                'advanced_logging': db_config.get('extended_logs', True)\n            }\n        }\n        \n        return jsonify({'success': True, 'data': config_data})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/devices/delete', methods=['POST'])\n@require_permission('manage_devices')\ndef delete_devices():\n    try:\n        data = request.json\n        device_ids = data.get('device_ids', [])\n        \n        if not device_ids:\n            return jsonify({'success': False, 'error': 'No devices specified'}), 400\n        \n        deleted_count = db.delete_devices(device_ids)\n        \n        db.add_event(\n            event_type='devices_deleted',\n            severity='info',\n            description=f\"Deleted {deleted_count} device(s) from system\"\n        )\n        \n        # Emit real-time update\n        all_devices = db.get_all_devices()\n        safe_emit('device_list_update', {\n            'devices': all_devices,\n            'timestamp': datetime.now().isoformat()\n        })\n        \n        stats = db.get_dashboard_stats()\n        safe_emit('dashboard_stats_update', {\n            'stats': stats,\n            'timestamp': datetime.now().isoformat()\n        })\n        \n        return jsonify({'success': True, 'deleted_count': deleted_count})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/alerts/<int:alert_id>/mark-safe', methods=['POST'])\n@require_permission('manage_alerts')\ndef mark_alert_safe(alert_id):\n    try:\n        db.mark_alert_safe(alert_id)\n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/alerts/delete', methods=['POST'])\n@require_permission('manage_alerts')\ndef delete_alerts():\n    try:\n        data = request.json\n        alert_ids = data.get('alert_ids', [])\n        \n        if alert_ids:\n            deleted_count = db.delete_alerts(alert_ids)\n        else:\n            deleted_count = db.delete_alerts()\n        \n        return jsonify({'success': True, 'deleted_count': deleted_count})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/events/delete', methods=['POST'])\n@login_required\ndef delete_events():\n    try:\n        data = request.json\n        event_ids = data.get('event_ids', [])\n        \n        if event_ids:\n            deleted_count = db.delete_events(event_ids)\n        else:\n            deleted_count = db.delete_events()\n        \n        return jsonify({'success': True, 'deleted_count': deleted_count})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/timezone/info')\n@login_required\ndef get_timezone_info():\n    kenya_tz = datetime.timezone(timedelta(hours=3))\n    kenya_time = datetime.now(kenya_tz)\n    \n    return jsonify({\n        'success': True,\n        'timezone': 'Africa/Nairobi (EAT)',\n        'offset': '+03:00',\n        'current_time': kenya_time.strftime('%Y-%m-%d %H:%M:%S')\n    })\n\n\n@app.route('/api/language/set', methods=['POST'])\n@login_required\ndef set_language():\n    try:\n        data = request.json\n        language = data.get('language', 'en')\n        \n        if i18n.set_language(language):\n            return jsonify({\n                'success': True,\n                'message': 'Language updated successfully',\n                'current_language': language\n            })\n        else:\n            return jsonify({\n                'success': False,\n                'error': 'Invalid language code'\n            }), 400\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/language/current')\n@login_required\ndef get_current_language():\n    try:\n        current_lang = i18n.get_current_language()\n        available_langs = i18n.get_available_languages()\n        \n        return jsonify({\n            'success': True,\n            'current_language': current_lang,\n            'available_languages': available_langs\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/config/save', methods=['POST'])\n@require_permission('manage_config')\ndef save_config():\n    try:\n        global scan_interval, SCAN_INTERVAL, scanning_active\n        data = request.json\n        \n        if 'scan_interval' in data:\n            new_interval = int(data['scan_interval'])\n            if 30 <= new_interval <= 600:\n                scan_interval = new_interval\n                SCAN_INTERVAL = new_interval\n                db.set_config('scan_interval', new_interval)\n        \n        if 'scanning_active' in data:\n            scanning_active = bool(data['scanning_active'])\n            db.set_config('scanning_active', scanning_active)\n        \n        for key in ['traffic_monitoring', 'extended_logs', 'email_alerts']:\n            if key in data:\n                db.set_config(key, bool(data[key]))\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        \n        if 'rules' in data:\n            for rule_name, enabled in data['rules'].items():\n                rule_map = {\n                    'new_device_alert': 'new_device_detected',\n                    'reconnect_alert': 'frequent_reconnect',\n                    'suspicious_mac_alert': 'suspicious_mac'\n                }\n                \n                db_rule_name = rule_map.get(rule_name, rule_name)\n                cursor.execute('''\n                    UPDATE rules SET enabled = ? WHERE name = ?\n                ''', (1 if enabled else 0, db_rule_name))\n        \n        conn.commit()\n        conn.close()\n        \n        alert_engine.reload_rules()\n        \n        db.add_event(\n            event_type='config_updated',\n            severity='info',\n            description=f'System configuration updated. Scan interval: {scan_interval}s'\n        )\n        \n        return jsonify({\n            'success': True, \n            'message': 'Configuration saved successfully',\n            'scan_interval': scan_interval\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/scan/stop', methods=['POST'])\n@login_required\ndef stop_scanning():\n    try:\n        db.set_config('scanning_active', False)\n        db.add_event(\n            event_type='scan_stopped',\n            severity='info',\n            description='Network scanning manually stopped'\n        )\n        return jsonify({'success': True, 'message': 'Scanning will stop after current cycle'})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/scan/start', methods=['POST'])\n@login_required\ndef start_scanning():\n    try:\n        global scanner_thread, _scanner_started\n        \n        db.set_config('scanning_active', True)\n        \n        if scanner_thread is None or not scanner_thread.is_alive():\n            scanner_thread = threading.Thread(target=_scanner_loop, args=(app,), daemon=True)\n            scanner_thread.start()\n            _scanner_started = True\n            \n        db.add_event(\n            event_type='scan_started',\n            severity='info',\n            description='Network scanning manually started'\n        )\n        return jsonify({'success': True, 'message': 'Scanning started'})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/rules')\n@login_required\ndef rules_page():\n    return render_template('rules.html')\n\n\n@app.route('/analytics')\n@login_required\ndef analytics_page():\n    return render_template('analytics.html')\n\n\n@app.route('/users')\n@login_required\ndef users_page():\n    # Check if user is admin\n    if not session.get('is_admin', False):\n        flash('Admin access required', 'error')\n        return redirect(url_for('index'))\n    return render_template('users.html')\n\n\n@app.route('/register', methods=['GET', 'POST'])\ndef register():\n    if request.method == 'POST':\n        username = request.form.get('username', '').strip()\n        email = request.form.get('email', '').strip()\n        password = request.form.get('password', '')\n        confirm_password = request.form.get('confirm_password', '')\n        role = request.form.get('role', 'viewer')\n        \n        # Validate input\n        if not username or len(username) < 3:\n            return render_template('register.html', error='Username must be at least 3 characters')\n        \n        if not email or '@' not in email:\n            return render_template('register.html', error='Valid email address required')\n        \n        if not password or len(password) < 8:\n            return render_template('register.html', error='Password must be at least 8 characters')\n        \n        if password != confirm_password:\n            return render_template('register.html', error='Passwords do not match')\n        \n        # Register user\n        result = user_manager.register_user(username, email, password, role)\n        \n        if result['success']:\n            return render_template('login.html', success='Registration successful! Please log in.')\n        else:\n            return render_template('register.html', error=result['error'])\n    \n    return render_template('register.html')\n\n\n@app.route('/api/rules', methods=['GET'])\n@login_required\ndef get_rules():\n    try:\n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('SELECT * FROM rules ORDER BY id DESC')\n        rules = [dict(row) for row in cursor.fetchall()]\n        conn.close()\n        return jsonify({'success': True, 'data': rules})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/add', methods=['POST'])\n@require_permission('manage_rules')\ndef add_rule():\n    try:\n        data = request.json\n        name = data.get('name')\n        rule_type = data.get('rule_type', 'device_event')\n        condition = data.get('condition')\n        threshold = data.get('threshold', 1)\n        severity = data.get('severity', 'medium')\n        \n        if not name or not condition:\n            return jsonify({'success': False, 'error': 'Name and condition required'}), 400\n        \n        validation_errors = smart_alert_engine.add_rule_validation({\n            'name': name, 'condition': condition, 'threshold': threshold, 'severity': severity\n        })\n        if validation_errors:\n            return jsonify({'success': False, 'error': '; '.join(validation_errors)}), 400\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('''\n            INSERT INTO rules (name, rule_type, condition, threshold, severity, enabled)\n            VALUES (?, ?, ?, ?, ?, 1)\n        ''', (name, rule_type, condition, threshold, severity))\n        conn.commit()\n        rule_id = cursor.lastrowid\n        conn.close()\n        \n        db.add_event(\n            event_type='rule_created',\n            severity='info',\n            description=f'New rule created: {name}'\n        )\n        \n        alert_engine.reload_rules()\n        \n        return jsonify({'success': True, 'rule_id': rule_id})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/<int:rule_id>', methods=['DELETE'])\n@require_permission('manage_rules')\ndef delete_rule(rule_id):\n    try:\n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('DELETE FROM rules WHERE id = ?', (rule_id,))\n        conn.commit()\n        conn.close()\n        \n        db.add_event(\n            event_type='rule_deleted',\n            severity='info',\n            description=f'Rule {rule_id} deleted'\n        )\n        \n        alert_engine.reload_rules()\n        \n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/<int:rule_id>/toggle', methods=['POST'])\n@login_required\ndef toggle_rule(rule_id):\n    try:\n        data = request.json\n        enabled = data.get('enabled', 1)\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        cursor.execute('UPDATE rules SET enabled = ? WHERE id = ?', (enabled, rule_id))\n        conn.commit()\n        conn.close()\n        \n        alert_engine.reload_rules()\n        \n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/<int:rule_id>', methods=['PUT'])\n@require_permission('manage_rules')\ndef update_rule(rule_id):\n    \"\"\"Update an existing rule\"\"\"\n    try:\n        data = request.json\n        name = data.get('name')\n        condition = data.get('condition')\n        threshold = data.get('threshold')\n        severity = data.get('severity')\n        \n        if not name or not condition:\n            return jsonify({'success': False, 'error': 'Name and condition required'}), 400\n        \n        # Validate threshold\n        validation_errors = smart_alert_engine.add_rule_validation({\n            'name': name, 'condition': condition, 'threshold': threshold, 'severity': severity\n        })\n        if validation_errors:\n            return jsonify({'success': False, 'error': '; '.join(validation_errors)}), 400\n        \n        conn = db.get_connection()\n        cursor = conn.cursor()\n        \n        # Check if rule exists\n        cursor.execute('SELECT id FROM rules WHERE id = ?', (rule_id,))\n        if not cursor.fetchone():\n            conn.close()\n            return jsonify({'success': False, 'error': 'Rule not found'}), 404\n        \n        # Update rule\n        cursor.execute('''\n            UPDATE rules \n            SET name = ?, condition = ?, threshold = ?, severity = ?\n            WHERE id = ?\n        ''', (name, condition, threshold, severity, rule_id))\n        \n        conn.commit()\n        conn.close()\n        \n        db.add_event(\n            event_type='rule_updated',\n            severity='info',\n            description=f'Rule updated: {name}'\n        )\n        \n        alert_engine.reload_rules()\n        \n        return jsonify({'success': True, 'rule_id': rule_id})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/conditions', methods=['GET'])\n@login_required\ndef get_condition_metadata():\n    \"\"\"Return metadata about all available conditions for the frontend\"\"\"\n    try:\n        from rules.condition_metadata import CONDITION_METADATA\n        return jsonify({\n            'success': True,\n            'data': CONDITION_METADATA\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/validate', methods=['POST'])\n@login_required\ndef validate_rule_threshold():\n    \"\"\"Validate a threshold value for a given condition (frontend use)\"\"\"\n    try:\n        from rules.condition_metadata import validate_threshold_for_condition\n        \n        data = request.json\n        condition = data.get('condition')\n        threshold = data.get('threshold')\n        \n        is_valid, message = validate_threshold_for_condition(condition, threshold)\n        \n        return jsonify({\n            'success': True,\n            'valid': is_valid,\n            'message': message\n        })\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/rules/test', methods=['POST'])\n@login_required\ndef test_rule():\n    try:\n        data = request.json\n        rule_data = {\n            'name': data.get('name'),\n            'condition': data.get('condition'),\n            'threshold': data.get('threshold', 1),\n            'severity': data.get('severity', 'medium')\n        }\n        test_device_id = data.get('device_id')\n        \n        if not test_device_id:\n            return jsonify({'success': False, 'error': 'Device ID required'}), 400\n        \n        result = smart_alert_engine.test_rule(rule_data, test_device_id)\n        return jsonify({'success': True, 'result': result})\n        \n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n# User Management API Endpoints - ADMIN ONLY\n@app.route('/api/users', methods=['GET'])\n@require_admin\ndef get_users():\n    try:\n        users = user_manager.get_all_users()\n        return jsonify({'success': True, 'data': users})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/users', methods=['POST'])\n@require_admin\ndef create_user():\n    try:\n        data = request.json or {}\n        if not data:\n            return jsonify({'success': False, 'error': 'No data provided'}), 400\n        \n        data = sanitize_input(data)\n        \n        # Validate input\n        errors = validate_input(data, {\n            'username': {'type': 'str', 'required': True, 'min_length': 3, 'max_length': 50},\n            'email': {'type': 'str', 'required': True, 'max_length': 100},\n            'password': {'type': 'str', 'required': True, 'min_length': 8},\n            'role': {'type': 'str', 'required': True}\n        })\n        \n        if errors:\n            return jsonify({'success': False, 'error': '; '.join(errors)}), 400\n        \n        # Validate role - only admin and viewer\n        valid_roles = ['admin', 'viewer']\n        if data.get('role') not in valid_roles:\n            return jsonify({'success': False, 'error': 'Role must be either \"admin\" or \"viewer\"'}), 400\n        \n        result = user_manager.register_user(\n            data['username'],\n            data['email'],\n            data['password'],\n            data['role']\n        )\n        \n        if result['success']:\n            # Log event async (don't wait)\n            def log_event():\n                try:\n                    db.add_event(\n                        event_type='user_created',\n                        severity='info',\n                        description=f\"User {data['username']} created with role {data['role']}\"\n                    )\n                except:\n                    pass\n            \n            import threading\n            threading.Thread(target=log_event, daemon=True).start()\n            \n            # Broadcast user list update (async - don't block)\n            def broadcast_update():\n                try:\n                    all_users = user_manager.get_all_users()\n                    safe_emit('user_list_update', {\n                        'users': all_users,\n                        'timestamp': datetime.now().isoformat(),\n                        'action': 'user_created',\n                        'username': data['username']\n                    })\n                except:\n                    pass\n            \n            threading.Thread(target=broadcast_update, daemon=True).start()\n            \n            return jsonify(result)\n        else:\n            return jsonify(result), 400\n    except Exception as e:\n        import traceback\n        print(f\"User creation error: {e}\")\n        print(traceback.format_exc())\n        return jsonify({'success': False, 'error': f'Server error: {str(e)}'}), 500\n\n\n@app.route('/api/users/<int:user_id>/status', methods=['PUT'])\n@require_admin\ndef update_user_status(user_id):\n    try:\n        data = request.json or {}\n        is_active = data.get('is_active', True)\n        current_user_id = session.get('user_id')\n        \n        if is_active:\n            # Reactivate user\n            conn = db.get_connection()\n            cursor = conn.cursor()\n            cursor.execute('UPDATE users SET is_active = 1 WHERE id = ?', (user_id,))\n            conn.commit()\n            conn.close()\n        else:\n            # Deactivate user\n            conn = db.get_connection()\n            cursor = conn.cursor()\n            cursor.execute('UPDATE users SET is_active = 0 WHERE id = ?', (user_id,))\n            conn.commit()\n            conn.close()\n            \n            # IF USER DEACTIVATED THEMSELVES - LOG THEM OUT IMMEDIATELY\n            if current_user_id == user_id:\n                # Invalidate all their sessions\n                try:\n                    conn = db.get_connection()\n                    cursor = conn.cursor()\n                    cursor.execute('DELETE FROM user_sessions WHERE user_id = ?', (user_id,))\n                    conn.commit()\n                    conn.close()\n                except:\n                    pass\n                \n                # Clear their current session\n                session.clear()\n                \n                # Return special response to trigger logout on frontend\n                return jsonify({\n                    'success': True,\n                    'logged_out': True,\n                    'message': 'Your account has been deactivated. You will be logged out.'\n                }), 200\n        \n        # Log event async\n        def log_event():\n            try:\n                event_type = 'user_activated' if is_active else 'user_deactivated'\n                db.add_event(\n                    event_type=event_type,\n                    severity='info',\n                    description=f\"User {user_id} {'activated' if is_active else 'deactivated'}\"\n                )\n            except:\n                pass\n        \n        import threading\n        threading.Thread(target=log_event, daemon=True).start()\n        \n        # Broadcast user list update (async)\n        def broadcast_update():\n            try:\n                all_users = user_manager.get_all_users()\n                safe_emit('user_list_update', {\n                    'users': all_users,\n                    'timestamp': datetime.now().isoformat(),\n                    'action': 'user_status_changed',\n                    'user_id': user_id,\n                    'deactivated_self': current_user_id == user_id and not is_active\n                })\n            except:\n                pass\n        \n        threading.Thread(target=broadcast_update, daemon=True).start()\n        \n        return jsonify({'success': True})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@app.route('/api/users/activity', methods=['GET'])\n@require_admin\ndef get_user_activity():\n    try:\n        limit = request.args.get('limit', 100, type=int)\n        activity = user_manager.get_user_activity(limit=limit)\n        return jsonify({'success': True, 'data': activity})\n    except Exception as e:\n        return jsonify({'success': False, 'error': str(e)}), 500\n\n\n@socketio.on('connect')\ndef handle_connect():\n    try:\n        client_sid = request.sid\n        active_clients.add(client_sid)\n        # Only log in verbose mode - reduce noise\n        # print(f\"{Colors.GREEN}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} Client connected: {client_sid}\")\n        emit('connected', {'message': 'Connected to NetWatch SIEM'}, skip_errors=True)\n    except Exception:\n        pass\n\n@socketio.on('disconnect')\ndef handle_disconnect():\n    try:\n        client_sid = request.sid\n        if client_sid in active_clients:\n            active_clients.remove(client_sid)\n        # Only log in verbose mode - reduce noise\n        # print(f\"{Colors.YELLOW}[{datetime.now().strftime('%H:%M:%S')}]{Colors.RESET} Client disconnected: {client_sid}\")\n    except Exception:\n        pass\n\n@socketio.on('request_dashboard_stats')\ndef handle_dashboard_stats_request():\n    try:\n        stats = db.get_dashboard_stats()\n        if stats:\n            emit('dashboard_stats_update', {\n                'stats': stats,\n                'timestamp': datetime.now().isoformat()\n            }, skip_errors=True)\n    except Exception:\n        pass\n\n@socketio.on('request_device_list')\ndef handle_device_list_request():\n    try:\n        devices = db.get_all_devices()\n        if devices is not None:\n            emit('device_list_update', {\n                'devices': devices,\n                'timestamp': datetime.now().isoformat()\n            }, skip_errors=True)\n    except Exception:\n        pass\n\n\nif __name__ == '__main__':\n    socketio.run(app, host='0.0.0.0', port=5000, debug=False)","size_bytes":53532},"config.py":{"content":"import os\nfrom datetime import timedelta\n\nclass Config:\n    SECRET_KEY = os.environ.get('SESSION_SECRET', 'netwatch-siem-secret-key-2024')\n    DATABASE_PATH = 'netwatch.db'\n    \n    SCAN_INTERVAL = 10\n    SCAN_TIMEOUT = 5\n    \n    ALERT_RETENTION_DAYS = 90\n    LOG_RETENTION_DAYS = 365\n    \n    LICENSE_TYPE = 'FULL'\n    \n    TRAFFIC_MONITORING = True\n    EXTENDED_LOGS = True\n    EMAIL_ALERTS = True\n    ADVANCED_RULES = True\n    \n    RULES_CONFIG = {\n        'new_device_alert': True,\n        'reconnect_threshold': 5,\n        'inactive_timeout': 3600,\n        'suspicious_mac_prefixes': ['00:00:00', 'FF:FF:FF'],\n        'traffic_spike_threshold': 1000000\n    }\n    \n    ALERT_SETTINGS = {\n        'enable_sound': True,\n        'enable_popup': True,\n        'enable_email': True\n    }\n","size_bytes":788},"monitoring/traffic_analyzer.py":{"content":"\"\"\"\nReal-time Traffic Analyzer for NetWatch SIEM\nProvides deep packet inspection and traffic analysis\n\"\"\"\n\nimport asyncio\nimport json\nimport logging\nimport socket\nimport struct\nimport threading\nimport time\nfrom collections import defaultdict, deque\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional, Tuple\nimport psutil\nfrom scapy.all import *\nfrom scapy.layers.inet import IP, TCP, UDP, ICMP\nfrom scapy.layers.l2 import ARP, Ether # this is for the ethernet layer which is used to extract the source and destination mac addresses\nimport hashlib\n\nlogger = logging.getLogger(__name__)\n\nclass TrafficAnalyzer:\n    \"\"\"Real-time network traffic analysis and monitoring\"\"\"\n    \n    def __init__(self, db, config=None):\n        self.db = db\n        self.config = config or {}\n        self.is_monitoring = False\n        self.monitor_thread = None\n        \n        # Traffic statistics\n        self.traffic_stats = defaultdict(lambda: {\n            'bytes_sent': 0,\n            'bytes_received': 0,\n            'packets_sent': 0,\n            'packets_received': 0,\n            'connections': 0,\n            'last_seen': None\n        })\n        \n        # Connection tracking\n        self.active_connections = {}\n        self.connection_history = deque(maxlen=10000)\n        \n        # Threat detection\n        self.threat_detector = ThreatDetector()\n        self.anomaly_detector = AnomalyDetector()\n        \n        # Performance monitoring\n        self.performance_metrics = {\n            'packets_processed': 0,\n            'threats_detected': 0,\n            'anomalies_detected': 0,\n            'start_time': None\n        }\n        \n        # Bandwidth monitoring\n        self.bandwidth_stats = defaultdict(lambda: deque(maxlen=60))  # 60 seconds\n        \n    def start_monitoring(self, interface=None):\n        \"\"\"Start real-time traffic monitoring\"\"\"\n        if self.is_monitoring:\n            return\n        \n        self.is_monitoring = True\n        self.performance_metrics['start_time'] = datetime.now()\n        \n        # Start monitoring thread\n        self.monitor_thread = threading.Thread(\n            target=self._monitoring_loop, \n            args=(interface,),\n            daemon=True\n        )\n        self.monitor_thread.start()\n        \n        logger.info(f\"Traffic monitoring started on interface: {interface or 'auto'}\")\n    \n    def stop_monitoring(self):\n        \"\"\"Stop traffic monitoring\"\"\"\n        self.is_monitoring = False\n        if self.monitor_thread:\n            self.monitor_thread.join(timeout=5)\n        logger.info(\"Traffic monitoring stopped\")\n    \n    def _monitoring_loop(self, interface=None):\n        \"\"\"Main monitoring loop\"\"\"\n        try:\n            # Get network interface\n            if not interface:\n                interface = self._get_primary_interface()\n            \n            if not interface:\n                logger.error(\"No suitable network interface found\")\n                return\n            \n            # Start packet capture\n            sniff(\n                iface=interface,\n                prn=self._process_packet,\n                store=0,\n                stop_filter=lambda x: not self.is_monitoring\n            )\n            \n        except Exception as e:\n            logger.error(f\"Traffic monitoring error: {e}\")\n    \n    def _get_primary_interface(self) -> Optional[str]:\n        \"\"\"Get primary network interface\"\"\"\n        try:\n            interfaces = psutil.net_if_addrs()\n            \n            for interface, addresses in interfaces.items():\n                if interface.startswith(('lo', 'docker', 'veth')):\n                    continue\n                \n                for addr in addresses:\n                    if addr.family == socket.AF_INET and not addr.address.startswith('127.'):\n                        return interface\n            \n        except Exception as e:\n            logger.error(f\"Error getting primary interface: {e}\")\n        \n        return None\n    \n    def _process_packet(self, packet):\n        \"\"\"Process captured packet\"\"\"\n        try:\n            self.performance_metrics['packets_processed'] += 1\n            \n            # Extract packet information\n            packet_info = self._extract_packet_info(packet)\n            if not packet_info:\n                return\n            \n            # Update traffic statistics\n            self._update_traffic_stats(packet_info)\n            \n            # Track connections\n            self._track_connection(packet_info)\n            \n            # Detect threats\n            threats = self.threat_detector.analyze_packet(packet_info)\n            if threats:\n                self.performance_metrics['threats_detected'] += len(threats)\n                self._handle_threats(threats, packet_info)\n            \n            # Detect anomalies\n            anomalies = self.anomaly_detector.detect_anomalies(packet_info)\n            if anomalies:\n                self.performance_metrics['anomalies_detected'] += len(anomalies)\n                self._handle_anomalies(anomalies, packet_info)\n            \n            # Update bandwidth stats\n            self._update_bandwidth_stats(packet_info)\n            \n        except Exception as e:\n            logger.error(f\"Error processing packet: {e}\")\n    \n    def _extract_packet_info(self, packet) -> Optional[Dict]:\n        \"\"\"Extract relevant information from packet\"\"\"\n        try:\n            packet_info = {\n                'timestamp': datetime.now(),\n                'size': len(packet),\n                'protocol': 'unknown'\n            }\n            \n            # Extract IP information\n            if IP in packet:\n                ip_layer = packet[IP]\n                packet_info.update({\n                    'src_ip': ip_layer.src,\n                    'dst_ip': ip_layer.dst,\n                    'protocol': ip_layer.proto,\n                    'ttl': ip_layer.ttl,\n                    'tos': ip_layer.tos\n                })\n                \n                # Extract TCP information\n                if TCP in packet:\n                    tcp_layer = packet[TCP]\n                    packet_info.update({\n                        'src_port': tcp_layer.sport,\n                        'dst_port': tcp_layer.dport,\n                        'flags': tcp_layer.flags,\n                        'seq': tcp_layer.seq,\n                        'ack': tcp_layer.ack,\n                        'window': tcp_layer.window\n                    })\n                \n                # Extract UDP information\n                elif UDP in packet:\n                    udp_layer = packet[UDP]\n                    packet_info.update({\n                        'src_port': udp_layer.sport,\n                        'dst_port': udp_layer.dport,\n                        'length': udp_layer.len\n                    })\n                \n                # Extract ICMP information\n                elif ICMP in packet:\n                    icmp_layer = packet[ICMP]\n                    packet_info.update({\n                        'icmp_type': icmp_layer.type,\n                        'icmp_code': icmp_layer.code\n                    })\n            \n            # Extract Ethernet information\n            if Ether in packet:\n                eth_layer = packet[Ether]\n                packet_info.update({\n                    'src_mac': eth_layer.src,\n                    'dst_mac': eth_layer.dst,\n                    'ethertype': eth_layer.type\n                })\n            \n            # Extract ARP information\n            if ARP in packet:\n                arp_layer = packet[ARP]\n                packet_info.update({\n                    'arp_op': arp_layer.op,\n                    'arp_psrc': arp_layer.psrc,\n                    'arp_pdst': arp_layer.pdst,\n                    'arp_hwsrc': arp_layer.hwsrc,\n                    'arp_hwdst': arp_layer.hwdst\n                })\n            \n            return packet_info\n            \n        except Exception as e:\n            logger.error(f\"Error extracting packet info: {e}\")\n            return None\n    \n    def _update_traffic_stats(self, packet_info: Dict):\n        \"\"\"Update traffic statistics\"\"\"\n        try:\n            src_ip = packet_info.get('src_ip')\n            dst_ip = packet_info.get('dst_ip')\n            size = packet_info.get('size', 0)\n            \n            if src_ip:\n                self.traffic_stats[src_ip]['bytes_sent'] += size\n                self.traffic_stats[src_ip]['packets_sent'] += 1\n                self.traffic_stats[src_ip]['last_seen'] = packet_info['timestamp']\n            \n            if dst_ip:\n                self.traffic_stats[dst_ip]['bytes_received'] += size\n                self.traffic_stats[dst_ip]['packets_received'] += 1\n                self.traffic_stats[dst_ip]['last_seen'] = packet_info['timestamp']\n                \n        except Exception as e:\n            logger.error(f\"Error updating traffic stats: {e}\")\n    \n    def _track_connection(self, packet_info: Dict):\n        \"\"\"Track network connections\"\"\"\n        try:\n            src_ip = packet_info.get('src_ip')\n            dst_ip = packet_info.get('dst_ip')\n            src_port = packet_info.get('src_port')\n            dst_port = packet_info.get('dst_port')\n            protocol = packet_info.get('protocol')\n            \n            if not all([src_ip, dst_ip, src_port, dst_port, protocol]):\n                return\n            \n            # Create connection key\n            conn_key = f\"{src_ip}:{src_port}-{dst_ip}:{dst_port}-{protocol}\"\n            \n            # Update connection info\n            if conn_key not in self.active_connections:\n                self.active_connections[conn_key] = {\n                    'src_ip': src_ip,\n                    'dst_ip': dst_ip,\n                    'src_port': src_port,\n                    'dst_port': dst_port,\n                    'protocol': protocol,\n                    'start_time': packet_info['timestamp'],\n                    'packets': 0,\n                    'bytes': 0,\n                    'last_seen': packet_info['timestamp']\n                }\n            \n            # Update connection stats\n            self.active_connections[conn_key]['packets'] += 1\n            self.active_connections[conn_key]['bytes'] += packet_info.get('size', 0)\n            self.active_connections[conn_key]['last_seen'] = packet_info['timestamp']\n            \n            # Add to history\n            self.connection_history.append({\n                'timestamp': packet_info['timestamp'],\n                'connection': conn_key,\n                'packet_info': packet_info\n            })\n            \n        except Exception as e:\n            logger.error(f\"Error tracking connection: {e}\")\n    \n    def _update_bandwidth_stats(self, packet_info: Dict):\n        \"\"\"Update bandwidth statistics\"\"\"\n        try:\n            current_time = packet_info['timestamp']\n            size = packet_info.get('size', 0)\n            \n            # Update per-second bandwidth\n            second_key = current_time.strftime('%Y-%m-%d %H:%M:%S')\n            self.bandwidth_stats[second_key].append(size)\n            \n        except Exception as e:\n            logger.error(f\"Error updating bandwidth stats: {e}\")\n    \n    def _handle_threats(self, threats: List[Dict], packet_info: Dict):\n        \"\"\"Handle detected threats\"\"\"\n        try:\n            for threat in threats:\n                # Log threat\n                self.db.add_event(\n                    event_type='threat_detected',\n                    severity=threat.get('severity', 'medium'),\n                    description=threat.get('description', 'Unknown threat'),\n                    metadata={\n                        'threat_type': threat.get('type'),\n                        'packet_info': packet_info,\n                        'threat_details': threat\n                    }\n                )\n                \n                # Create alert\n                self.db.add_alert(\n                    alert_type=threat.get('type', 'unknown_threat'),\n                    severity=threat.get('severity', 'medium'),\n                    title=f\"Threat Detected: {threat.get('type', 'Unknown')}\",\n                    description=threat.get('description', 'Unknown threat detected'),\n                    metadata=threat\n                )\n                \n                logger.warning(f\"Threat detected: {threat}\")\n                \n        except Exception as e:\n            logger.error(f\"Error handling threats: {e}\")\n    \n    def _handle_anomalies(self, anomalies: List[Dict], packet_info: Dict):\n        \"\"\"Handle detected anomalies\"\"\"\n        try:\n            for anomaly in anomalies:\n                # Log anomaly\n                self.db.add_event(\n                    event_type='anomaly_detected',\n                    severity='low',\n                    description=anomaly.get('description', 'Network anomaly detected'),\n                    metadata={\n                        'anomaly_type': anomaly.get('type'),\n                        'packet_info': packet_info,\n                        'anomaly_details': anomaly\n                    }\n                )\n                \n                logger.info(f\"Anomaly detected: {anomaly}\")\n                \n        except Exception as e:\n            logger.error(f\"Error handling anomalies: {e}\")\n    \n    def get_traffic_stats(self) -> Dict:\n        \"\"\"Get current traffic statistics\"\"\"\n        return {\n            'traffic_stats': dict(self.traffic_stats),\n            'active_connections': len(self.active_connections),\n            'performance_metrics': self.performance_metrics.copy(),\n            'bandwidth_stats': {\n                key: sum(values) for key, values in self.bandwidth_stats.items()\n            }\n        }\n    \n    def get_connection_history(self, limit: int = 100) -> List[Dict]:\n        \"\"\"Get recent connection history\"\"\"\n        return list(self.connection_history)[-limit:]\n    \n    def get_bandwidth_usage(self, time_window: int = 60) -> Dict:\n        \"\"\"Get bandwidth usage for time window\"\"\"\n        current_time = datetime.now()\n        start_time = current_time - timedelta(seconds=time_window)\n        \n        bandwidth_data = []\n        for second_key, sizes in self.bandwidth_stats.items():\n            try:\n                second_time = datetime.strptime(second_key, '%Y-%m-%d %H:%M:%S')\n                if second_time >= start_time:\n                    bandwidth_data.append({\n                        'timestamp': second_time.isoformat(),\n                        'bytes': sum(sizes)\n                    })\n            except:\n                continue\n        \n        return {\n            'time_window': time_window,\n            'data': sorted(bandwidth_data, key=lambda x: x['timestamp'])\n        }\n\n\nclass ThreatDetector:\n    \"\"\"Detect security threats in network traffic\"\"\"\n    \n    def __init__(self):\n        self.threat_patterns = {\n            'port_scan': {\n                'threshold': 10,\n                'time_window': 60,\n                'description': 'Port scanning detected'\n            },\n            'brute_force': {\n                'threshold': 5,\n                'time_window': 300,\n                'description': 'Brute force attack detected'\n            },\n            'ddos': {\n                'threshold': 100,\n                'time_window': 60,\n                'description': 'DDoS attack detected'\n            },\n            'suspicious_ports': {\n                'ports': [23, 135, 139, 445, 1433, 3389],\n                'description': 'Suspicious port access detected'\n            }\n        }\n        \n        self.detection_counters = defaultdict(lambda: defaultdict(int))\n        self.last_reset = datetime.now()\n    \n    def analyze_packet(self, packet_info: Dict) -> List[Dict]:\n        \"\"\"Analyze packet for threats\"\"\"\n        threats = []\n        \n        try:\n            # Check for port scanning\n            port_scan_threat = self._detect_port_scan(packet_info)\n            if port_scan_threat:\n                threats.append(port_scan_threat)\n            \n            # Check for brute force\n            brute_force_threat = self._detect_brute_force(packet_info)\n            if brute_force_threat:\n                threats.append(brute_force_threat)\n            \n            # Check for suspicious ports\n            suspicious_port_threat = self._detect_suspicious_ports(packet_info)\n            if suspicious_port_threat:\n                threats.append(suspicious_port_threat)\n            \n            # Check for DDoS\n            ddos_threat = self._detect_ddos(packet_info)\n            if ddos_threat:\n                threats.append(ddos_threat)\n            \n        except Exception as e:\n            logger.error(f\"Error analyzing packet for threats: {e}\")\n        \n        return threats\n    \n    def _detect_port_scan(self, packet_info: Dict) -> Optional[Dict]:\n        \"\"\"Detect port scanning attempts\"\"\"\n        try:\n            src_ip = packet_info.get('src_ip')\n            dst_port = packet_info.get('dst_port')\n            \n            if not src_ip or not dst_port:\n                return None\n            \n            # Reset counters every minute\n            if (datetime.now() - self.last_reset).seconds >= 60:\n                self.detection_counters.clear()\n                self.last_reset = datetime.now()\n            \n            # Count unique ports accessed by source IP\n            port_key = f\"port_scan_{src_ip}\"\n            self.detection_counters[port_key][dst_port] += 1\n            \n            # Check threshold\n            if len(self.detection_counters[port_key]) >= self.threat_patterns['port_scan']['threshold']:\n                return {\n                    'type': 'port_scan',\n                    'severity': 'high',\n                    'description': f'Port scanning detected from {src_ip}',\n                    'source_ip': src_ip,\n                    'ports_scanned': list(self.detection_counters[port_key].keys())\n                }\n            \n        except Exception as e:\n            logger.error(f\"Error detecting port scan: {e}\")\n        \n        return None\n    \n    def _detect_brute_force(self, packet_info: Dict) -> Optional[Dict]:\n        \"\"\"Detect brute force attacks\"\"\"\n        try:\n            src_ip = packet_info.get('src_ip')\n            dst_ip = packet_info.get('dst_ip')\n            dst_port = packet_info.get('dst_port')\n            \n            if not all([src_ip, dst_ip, dst_port]):\n                return None\n            \n            # Check for SSH brute force (port 22)\n            if dst_port == 22:\n                brute_key = f\"brute_force_{src_ip}_{dst_ip}_{dst_port}\"\n                self.detection_counters[brute_key]['attempts'] += 1\n                \n                if self.detection_counters[brute_key]['attempts'] >= self.threat_patterns['brute_force']['threshold']:\n                    return {\n                        'type': 'brute_force',\n                        'severity': 'high',\n                        'description': f'Brute force attack detected from {src_ip} to {dst_ip}:{dst_port}',\n                        'source_ip': src_ip,\n                        'target_ip': dst_ip,\n                        'target_port': dst_port,\n                        'attempts': self.detection_counters[brute_key]['attempts']\n                    }\n            \n        except Exception as e:\n            logger.error(f\"Error detecting brute force: {e}\")\n        \n        return None\n    \n    def _detect_suspicious_ports(self, packet_info: Dict) -> Optional[Dict]:\n        \"\"\"Detect access to suspicious ports\"\"\"\n        try:\n            dst_port = packet_info.get('dst_port')\n            src_ip = packet_info.get('src_ip')\n            \n            if not dst_port or not src_ip:\n                return None\n            \n            suspicious_ports = self.threat_patterns['suspicious_ports']['ports']\n            \n            if dst_port in suspicious_ports:\n                return {\n                    'type': 'suspicious_port_access',\n                    'severity': 'medium',\n                    'description': f'Suspicious port {dst_port} accessed from {src_ip}',\n                    'source_ip': src_ip,\n                    'suspicious_port': dst_port\n                }\n            \n        except Exception as e:\n            logger.error(f\"Error detecting suspicious ports: {e}\")\n        \n        return None\n    \n    def _detect_ddos(self, packet_info: Dict) -> Optional[Dict]:\n        \"\"\"Detect DDoS attacks\"\"\"\n        try:\n            dst_ip = packet_info.get('dst_ip')\n            \n            if not dst_ip:\n                return None\n            \n            # Count packets to destination IP\n            ddos_key = f\"ddos_{dst_ip}\"\n            self.detection_counters[ddos_key]['packets'] += 1\n            \n            # Check threshold\n            if self.detection_counters[ddos_key]['packets'] >= self.threat_patterns['ddos']['threshold']:\n                return {\n                    'type': 'ddos',\n                    'severity': 'critical',\n                    'description': f'Potential DDoS attack targeting {dst_ip}',\n                    'target_ip': dst_ip,\n                    'packet_count': self.detection_counters[ddos_key]['packets']\n                }\n            \n        except Exception as e:\n            logger.error(f\"Error detecting DDoS: {e}\")\n        \n        return None\n\n\nclass AnomalyDetector:\n    \"\"\"Detect anomalous network behavior\"\"\"\n    \n    def __init__(self):\n        self.baseline_metrics = defaultdict(lambda: deque(maxlen=1000))\n        self.anomaly_threshold = 2.5  # Z-score threshold\n        \n    def detect_anomalies(self, packet_info: Dict) -> List[Dict]:\n        \"\"\"Detect anomalies in network behavior\"\"\"\n        anomalies = []\n        \n        try:\n            # Check bandwidth anomalies\n            bandwidth_anomaly = self._detect_bandwidth_anomaly(packet_info)\n            if bandwidth_anomaly:\n                anomalies.append(bandwidth_anomaly)\n            \n            # Check connection anomalies\n            connection_anomaly = self._detect_connection_anomaly(packet_info)\n            if connection_anomaly:\n                anomalies.append(connection_anomaly)\n            \n        except Exception as e:\n            logger.error(f\"Error detecting anomalies: {e}\")\n        \n        return anomalies\n    \n    def _detect_bandwidth_anomaly(self, packet_info: Dict) -> Optional[Dict]:\n        \"\"\"Detect bandwidth anomalies\"\"\"\n        try:\n            size = packet_info.get('size', 0)\n            \n            # Update baseline\n            self.baseline_metrics['packet_size'].append(size)\n            \n            # Check for anomaly\n            if len(self.baseline_metrics['packet_size']) >= 100:\n                if self._is_anomalous(size, self.baseline_metrics['packet_size']):\n                    return {\n                        'type': 'bandwidth_anomaly',\n                        'description': f'Unusual packet size detected: {size} bytes',\n                        'packet_size': size,\n                        'severity': 'low'\n                    }\n            \n        except Exception as e:\n            logger.error(f\"Error detecting bandwidth anomaly: {e}\")\n        \n        return None\n    \n    def _detect_connection_anomaly(self, packet_info: Dict) -> Optional[Dict]:\n        \"\"\"Detect connection anomalies\"\"\"\n        try:\n            src_ip = packet_info.get('src_ip')\n            \n            if not src_ip:\n                return None\n            \n            # Update baseline\n            self.baseline_metrics[f'connections_{src_ip}'].append(datetime.now())\n            \n            # Check for anomaly (too many connections)\n            recent_connections = [\n                conn for conn in self.baseline_metrics[f'connections_{src_ip}']\n                if (datetime.now() - conn).seconds <= 60\n            ]\n            \n            if len(recent_connections) > 50:  # Threshold for anomaly\n                return {\n                    'type': 'connection_anomaly',\n                    'description': f'Unusual connection pattern from {src_ip}',\n                    'source_ip': src_ip,\n                    'connection_count': len(recent_connections),\n                    'severity': 'medium'\n                }\n            \n        except Exception as e:\n            logger.error(f\"Error detecting connection anomaly: {e}\")\n        \n        return None\n    \n    def _is_anomalous(self, value: float, baseline: deque) -> bool:\n        \"\"\"Check if value is anomalous based on baseline\"\"\"\n        try:\n            if len(baseline) < 10:\n                return False\n            \n            baseline_values = list(baseline)\n            mean = sum(baseline_values) / len(baseline_values)\n            variance = sum((x - mean) ** 2 for x in baseline_values) / len(baseline_values)\n            std_dev = variance ** 0.5\n            \n            if std_dev == 0:\n                return False\n            \n            z_score = abs(value - mean) / std_dev\n            return z_score > self.anomaly_threshold\n            \n        except Exception as e:\n            logger.error(f\"Error checking anomaly: {e}\")\n            return False\n","size_bytes":25162}},"version":2}